<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<conference>
    <name>International Conference on Artificial Neural Networks 2013</name>
    <acronym>ICANN2013</acronym>
    <description>The International Conference on Artificial Neural Networks (ICANN) is the annual flagship conference of the European Neural Network&#xD;
Society (ENNS). &#xD;
ICANN 2013 will provide a high-level international forum for the academic and industrial community to address new challenges, share solutions and discuss future research directions in neural networks, learning systems, computational intelligence, and real-world applications.&#xD;
&#xD;
More information on the homepage of the conference&#xD;
http://www.icann2013.org</description>
    <homepage>http://senldogo0039.springer-sbm.com</homepage>
    <pc-chairs>
        <pc-chair-id>person-45652</pc-chair-id>
        <pc-chair-id>person-32555480</pc-chair-id>
        <pc-chair-id>person-45776</pc-chair-id>
        <pc-chair-id>person-32633436</pc-chair-id>
        <pc-chair-id>person-45536</pc-chair-id>
        <pc-chair-id>person-32760</pc-chair-id>
    </pc-chairs>
    <pc-members>
        <pc-member-id>person-49676</pc-member-id>
        <pc-member-id>person-32250888</pc-member-id>
        <pc-member-id>person-51754</pc-member-id>
        <pc-member-id>person-32652672</pc-member-id>
        <pc-member-id>person-47310</pc-member-id>
        <pc-member-id>person-89382</pc-member-id>
        <pc-member-id>person-32650564</pc-member-id>
        <pc-member-id>person-32551372</pc-member-id>
        <pc-member-id>person-41861</pc-member-id>
        <pc-member-id>person-90477</pc-member-id>
        <pc-member-id>person-32651981</pc-member-id>
        <pc-member-id>person-32650853</pc-member-id>
        <pc-member-id>person-32652277</pc-member-id>
        <pc-member-id>person-32268372</pc-member-id>
        <pc-member-id>person-32657812</pc-member-id>
        <pc-member-id>person-32651709</pc-member-id>
        <pc-member-id>person-32652270</pc-member-id>
        <pc-member-id>person-32277579</pc-member-id>
        <pc-member-id>person-75747</pc-member-id>
        <pc-member-id>person-32652204</pc-member-id>
        <pc-member-id>person-32574873</pc-member-id>
        <pc-member-id>person-32650268</pc-member-id>
        <pc-member-id>person-47184</pc-member-id>
        <pc-member-id>person-32651861</pc-member-id>
        <pc-member-id>person-32651376</pc-member-id>
        <pc-member-id>person-47254</pc-member-id>
        <pc-member-id>person-32598838</pc-member-id>
        <pc-member-id>person-45776</pc-member-id>
        <pc-member-id>person-32649738</pc-member-id>
        <pc-member-id>person-46122</pc-member-id>
        <pc-member-id>person-32235763</pc-member-id>
        <pc-member-id>person-32650411</pc-member-id>
        <pc-member-id>person-32649969</pc-member-id>
        <pc-member-id>person-85050</pc-member-id>
        <pc-member-id>person-49927</pc-member-id>
        <pc-member-id>person-32654058</pc-member-id>
        <pc-member-id>person-24716</pc-member-id>
        <pc-member-id>person-32236453</pc-member-id>
        <pc-member-id>person-32235592</pc-member-id>
        <pc-member-id>person-32652807</pc-member-id>
        <pc-member-id>person-32653499</pc-member-id>
        <pc-member-id>person-47133</pc-member-id>
        <pc-member-id>person-32650240</pc-member-id>
        <pc-member-id>person-40568</pc-member-id>
        <pc-member-id>person-32650367</pc-member-id>
        <pc-member-id>person-46116</pc-member-id>
        <pc-member-id>person-32629057</pc-member-id>
        <pc-member-id>person-48738</pc-member-id>
        <pc-member-id>person-32242673</pc-member-id>
        <pc-member-id>person-32681420</pc-member-id>
        <pc-member-id>person-32235753</pc-member-id>
        <pc-member-id>person-32241085</pc-member-id>
        <pc-member-id>person-32652054</pc-member-id>
        <pc-member-id>person-46023</pc-member-id>
        <pc-member-id>person-32693457</pc-member-id>
        <pc-member-id>person-32652080</pc-member-id>
        <pc-member-id>person-32651275</pc-member-id>
        <pc-member-id>person-32633436</pc-member-id>
        <pc-member-id>person-32278102</pc-member-id>
        <pc-member-id>person-32651938</pc-member-id>
        <pc-member-id>person-32649897</pc-member-id>
        <pc-member-id>person-49394</pc-member-id>
        <pc-member-id>person-32650599</pc-member-id>
        <pc-member-id>person-32650571</pc-member-id>
        <pc-member-id>person-32651419</pc-member-id>
        <pc-member-id>person-46964</pc-member-id>
        <pc-member-id>person-47138</pc-member-id>
        <pc-member-id>person-32651088</pc-member-id>
        <pc-member-id>person-32650634</pc-member-id>
        <pc-member-id>person-32580152</pc-member-id>
        <pc-member-id>person-49485</pc-member-id>
        <pc-member-id>person-46673</pc-member-id>
        <pc-member-id>person-48693</pc-member-id>
        <pc-member-id>person-46851</pc-member-id>
        <pc-member-id>person-59412</pc-member-id>
        <pc-member-id>person-32651976</pc-member-id>
        <pc-member-id>person-81561</pc-member-id>
        <pc-member-id>person-46134</pc-member-id>
        <pc-member-id>person-32306808</pc-member-id>
        <pc-member-id>person-46093</pc-member-id>
        <pc-member-id>person-45536</pc-member-id>
        <pc-member-id>person-45115</pc-member-id>
        <pc-member-id>person-32235225</pc-member-id>
        <pc-member-id>person-32606978</pc-member-id>
        <pc-member-id>person-32697866</pc-member-id>
        <pc-member-id>person-32658597</pc-member-id>
        <pc-member-id>person-46021</pc-member-id>
        <pc-member-id>person-32649636</pc-member-id>
        <pc-member-id>person-32653512</pc-member-id>
        <pc-member-id>person-47052</pc-member-id>
        <pc-member-id>person-91060</pc-member-id>
        <pc-member-id>person-32652226</pc-member-id>
        <pc-member-id>person-32598843</pc-member-id>
        <pc-member-id>person-32651889</pc-member-id>
        <pc-member-id>person-32268904</pc-member-id>
        <pc-member-id>person-32681937</pc-member-id>
        <pc-member-id>person-32760</pc-member-id>
        <pc-member-id>person-50804</pc-member-id>
        <pc-member-id>person-32660075</pc-member-id>
        <pc-member-id>person-47136</pc-member-id>
        <pc-member-id>person-32653710</pc-member-id>
        <pc-member-id>person-32650848</pc-member-id>
        <pc-member-id>person-32652581</pc-member-id>
    </pc-members>
    <proceedings-list>
        <proceedings id="proceedings-32919664">
            <title>Artificial Neural Networks: Theory and Applications - ICANN 2013</title>
            <series>ICANN2013</series>
        </proceedings>
    </proceedings-list>
    <sessions>
        <session id="session-32919821" inProceedings="proceedings-32919664">
            <name>Neural network theory and models</name>
            <papers>
                <paper-id>paper-32599932</paper-id>
                <paper-id>paper-32608586</paper-id>
                <paper-id>paper-32612540</paper-id>
                <paper-id>paper-32613336</paper-id>
                <paper-id>paper-32615998</paper-id>
                <paper-id>paper-32617929</paper-id>
                <paper-id>paper-32619276</paper-id>
                <paper-id>paper-32638614</paper-id>
                <paper-id>paper-32652172</paper-id>
                <paper-id>paper-32664755</paper-id>
                <paper-id>paper-32665205</paper-id>
                <paper-id>paper-32676289</paper-id>
                <paper-id>paper-32612692</paper-id>
            </papers>
            <pc-chairs>
                <pc-chair-id>person-45652</pc-chair-id>
                <pc-chair-id>person-32555480</pc-chair-id>
                <pc-chair-id>person-45776</pc-chair-id>
                <pc-chair-id>person-32633436</pc-chair-id>
                <pc-chair-id>person-45536</pc-chair-id>
                <pc-chair-id>person-32760</pc-chair-id>
            </pc-chairs>
            <pc-members>
                <pc-member-id>person-49676</pc-member-id>
                <pc-member-id>person-32250888</pc-member-id>
                <pc-member-id>person-51754</pc-member-id>
                <pc-member-id>person-32652672</pc-member-id>
                <pc-member-id>person-47310</pc-member-id>
                <pc-member-id>person-89382</pc-member-id>
                <pc-member-id>person-32650564</pc-member-id>
                <pc-member-id>person-32551372</pc-member-id>
                <pc-member-id>person-41861</pc-member-id>
                <pc-member-id>person-90477</pc-member-id>
                <pc-member-id>person-32651981</pc-member-id>
                <pc-member-id>person-32650853</pc-member-id>
                <pc-member-id>person-32652277</pc-member-id>
                <pc-member-id>person-32268372</pc-member-id>
                <pc-member-id>person-32657812</pc-member-id>
                <pc-member-id>person-32651709</pc-member-id>
                <pc-member-id>person-32652270</pc-member-id>
                <pc-member-id>person-32277579</pc-member-id>
                <pc-member-id>person-75747</pc-member-id>
                <pc-member-id>person-32652204</pc-member-id>
                <pc-member-id>person-32574873</pc-member-id>
                <pc-member-id>person-32650268</pc-member-id>
                <pc-member-id>person-47184</pc-member-id>
                <pc-member-id>person-32651861</pc-member-id>
                <pc-member-id>person-32651376</pc-member-id>
                <pc-member-id>person-47254</pc-member-id>
                <pc-member-id>person-32598838</pc-member-id>
                <pc-member-id>person-45776</pc-member-id>
                <pc-member-id>person-32649738</pc-member-id>
                <pc-member-id>person-46122</pc-member-id>
                <pc-member-id>person-32235763</pc-member-id>
                <pc-member-id>person-32650411</pc-member-id>
                <pc-member-id>person-32649969</pc-member-id>
                <pc-member-id>person-85050</pc-member-id>
                <pc-member-id>person-49927</pc-member-id>
                <pc-member-id>person-32654058</pc-member-id>
                <pc-member-id>person-24716</pc-member-id>
                <pc-member-id>person-32236453</pc-member-id>
                <pc-member-id>person-32235592</pc-member-id>
                <pc-member-id>person-32652807</pc-member-id>
                <pc-member-id>person-32653499</pc-member-id>
                <pc-member-id>person-47133</pc-member-id>
                <pc-member-id>person-32650240</pc-member-id>
                <pc-member-id>person-40568</pc-member-id>
                <pc-member-id>person-32650367</pc-member-id>
                <pc-member-id>person-46116</pc-member-id>
                <pc-member-id>person-32629057</pc-member-id>
                <pc-member-id>person-48738</pc-member-id>
                <pc-member-id>person-32242673</pc-member-id>
                <pc-member-id>person-32681420</pc-member-id>
                <pc-member-id>person-32235753</pc-member-id>
                <pc-member-id>person-32241085</pc-member-id>
                <pc-member-id>person-32652054</pc-member-id>
                <pc-member-id>person-46023</pc-member-id>
                <pc-member-id>person-32693457</pc-member-id>
                <pc-member-id>person-32652080</pc-member-id>
                <pc-member-id>person-32651275</pc-member-id>
                <pc-member-id>person-32633436</pc-member-id>
                <pc-member-id>person-32278102</pc-member-id>
                <pc-member-id>person-32651938</pc-member-id>
                <pc-member-id>person-32649897</pc-member-id>
                <pc-member-id>person-49394</pc-member-id>
                <pc-member-id>person-32650599</pc-member-id>
                <pc-member-id>person-32650571</pc-member-id>
                <pc-member-id>person-32651419</pc-member-id>
                <pc-member-id>person-46964</pc-member-id>
                <pc-member-id>person-47138</pc-member-id>
                <pc-member-id>person-32651088</pc-member-id>
                <pc-member-id>person-32650634</pc-member-id>
                <pc-member-id>person-32580152</pc-member-id>
                <pc-member-id>person-49485</pc-member-id>
                <pc-member-id>person-46673</pc-member-id>
                <pc-member-id>person-48693</pc-member-id>
                <pc-member-id>person-46851</pc-member-id>
                <pc-member-id>person-59412</pc-member-id>
                <pc-member-id>person-32651976</pc-member-id>
                <pc-member-id>person-81561</pc-member-id>
                <pc-member-id>person-46134</pc-member-id>
                <pc-member-id>person-32306808</pc-member-id>
                <pc-member-id>person-46093</pc-member-id>
                <pc-member-id>person-45536</pc-member-id>
                <pc-member-id>person-45115</pc-member-id>
                <pc-member-id>person-32235225</pc-member-id>
                <pc-member-id>person-32606978</pc-member-id>
                <pc-member-id>person-32697866</pc-member-id>
                <pc-member-id>person-32658597</pc-member-id>
                <pc-member-id>person-46021</pc-member-id>
                <pc-member-id>person-32649636</pc-member-id>
                <pc-member-id>person-32653512</pc-member-id>
                <pc-member-id>person-47052</pc-member-id>
                <pc-member-id>person-91060</pc-member-id>
                <pc-member-id>person-32652226</pc-member-id>
                <pc-member-id>person-32598843</pc-member-id>
                <pc-member-id>person-32651889</pc-member-id>
                <pc-member-id>person-32268904</pc-member-id>
                <pc-member-id>person-32681937</pc-member-id>
                <pc-member-id>person-32760</pc-member-id>
                <pc-member-id>person-50804</pc-member-id>
                <pc-member-id>person-32660075</pc-member-id>
                <pc-member-id>person-47136</pc-member-id>
                <pc-member-id>person-32653710</pc-member-id>
                <pc-member-id>person-32650848</pc-member-id>
                <pc-member-id>person-32652581</pc-member-id>
            </pc-members>
        </session>
        <session id="session-32919822" inProceedings="proceedings-32919664">
            <name>Machine learning and learning algorithms</name>
            <papers>
                <paper-id>paper-32573592</paper-id>
                <paper-id>paper-32603569</paper-id>
                <paper-id>paper-32608612</paper-id>
                <paper-id>paper-32613374</paper-id>
                <paper-id>paper-32613491</paper-id>
                <paper-id>paper-32643628</paper-id>
                <paper-id>paper-32645660</paper-id>
                <paper-id>paper-32647316</paper-id>
                <paper-id>paper-32676583</paper-id>
                <paper-id>paper-32622492</paper-id>
                <paper-id>paper-32632440</paper-id>
                <paper-id>paper-32690585</paper-id>
            </papers>
            <pc-chairs>
                <pc-chair-id>person-45652</pc-chair-id>
                <pc-chair-id>person-32555480</pc-chair-id>
                <pc-chair-id>person-45776</pc-chair-id>
                <pc-chair-id>person-32633436</pc-chair-id>
                <pc-chair-id>person-45536</pc-chair-id>
                <pc-chair-id>person-32760</pc-chair-id>
            </pc-chairs>
            <pc-members>
                <pc-member-id>person-49676</pc-member-id>
                <pc-member-id>person-32250888</pc-member-id>
                <pc-member-id>person-51754</pc-member-id>
                <pc-member-id>person-32652672</pc-member-id>
                <pc-member-id>person-47310</pc-member-id>
                <pc-member-id>person-89382</pc-member-id>
                <pc-member-id>person-32650564</pc-member-id>
                <pc-member-id>person-32551372</pc-member-id>
                <pc-member-id>person-41861</pc-member-id>
                <pc-member-id>person-90477</pc-member-id>
                <pc-member-id>person-32651981</pc-member-id>
                <pc-member-id>person-32650853</pc-member-id>
                <pc-member-id>person-32652277</pc-member-id>
                <pc-member-id>person-32268372</pc-member-id>
                <pc-member-id>person-32657812</pc-member-id>
                <pc-member-id>person-32651709</pc-member-id>
                <pc-member-id>person-32652270</pc-member-id>
                <pc-member-id>person-32277579</pc-member-id>
                <pc-member-id>person-75747</pc-member-id>
                <pc-member-id>person-32652204</pc-member-id>
                <pc-member-id>person-32574873</pc-member-id>
                <pc-member-id>person-32650268</pc-member-id>
                <pc-member-id>person-47184</pc-member-id>
                <pc-member-id>person-32651861</pc-member-id>
                <pc-member-id>person-32651376</pc-member-id>
                <pc-member-id>person-47254</pc-member-id>
                <pc-member-id>person-32598838</pc-member-id>
                <pc-member-id>person-45776</pc-member-id>
                <pc-member-id>person-32649738</pc-member-id>
                <pc-member-id>person-46122</pc-member-id>
                <pc-member-id>person-32235763</pc-member-id>
                <pc-member-id>person-32650411</pc-member-id>
                <pc-member-id>person-32649969</pc-member-id>
                <pc-member-id>person-85050</pc-member-id>
                <pc-member-id>person-49927</pc-member-id>
                <pc-member-id>person-32654058</pc-member-id>
                <pc-member-id>person-24716</pc-member-id>
                <pc-member-id>person-32236453</pc-member-id>
                <pc-member-id>person-32235592</pc-member-id>
                <pc-member-id>person-32652807</pc-member-id>
                <pc-member-id>person-32653499</pc-member-id>
                <pc-member-id>person-47133</pc-member-id>
                <pc-member-id>person-32650240</pc-member-id>
                <pc-member-id>person-40568</pc-member-id>
                <pc-member-id>person-32650367</pc-member-id>
                <pc-member-id>person-46116</pc-member-id>
                <pc-member-id>person-32629057</pc-member-id>
                <pc-member-id>person-48738</pc-member-id>
                <pc-member-id>person-32242673</pc-member-id>
                <pc-member-id>person-32681420</pc-member-id>
                <pc-member-id>person-32235753</pc-member-id>
                <pc-member-id>person-32241085</pc-member-id>
                <pc-member-id>person-32652054</pc-member-id>
                <pc-member-id>person-46023</pc-member-id>
                <pc-member-id>person-32693457</pc-member-id>
                <pc-member-id>person-32652080</pc-member-id>
                <pc-member-id>person-32651275</pc-member-id>
                <pc-member-id>person-32633436</pc-member-id>
                <pc-member-id>person-32278102</pc-member-id>
                <pc-member-id>person-32651938</pc-member-id>
                <pc-member-id>person-32649897</pc-member-id>
                <pc-member-id>person-49394</pc-member-id>
                <pc-member-id>person-32650599</pc-member-id>
                <pc-member-id>person-32650571</pc-member-id>
                <pc-member-id>person-32651419</pc-member-id>
                <pc-member-id>person-46964</pc-member-id>
                <pc-member-id>person-47138</pc-member-id>
                <pc-member-id>person-32651088</pc-member-id>
                <pc-member-id>person-32650634</pc-member-id>
                <pc-member-id>person-32580152</pc-member-id>
                <pc-member-id>person-49485</pc-member-id>
                <pc-member-id>person-46673</pc-member-id>
                <pc-member-id>person-48693</pc-member-id>
                <pc-member-id>person-46851</pc-member-id>
                <pc-member-id>person-59412</pc-member-id>
                <pc-member-id>person-32651976</pc-member-id>
                <pc-member-id>person-81561</pc-member-id>
                <pc-member-id>person-46134</pc-member-id>
                <pc-member-id>person-32306808</pc-member-id>
                <pc-member-id>person-46093</pc-member-id>
                <pc-member-id>person-45536</pc-member-id>
                <pc-member-id>person-45115</pc-member-id>
                <pc-member-id>person-32235225</pc-member-id>
                <pc-member-id>person-32606978</pc-member-id>
                <pc-member-id>person-32697866</pc-member-id>
                <pc-member-id>person-32658597</pc-member-id>
                <pc-member-id>person-46021</pc-member-id>
                <pc-member-id>person-32649636</pc-member-id>
                <pc-member-id>person-32653512</pc-member-id>
                <pc-member-id>person-47052</pc-member-id>
                <pc-member-id>person-91060</pc-member-id>
                <pc-member-id>person-32652226</pc-member-id>
                <pc-member-id>person-32598843</pc-member-id>
                <pc-member-id>person-32651889</pc-member-id>
                <pc-member-id>person-32268904</pc-member-id>
                <pc-member-id>person-32681937</pc-member-id>
                <pc-member-id>person-32760</pc-member-id>
                <pc-member-id>person-50804</pc-member-id>
                <pc-member-id>person-32660075</pc-member-id>
                <pc-member-id>person-47136</pc-member-id>
                <pc-member-id>person-32653710</pc-member-id>
                <pc-member-id>person-32650848</pc-member-id>
                <pc-member-id>person-32652581</pc-member-id>
            </pc-members>
        </session>
        <session id="session-32919823" inProceedings="proceedings-32919664">
            <name>Brain-machine interaction and Bio-inspired systems</name>
            <papers>
                <paper-id>paper-32608733</paper-id>
                <paper-id>paper-32616184</paper-id>
                <paper-id>paper-32628772</paper-id>
                <paper-id>paper-32629374</paper-id>
                <paper-id>paper-32664830</paper-id>
                <paper-id>paper-32664922</paper-id>
            </papers>
            <pc-chairs>
                <pc-chair-id>person-45652</pc-chair-id>
                <pc-chair-id>person-32555480</pc-chair-id>
                <pc-chair-id>person-45776</pc-chair-id>
                <pc-chair-id>person-32633436</pc-chair-id>
                <pc-chair-id>person-45536</pc-chair-id>
                <pc-chair-id>person-32760</pc-chair-id>
            </pc-chairs>
            <pc-members>
                <pc-member-id>person-49676</pc-member-id>
                <pc-member-id>person-32250888</pc-member-id>
                <pc-member-id>person-51754</pc-member-id>
                <pc-member-id>person-32652672</pc-member-id>
                <pc-member-id>person-47310</pc-member-id>
                <pc-member-id>person-89382</pc-member-id>
                <pc-member-id>person-32650564</pc-member-id>
                <pc-member-id>person-32551372</pc-member-id>
                <pc-member-id>person-41861</pc-member-id>
                <pc-member-id>person-90477</pc-member-id>
                <pc-member-id>person-32651981</pc-member-id>
                <pc-member-id>person-32650853</pc-member-id>
                <pc-member-id>person-32652277</pc-member-id>
                <pc-member-id>person-32268372</pc-member-id>
                <pc-member-id>person-32657812</pc-member-id>
                <pc-member-id>person-32651709</pc-member-id>
                <pc-member-id>person-32652270</pc-member-id>
                <pc-member-id>person-32277579</pc-member-id>
                <pc-member-id>person-75747</pc-member-id>
                <pc-member-id>person-32652204</pc-member-id>
                <pc-member-id>person-32574873</pc-member-id>
                <pc-member-id>person-32650268</pc-member-id>
                <pc-member-id>person-47184</pc-member-id>
                <pc-member-id>person-32651861</pc-member-id>
                <pc-member-id>person-32651376</pc-member-id>
                <pc-member-id>person-47254</pc-member-id>
                <pc-member-id>person-32598838</pc-member-id>
                <pc-member-id>person-45776</pc-member-id>
                <pc-member-id>person-32649738</pc-member-id>
                <pc-member-id>person-46122</pc-member-id>
                <pc-member-id>person-32235763</pc-member-id>
                <pc-member-id>person-32650411</pc-member-id>
                <pc-member-id>person-32649969</pc-member-id>
                <pc-member-id>person-85050</pc-member-id>
                <pc-member-id>person-49927</pc-member-id>
                <pc-member-id>person-32654058</pc-member-id>
                <pc-member-id>person-24716</pc-member-id>
                <pc-member-id>person-32236453</pc-member-id>
                <pc-member-id>person-32235592</pc-member-id>
                <pc-member-id>person-32652807</pc-member-id>
                <pc-member-id>person-32653499</pc-member-id>
                <pc-member-id>person-47133</pc-member-id>
                <pc-member-id>person-32650240</pc-member-id>
                <pc-member-id>person-40568</pc-member-id>
                <pc-member-id>person-32650367</pc-member-id>
                <pc-member-id>person-46116</pc-member-id>
                <pc-member-id>person-32629057</pc-member-id>
                <pc-member-id>person-48738</pc-member-id>
                <pc-member-id>person-32242673</pc-member-id>
                <pc-member-id>person-32681420</pc-member-id>
                <pc-member-id>person-32235753</pc-member-id>
                <pc-member-id>person-32241085</pc-member-id>
                <pc-member-id>person-32652054</pc-member-id>
                <pc-member-id>person-46023</pc-member-id>
                <pc-member-id>person-32693457</pc-member-id>
                <pc-member-id>person-32652080</pc-member-id>
                <pc-member-id>person-32651275</pc-member-id>
                <pc-member-id>person-32633436</pc-member-id>
                <pc-member-id>person-32278102</pc-member-id>
                <pc-member-id>person-32651938</pc-member-id>
                <pc-member-id>person-32649897</pc-member-id>
                <pc-member-id>person-49394</pc-member-id>
                <pc-member-id>person-32650599</pc-member-id>
                <pc-member-id>person-32650571</pc-member-id>
                <pc-member-id>person-32651419</pc-member-id>
                <pc-member-id>person-46964</pc-member-id>
                <pc-member-id>person-47138</pc-member-id>
                <pc-member-id>person-32651088</pc-member-id>
                <pc-member-id>person-32650634</pc-member-id>
                <pc-member-id>person-32580152</pc-member-id>
                <pc-member-id>person-49485</pc-member-id>
                <pc-member-id>person-46673</pc-member-id>
                <pc-member-id>person-48693</pc-member-id>
                <pc-member-id>person-46851</pc-member-id>
                <pc-member-id>person-59412</pc-member-id>
                <pc-member-id>person-32651976</pc-member-id>
                <pc-member-id>person-81561</pc-member-id>
                <pc-member-id>person-46134</pc-member-id>
                <pc-member-id>person-32306808</pc-member-id>
                <pc-member-id>person-46093</pc-member-id>
                <pc-member-id>person-45536</pc-member-id>
                <pc-member-id>person-45115</pc-member-id>
                <pc-member-id>person-32235225</pc-member-id>
                <pc-member-id>person-32606978</pc-member-id>
                <pc-member-id>person-32697866</pc-member-id>
                <pc-member-id>person-32658597</pc-member-id>
                <pc-member-id>person-46021</pc-member-id>
                <pc-member-id>person-32649636</pc-member-id>
                <pc-member-id>person-32653512</pc-member-id>
                <pc-member-id>person-47052</pc-member-id>
                <pc-member-id>person-91060</pc-member-id>
                <pc-member-id>person-32652226</pc-member-id>
                <pc-member-id>person-32598843</pc-member-id>
                <pc-member-id>person-32651889</pc-member-id>
                <pc-member-id>person-32268904</pc-member-id>
                <pc-member-id>person-32681937</pc-member-id>
                <pc-member-id>person-32760</pc-member-id>
                <pc-member-id>person-50804</pc-member-id>
                <pc-member-id>person-32660075</pc-member-id>
                <pc-member-id>person-47136</pc-member-id>
                <pc-member-id>person-32653710</pc-member-id>
                <pc-member-id>person-32650848</pc-member-id>
                <pc-member-id>person-32652581</pc-member-id>
            </pc-members>
        </session>
        <session id="session-32919824" inProceedings="proceedings-32919664">
            <name>Cognitive sciences and Neuroscience</name>
            <papers>
                <paper-id>paper-32618075</paper-id>
                <paper-id>paper-32575007</paper-id>
                <paper-id>paper-32600209</paper-id>
                <paper-id>paper-32616603</paper-id>
                <paper-id>paper-32627217</paper-id>
                <paper-id>paper-32631163</paper-id>
                <paper-id>paper-32643976</paper-id>
                <paper-id>paper-32660269</paper-id>
                <paper-id>paper-32663827</paper-id>
                <paper-id>paper-32663947</paper-id>
            </papers>
            <pc-chairs>
                <pc-chair-id>person-45652</pc-chair-id>
                <pc-chair-id>person-32555480</pc-chair-id>
                <pc-chair-id>person-45776</pc-chair-id>
                <pc-chair-id>person-32633436</pc-chair-id>
                <pc-chair-id>person-45536</pc-chair-id>
                <pc-chair-id>person-32760</pc-chair-id>
            </pc-chairs>
            <pc-members>
                <pc-member-id>person-49676</pc-member-id>
                <pc-member-id>person-32250888</pc-member-id>
                <pc-member-id>person-51754</pc-member-id>
                <pc-member-id>person-32652672</pc-member-id>
                <pc-member-id>person-47310</pc-member-id>
                <pc-member-id>person-89382</pc-member-id>
                <pc-member-id>person-32650564</pc-member-id>
                <pc-member-id>person-32551372</pc-member-id>
                <pc-member-id>person-41861</pc-member-id>
                <pc-member-id>person-90477</pc-member-id>
                <pc-member-id>person-32651981</pc-member-id>
                <pc-member-id>person-32650853</pc-member-id>
                <pc-member-id>person-32652277</pc-member-id>
                <pc-member-id>person-32268372</pc-member-id>
                <pc-member-id>person-32657812</pc-member-id>
                <pc-member-id>person-32651709</pc-member-id>
                <pc-member-id>person-32652270</pc-member-id>
                <pc-member-id>person-32277579</pc-member-id>
                <pc-member-id>person-75747</pc-member-id>
                <pc-member-id>person-32652204</pc-member-id>
                <pc-member-id>person-32574873</pc-member-id>
                <pc-member-id>person-32650268</pc-member-id>
                <pc-member-id>person-47184</pc-member-id>
                <pc-member-id>person-32651861</pc-member-id>
                <pc-member-id>person-32651376</pc-member-id>
                <pc-member-id>person-47254</pc-member-id>
                <pc-member-id>person-32598838</pc-member-id>
                <pc-member-id>person-45776</pc-member-id>
                <pc-member-id>person-32649738</pc-member-id>
                <pc-member-id>person-46122</pc-member-id>
                <pc-member-id>person-32235763</pc-member-id>
                <pc-member-id>person-32650411</pc-member-id>
                <pc-member-id>person-32649969</pc-member-id>
                <pc-member-id>person-85050</pc-member-id>
                <pc-member-id>person-49927</pc-member-id>
                <pc-member-id>person-32654058</pc-member-id>
                <pc-member-id>person-24716</pc-member-id>
                <pc-member-id>person-32236453</pc-member-id>
                <pc-member-id>person-32235592</pc-member-id>
                <pc-member-id>person-32652807</pc-member-id>
                <pc-member-id>person-32653499</pc-member-id>
                <pc-member-id>person-47133</pc-member-id>
                <pc-member-id>person-32650240</pc-member-id>
                <pc-member-id>person-40568</pc-member-id>
                <pc-member-id>person-32650367</pc-member-id>
                <pc-member-id>person-46116</pc-member-id>
                <pc-member-id>person-32629057</pc-member-id>
                <pc-member-id>person-48738</pc-member-id>
                <pc-member-id>person-32242673</pc-member-id>
                <pc-member-id>person-32681420</pc-member-id>
                <pc-member-id>person-32235753</pc-member-id>
                <pc-member-id>person-32241085</pc-member-id>
                <pc-member-id>person-32652054</pc-member-id>
                <pc-member-id>person-46023</pc-member-id>
                <pc-member-id>person-32693457</pc-member-id>
                <pc-member-id>person-32652080</pc-member-id>
                <pc-member-id>person-32651275</pc-member-id>
                <pc-member-id>person-32633436</pc-member-id>
                <pc-member-id>person-32278102</pc-member-id>
                <pc-member-id>person-32651938</pc-member-id>
                <pc-member-id>person-32649897</pc-member-id>
                <pc-member-id>person-49394</pc-member-id>
                <pc-member-id>person-32650599</pc-member-id>
                <pc-member-id>person-32650571</pc-member-id>
                <pc-member-id>person-32651419</pc-member-id>
                <pc-member-id>person-46964</pc-member-id>
                <pc-member-id>person-47138</pc-member-id>
                <pc-member-id>person-32651088</pc-member-id>
                <pc-member-id>person-32650634</pc-member-id>
                <pc-member-id>person-32580152</pc-member-id>
                <pc-member-id>person-49485</pc-member-id>
                <pc-member-id>person-46673</pc-member-id>
                <pc-member-id>person-48693</pc-member-id>
                <pc-member-id>person-46851</pc-member-id>
                <pc-member-id>person-59412</pc-member-id>
                <pc-member-id>person-32651976</pc-member-id>
                <pc-member-id>person-81561</pc-member-id>
                <pc-member-id>person-46134</pc-member-id>
                <pc-member-id>person-32306808</pc-member-id>
                <pc-member-id>person-46093</pc-member-id>
                <pc-member-id>person-45536</pc-member-id>
                <pc-member-id>person-45115</pc-member-id>
                <pc-member-id>person-32235225</pc-member-id>
                <pc-member-id>person-32606978</pc-member-id>
                <pc-member-id>person-32697866</pc-member-id>
                <pc-member-id>person-32658597</pc-member-id>
                <pc-member-id>person-46021</pc-member-id>
                <pc-member-id>person-32649636</pc-member-id>
                <pc-member-id>person-32653512</pc-member-id>
                <pc-member-id>person-47052</pc-member-id>
                <pc-member-id>person-91060</pc-member-id>
                <pc-member-id>person-32652226</pc-member-id>
                <pc-member-id>person-32598843</pc-member-id>
                <pc-member-id>person-32651889</pc-member-id>
                <pc-member-id>person-32268904</pc-member-id>
                <pc-member-id>person-32681937</pc-member-id>
                <pc-member-id>person-32760</pc-member-id>
                <pc-member-id>person-50804</pc-member-id>
                <pc-member-id>person-32660075</pc-member-id>
                <pc-member-id>person-47136</pc-member-id>
                <pc-member-id>person-32653710</pc-member-id>
                <pc-member-id>person-32650848</pc-member-id>
                <pc-member-id>person-32652581</pc-member-id>
            </pc-members>
        </session>
        <session id="session-32919825" inProceedings="proceedings-32919664">
            <name>Pattern recognition and classification</name>
            <papers>
                <paper-id>paper-32643655</paper-id>
                <paper-id>paper-32664903</paper-id>
                <paper-id>paper-32616629</paper-id>
                <paper-id>paper-32627025</paper-id>
                <paper-id>paper-32637493</paper-id>
                <paper-id>paper-32644593</paper-id>
                <paper-id>paper-32651510</paper-id>
                <paper-id>paper-32663131</paper-id>
                <paper-id>paper-32664300</paper-id>
                <paper-id>paper-32664726</paper-id>
                <paper-id>paper-32664988</paper-id>
                <paper-id>paper-32588975</paper-id>
                <paper-id>paper-32624356</paper-id>
                <paper-id>paper-32624407</paper-id>
                <paper-id>paper-32643062</paper-id>
            </papers>
            <pc-chairs>
                <pc-chair-id>person-45652</pc-chair-id>
                <pc-chair-id>person-32555480</pc-chair-id>
                <pc-chair-id>person-45776</pc-chair-id>
                <pc-chair-id>person-32633436</pc-chair-id>
                <pc-chair-id>person-45536</pc-chair-id>
                <pc-chair-id>person-32760</pc-chair-id>
            </pc-chairs>
            <pc-members>
                <pc-member-id>person-49676</pc-member-id>
                <pc-member-id>person-32250888</pc-member-id>
                <pc-member-id>person-51754</pc-member-id>
                <pc-member-id>person-32652672</pc-member-id>
                <pc-member-id>person-47310</pc-member-id>
                <pc-member-id>person-89382</pc-member-id>
                <pc-member-id>person-32650564</pc-member-id>
                <pc-member-id>person-32551372</pc-member-id>
                <pc-member-id>person-41861</pc-member-id>
                <pc-member-id>person-90477</pc-member-id>
                <pc-member-id>person-32651981</pc-member-id>
                <pc-member-id>person-32650853</pc-member-id>
                <pc-member-id>person-32652277</pc-member-id>
                <pc-member-id>person-32268372</pc-member-id>
                <pc-member-id>person-32657812</pc-member-id>
                <pc-member-id>person-32651709</pc-member-id>
                <pc-member-id>person-32652270</pc-member-id>
                <pc-member-id>person-32277579</pc-member-id>
                <pc-member-id>person-75747</pc-member-id>
                <pc-member-id>person-32652204</pc-member-id>
                <pc-member-id>person-32574873</pc-member-id>
                <pc-member-id>person-32650268</pc-member-id>
                <pc-member-id>person-47184</pc-member-id>
                <pc-member-id>person-32651861</pc-member-id>
                <pc-member-id>person-32651376</pc-member-id>
                <pc-member-id>person-47254</pc-member-id>
                <pc-member-id>person-32598838</pc-member-id>
                <pc-member-id>person-45776</pc-member-id>
                <pc-member-id>person-32649738</pc-member-id>
                <pc-member-id>person-46122</pc-member-id>
                <pc-member-id>person-32235763</pc-member-id>
                <pc-member-id>person-32650411</pc-member-id>
                <pc-member-id>person-32649969</pc-member-id>
                <pc-member-id>person-85050</pc-member-id>
                <pc-member-id>person-49927</pc-member-id>
                <pc-member-id>person-32654058</pc-member-id>
                <pc-member-id>person-24716</pc-member-id>
                <pc-member-id>person-32236453</pc-member-id>
                <pc-member-id>person-32235592</pc-member-id>
                <pc-member-id>person-32652807</pc-member-id>
                <pc-member-id>person-32653499</pc-member-id>
                <pc-member-id>person-47133</pc-member-id>
                <pc-member-id>person-32650240</pc-member-id>
                <pc-member-id>person-40568</pc-member-id>
                <pc-member-id>person-32650367</pc-member-id>
                <pc-member-id>person-46116</pc-member-id>
                <pc-member-id>person-32629057</pc-member-id>
                <pc-member-id>person-48738</pc-member-id>
                <pc-member-id>person-32242673</pc-member-id>
                <pc-member-id>person-32681420</pc-member-id>
                <pc-member-id>person-32235753</pc-member-id>
                <pc-member-id>person-32241085</pc-member-id>
                <pc-member-id>person-32652054</pc-member-id>
                <pc-member-id>person-46023</pc-member-id>
                <pc-member-id>person-32693457</pc-member-id>
                <pc-member-id>person-32652080</pc-member-id>
                <pc-member-id>person-32651275</pc-member-id>
                <pc-member-id>person-32633436</pc-member-id>
                <pc-member-id>person-32278102</pc-member-id>
                <pc-member-id>person-32651938</pc-member-id>
                <pc-member-id>person-32649897</pc-member-id>
                <pc-member-id>person-49394</pc-member-id>
                <pc-member-id>person-32650599</pc-member-id>
                <pc-member-id>person-32650571</pc-member-id>
                <pc-member-id>person-32651419</pc-member-id>
                <pc-member-id>person-46964</pc-member-id>
                <pc-member-id>person-47138</pc-member-id>
                <pc-member-id>person-32651088</pc-member-id>
                <pc-member-id>person-32650634</pc-member-id>
                <pc-member-id>person-32580152</pc-member-id>
                <pc-member-id>person-49485</pc-member-id>
                <pc-member-id>person-46673</pc-member-id>
                <pc-member-id>person-48693</pc-member-id>
                <pc-member-id>person-46851</pc-member-id>
                <pc-member-id>person-59412</pc-member-id>
                <pc-member-id>person-32651976</pc-member-id>
                <pc-member-id>person-81561</pc-member-id>
                <pc-member-id>person-46134</pc-member-id>
                <pc-member-id>person-32306808</pc-member-id>
                <pc-member-id>person-46093</pc-member-id>
                <pc-member-id>person-45536</pc-member-id>
                <pc-member-id>person-45115</pc-member-id>
                <pc-member-id>person-32235225</pc-member-id>
                <pc-member-id>person-32606978</pc-member-id>
                <pc-member-id>person-32697866</pc-member-id>
                <pc-member-id>person-32658597</pc-member-id>
                <pc-member-id>person-46021</pc-member-id>
                <pc-member-id>person-32649636</pc-member-id>
                <pc-member-id>person-32653512</pc-member-id>
                <pc-member-id>person-47052</pc-member-id>
                <pc-member-id>person-91060</pc-member-id>
                <pc-member-id>person-32652226</pc-member-id>
                <pc-member-id>person-32598843</pc-member-id>
                <pc-member-id>person-32651889</pc-member-id>
                <pc-member-id>person-32268904</pc-member-id>
                <pc-member-id>person-32681937</pc-member-id>
                <pc-member-id>person-32760</pc-member-id>
                <pc-member-id>person-50804</pc-member-id>
                <pc-member-id>person-32660075</pc-member-id>
                <pc-member-id>person-47136</pc-member-id>
                <pc-member-id>person-32653710</pc-member-id>
                <pc-member-id>person-32650848</pc-member-id>
                <pc-member-id>person-32652581</pc-member-id>
            </pc-members>
        </session>
        <session id="session-32919827" inProceedings="proceedings-32919664">
            <name>Neural network applications in control and robotics</name>
            <papers>
                <paper-id>paper-32642131</paper-id>
                <paper-id>paper-32651597</paper-id>
                <paper-id>paper-32664573</paper-id>
                <paper-id>paper-32664491</paper-id>
                <paper-id>paper-32574917</paper-id>
                <paper-id>paper-32615667</paper-id>
                <paper-id>paper-32644858</paper-id>
                <paper-id>paper-32664845</paper-id>
                <paper-id>paper-32613220</paper-id>
                <paper-id>paper-32676609</paper-id>
                <paper-id>paper-32664662</paper-id>
            </papers>
            <pc-chairs>
                <pc-chair-id>person-45652</pc-chair-id>
                <pc-chair-id>person-32555480</pc-chair-id>
                <pc-chair-id>person-45776</pc-chair-id>
                <pc-chair-id>person-32633436</pc-chair-id>
                <pc-chair-id>person-45536</pc-chair-id>
                <pc-chair-id>person-32760</pc-chair-id>
            </pc-chairs>
            <pc-members>
                <pc-member-id>person-49676</pc-member-id>
                <pc-member-id>person-32250888</pc-member-id>
                <pc-member-id>person-51754</pc-member-id>
                <pc-member-id>person-32652672</pc-member-id>
                <pc-member-id>person-47310</pc-member-id>
                <pc-member-id>person-89382</pc-member-id>
                <pc-member-id>person-32650564</pc-member-id>
                <pc-member-id>person-32551372</pc-member-id>
                <pc-member-id>person-41861</pc-member-id>
                <pc-member-id>person-90477</pc-member-id>
                <pc-member-id>person-32651981</pc-member-id>
                <pc-member-id>person-32650853</pc-member-id>
                <pc-member-id>person-32652277</pc-member-id>
                <pc-member-id>person-32268372</pc-member-id>
                <pc-member-id>person-32657812</pc-member-id>
                <pc-member-id>person-32651709</pc-member-id>
                <pc-member-id>person-32652270</pc-member-id>
                <pc-member-id>person-32277579</pc-member-id>
                <pc-member-id>person-75747</pc-member-id>
                <pc-member-id>person-32652204</pc-member-id>
                <pc-member-id>person-32574873</pc-member-id>
                <pc-member-id>person-32650268</pc-member-id>
                <pc-member-id>person-47184</pc-member-id>
                <pc-member-id>person-32651861</pc-member-id>
                <pc-member-id>person-32651376</pc-member-id>
                <pc-member-id>person-47254</pc-member-id>
                <pc-member-id>person-32598838</pc-member-id>
                <pc-member-id>person-45776</pc-member-id>
                <pc-member-id>person-32649738</pc-member-id>
                <pc-member-id>person-46122</pc-member-id>
                <pc-member-id>person-32235763</pc-member-id>
                <pc-member-id>person-32650411</pc-member-id>
                <pc-member-id>person-32649969</pc-member-id>
                <pc-member-id>person-85050</pc-member-id>
                <pc-member-id>person-49927</pc-member-id>
                <pc-member-id>person-32654058</pc-member-id>
                <pc-member-id>person-24716</pc-member-id>
                <pc-member-id>person-32236453</pc-member-id>
                <pc-member-id>person-32235592</pc-member-id>
                <pc-member-id>person-32652807</pc-member-id>
                <pc-member-id>person-32653499</pc-member-id>
                <pc-member-id>person-47133</pc-member-id>
                <pc-member-id>person-32650240</pc-member-id>
                <pc-member-id>person-40568</pc-member-id>
                <pc-member-id>person-32650367</pc-member-id>
                <pc-member-id>person-46116</pc-member-id>
                <pc-member-id>person-32629057</pc-member-id>
                <pc-member-id>person-48738</pc-member-id>
                <pc-member-id>person-32242673</pc-member-id>
                <pc-member-id>person-32681420</pc-member-id>
                <pc-member-id>person-32235753</pc-member-id>
                <pc-member-id>person-32241085</pc-member-id>
                <pc-member-id>person-32652054</pc-member-id>
                <pc-member-id>person-46023</pc-member-id>
                <pc-member-id>person-32693457</pc-member-id>
                <pc-member-id>person-32652080</pc-member-id>
                <pc-member-id>person-32651275</pc-member-id>
                <pc-member-id>person-32633436</pc-member-id>
                <pc-member-id>person-32278102</pc-member-id>
                <pc-member-id>person-32651938</pc-member-id>
                <pc-member-id>person-32649897</pc-member-id>
                <pc-member-id>person-49394</pc-member-id>
                <pc-member-id>person-32650599</pc-member-id>
                <pc-member-id>person-32650571</pc-member-id>
                <pc-member-id>person-32651419</pc-member-id>
                <pc-member-id>person-46964</pc-member-id>
                <pc-member-id>person-47138</pc-member-id>
                <pc-member-id>person-32651088</pc-member-id>
                <pc-member-id>person-32650634</pc-member-id>
                <pc-member-id>person-32580152</pc-member-id>
                <pc-member-id>person-49485</pc-member-id>
                <pc-member-id>person-46673</pc-member-id>
                <pc-member-id>person-48693</pc-member-id>
                <pc-member-id>person-46851</pc-member-id>
                <pc-member-id>person-59412</pc-member-id>
                <pc-member-id>person-32651976</pc-member-id>
                <pc-member-id>person-81561</pc-member-id>
                <pc-member-id>person-46134</pc-member-id>
                <pc-member-id>person-32306808</pc-member-id>
                <pc-member-id>person-46093</pc-member-id>
                <pc-member-id>person-45536</pc-member-id>
                <pc-member-id>person-45115</pc-member-id>
                <pc-member-id>person-32235225</pc-member-id>
                <pc-member-id>person-32606978</pc-member-id>
                <pc-member-id>person-32697866</pc-member-id>
                <pc-member-id>person-32658597</pc-member-id>
                <pc-member-id>person-46021</pc-member-id>
                <pc-member-id>person-32649636</pc-member-id>
                <pc-member-id>person-32653512</pc-member-id>
                <pc-member-id>person-47052</pc-member-id>
                <pc-member-id>person-91060</pc-member-id>
                <pc-member-id>person-32652226</pc-member-id>
                <pc-member-id>person-32598843</pc-member-id>
                <pc-member-id>person-32651889</pc-member-id>
                <pc-member-id>person-32268904</pc-member-id>
                <pc-member-id>person-32681937</pc-member-id>
                <pc-member-id>person-32760</pc-member-id>
                <pc-member-id>person-50804</pc-member-id>
                <pc-member-id>person-32660075</pc-member-id>
                <pc-member-id>person-47136</pc-member-id>
                <pc-member-id>person-32653710</pc-member-id>
                <pc-member-id>person-32650848</pc-member-id>
                <pc-member-id>person-32652581</pc-member-id>
            </pc-members>
        </session>
        <session id="session-32919828" inProceedings="proceedings-32919664">
            <name>Other applications of neural networks</name>
            <papers>
                <paper-id>paper-32593286</paper-id>
                <paper-id>paper-32599616</paper-id>
                <paper-id>paper-32613517</paper-id>
                <paper-id>paper-32623267</paper-id>
                <paper-id>paper-32636421</paper-id>
                <paper-id>paper-32642626</paper-id>
                <paper-id>paper-32643335</paper-id>
                <paper-id>paper-32622184</paper-id>
                <paper-id>paper-32633793</paper-id>
                <paper-id>paper-32613554</paper-id>
                <paper-id>paper-32682930</paper-id>
            </papers>
            <pc-chairs>
                <pc-chair-id>person-45652</pc-chair-id>
                <pc-chair-id>person-32555480</pc-chair-id>
                <pc-chair-id>person-45776</pc-chair-id>
                <pc-chair-id>person-32633436</pc-chair-id>
                <pc-chair-id>person-45536</pc-chair-id>
                <pc-chair-id>person-32760</pc-chair-id>
            </pc-chairs>
            <pc-members>
                <pc-member-id>person-49676</pc-member-id>
                <pc-member-id>person-32250888</pc-member-id>
                <pc-member-id>person-51754</pc-member-id>
                <pc-member-id>person-32652672</pc-member-id>
                <pc-member-id>person-47310</pc-member-id>
                <pc-member-id>person-89382</pc-member-id>
                <pc-member-id>person-32650564</pc-member-id>
                <pc-member-id>person-32551372</pc-member-id>
                <pc-member-id>person-41861</pc-member-id>
                <pc-member-id>person-90477</pc-member-id>
                <pc-member-id>person-32651981</pc-member-id>
                <pc-member-id>person-32650853</pc-member-id>
                <pc-member-id>person-32652277</pc-member-id>
                <pc-member-id>person-32268372</pc-member-id>
                <pc-member-id>person-32657812</pc-member-id>
                <pc-member-id>person-32651709</pc-member-id>
                <pc-member-id>person-32652270</pc-member-id>
                <pc-member-id>person-32277579</pc-member-id>
                <pc-member-id>person-75747</pc-member-id>
                <pc-member-id>person-32652204</pc-member-id>
                <pc-member-id>person-32574873</pc-member-id>
                <pc-member-id>person-32650268</pc-member-id>
                <pc-member-id>person-47184</pc-member-id>
                <pc-member-id>person-32651861</pc-member-id>
                <pc-member-id>person-32651376</pc-member-id>
                <pc-member-id>person-47254</pc-member-id>
                <pc-member-id>person-32598838</pc-member-id>
                <pc-member-id>person-45776</pc-member-id>
                <pc-member-id>person-32649738</pc-member-id>
                <pc-member-id>person-46122</pc-member-id>
                <pc-member-id>person-32235763</pc-member-id>
                <pc-member-id>person-32650411</pc-member-id>
                <pc-member-id>person-32649969</pc-member-id>
                <pc-member-id>person-85050</pc-member-id>
                <pc-member-id>person-49927</pc-member-id>
                <pc-member-id>person-32654058</pc-member-id>
                <pc-member-id>person-24716</pc-member-id>
                <pc-member-id>person-32236453</pc-member-id>
                <pc-member-id>person-32235592</pc-member-id>
                <pc-member-id>person-32652807</pc-member-id>
                <pc-member-id>person-32653499</pc-member-id>
                <pc-member-id>person-47133</pc-member-id>
                <pc-member-id>person-32650240</pc-member-id>
                <pc-member-id>person-40568</pc-member-id>
                <pc-member-id>person-32650367</pc-member-id>
                <pc-member-id>person-46116</pc-member-id>
                <pc-member-id>person-32629057</pc-member-id>
                <pc-member-id>person-48738</pc-member-id>
                <pc-member-id>person-32242673</pc-member-id>
                <pc-member-id>person-32681420</pc-member-id>
                <pc-member-id>person-32235753</pc-member-id>
                <pc-member-id>person-32241085</pc-member-id>
                <pc-member-id>person-32652054</pc-member-id>
                <pc-member-id>person-46023</pc-member-id>
                <pc-member-id>person-32693457</pc-member-id>
                <pc-member-id>person-32652080</pc-member-id>
                <pc-member-id>person-32651275</pc-member-id>
                <pc-member-id>person-32633436</pc-member-id>
                <pc-member-id>person-32278102</pc-member-id>
                <pc-member-id>person-32651938</pc-member-id>
                <pc-member-id>person-32649897</pc-member-id>
                <pc-member-id>person-49394</pc-member-id>
                <pc-member-id>person-32650599</pc-member-id>
                <pc-member-id>person-32650571</pc-member-id>
                <pc-member-id>person-32651419</pc-member-id>
                <pc-member-id>person-46964</pc-member-id>
                <pc-member-id>person-47138</pc-member-id>
                <pc-member-id>person-32651088</pc-member-id>
                <pc-member-id>person-32650634</pc-member-id>
                <pc-member-id>person-32580152</pc-member-id>
                <pc-member-id>person-49485</pc-member-id>
                <pc-member-id>person-46673</pc-member-id>
                <pc-member-id>person-48693</pc-member-id>
                <pc-member-id>person-46851</pc-member-id>
                <pc-member-id>person-59412</pc-member-id>
                <pc-member-id>person-32651976</pc-member-id>
                <pc-member-id>person-81561</pc-member-id>
                <pc-member-id>person-46134</pc-member-id>
                <pc-member-id>person-32306808</pc-member-id>
                <pc-member-id>person-46093</pc-member-id>
                <pc-member-id>person-45536</pc-member-id>
                <pc-member-id>person-45115</pc-member-id>
                <pc-member-id>person-32235225</pc-member-id>
                <pc-member-id>person-32606978</pc-member-id>
                <pc-member-id>person-32697866</pc-member-id>
                <pc-member-id>person-32658597</pc-member-id>
                <pc-member-id>person-46021</pc-member-id>
                <pc-member-id>person-32649636</pc-member-id>
                <pc-member-id>person-32653512</pc-member-id>
                <pc-member-id>person-47052</pc-member-id>
                <pc-member-id>person-91060</pc-member-id>
                <pc-member-id>person-32652226</pc-member-id>
                <pc-member-id>person-32598843</pc-member-id>
                <pc-member-id>person-32651889</pc-member-id>
                <pc-member-id>person-32268904</pc-member-id>
                <pc-member-id>person-32681937</pc-member-id>
                <pc-member-id>person-32760</pc-member-id>
                <pc-member-id>person-50804</pc-member-id>
                <pc-member-id>person-32660075</pc-member-id>
                <pc-member-id>person-47136</pc-member-id>
                <pc-member-id>person-32653710</pc-member-id>
                <pc-member-id>person-32650848</pc-member-id>
                <pc-member-id>person-32652581</pc-member-id>
            </pc-members>
        </session>
    </sessions>
    <persons>
        <person id="person-49676">
            <firstname>Giancarlo</firstname>
            <lastname>La Camera</lastname>
            <country>United States</country>
            <organization-id>suny-stony-brook</organization-id>
            <email>Giancarlo.LaCamera@stonybrook.edu</email>
        </person>
        <person id="person-32250888">
            <firstname>Alfredo</firstname>
            <lastname>Petrosino</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>alfredo.petrosino@uniparthenope.it</email>
        </person>
        <person id="person-51754">
            <firstname>Yaochu</firstname>
            <lastname>Jin</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>yaochu.jin@surrey.ac.uk</email>
        </person>
        <person id="person-32652672">
            <firstname>Alessio</firstname>
            <lastname>Micheli</lastname>
            <country>Italy</country>
            <organization-id>universita-di-pisa</organization-id>
            <email>micheli@di.unipi.it</email>
        </person>
        <person id="person-47310">
            <firstname>Stefan</firstname>
            <lastname>Wermter</lastname>
            <organization-id>university-of-hamburg</organization-id>
            <email>wermter@informatik.uni-hamburg.de</email>
        </person>
        <person id="person-89382">
            <firstname>Stefan</firstname>
            <lastname>Heinrich</lastname>
            <country>Germany</country>
            <organization-id>universitt-hamburg</organization-id>
            <email>heinrich@informatik.uni-hamburg.de</email>
        </person>
        <person id="person-32650564">
            <firstname>Ulysses</firstname>
            <lastname>Bernardet</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>bernuly@gmail.com</email>
        </person>
        <person id="person-32551372">
            <firstname>Marcello</firstname>
            <lastname>Sanguineti</lastname>
            <country>Italy</country>
            <organization-id>university-of-genova</organization-id>
            <email>marcello.sanguineti@unige.it</email>
        </person>
        <person id="person-41861">
            <firstname>Lazaros</firstname>
            <lastname>Iliadis</lastname>
            <country>Greece</country>
            <organization-id>democritus-university-of-thrace</organization-id>
            <email>liliadis@fmenr.duth.gr</email>
        </person>
        <person id="person-90477">
            <firstname>Jorg</firstname>
            <lastname>Conradt</lastname>
            <country>Germany</country>
            <organization-id>tu-mnchen</organization-id>
            <email>conradt@tum.de</email>
        </person>
        <person id="person-32651981">
            <firstname>Carmen</firstname>
            <lastname>Vidaurre</lastname>
            <country>Germany</country>
            <organization-id>berlin-institute-of-technology</organization-id>
            <email>carmen.vidaurre@tu-berlin.de</email>
        </person>
        <person id="person-32650853">
            <firstname>Novi</firstname>
            <lastname>Quadrianto</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>novi.quadrianto@gmail.com</email>
        </person>
        <person id="person-45652">
            <firstname>bruno</firstname>
            <lastname>apolloni</lastname>
            <country>Italy</country>
            <organization-id>university-of-milano</organization-id>
            <email>apolloni@dsi.unimi.it</email>
        </person>
        <person id="person-32652277">
            <firstname>Francesco</firstname>
            <lastname>Marcelloni</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>f.marcelloni@iet.unipi.it</email>
        </person>
        <person id="person-32268372">
            <firstname>Jim</firstname>
            <lastname>Austin</lastname>
            <country>United Kingdom</country>
            <organization-id>university-of-york</organization-id>
            <email>austin@cs.york.ac.uk</email>
        </person>
        <person id="person-32657812">
            <firstname>Sebastian</firstname>
            <lastname>Pannasch</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>pannasch@psychologie.tu-dresden.de</email>
        </person>
        <person id="person-32651709">
            <firstname>Mathew</firstname>
            <lastname>Magimai Doss</lastname>
            <country>Switzerland</country>
            <organization-id>idiap-research-institute</organization-id>
            <email>mathew@idiap.ch</email>
        </person>
        <person id="person-32652270">
            <firstname>Tetsuro</firstname>
            <lastname>Morimura</lastname>
            <country>Japan</country>
            <organization-id>ibm</organization-id>
            <email>tetsuro@jp.ibm.com</email>
        </person>
        <person id="person-32277579">
            <firstname>Thomas</firstname>
            <lastname>Martinetz</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>martinetz@inb.uni-luebeck.de</email>
        </person>
        <person id="person-75747">
            <firstname>Eleni</firstname>
            <lastname>Vasilaki</lastname>
            <country>United Kingdom</country>
            <organization-id>university-of-sheffield</organization-id>
            <email>e.vasilaki@sheffield.ac.uk</email>
            <email>e.vasilaki@gmail.com</email>
        </person>
        <person id="person-32652204">
            <firstname>Johan</firstname>
            <lastname>Suykens</lastname>
            <country>Belgium</country>
            <organization-id>ku-leuven</organization-id>
            <email>Johan.Suykens@esat.kuleuven.be</email>
        </person>
        <person id="person-32555480">
            <firstname>Valeri</firstname>
            <lastname>Mladenov</lastname>
            <country>Bulgaria</country>
            <organization-id>technical-university-sofia</organization-id>
            <email>valeri.m.mladenov@gmail.com</email>
        </person>
        <person id="person-32574873">
            <firstname>Petia</firstname>
            <lastname>Georgieva</lastname>
            <country>Portugal</country>
            <organization-id>university-of-aveiro</organization-id>
            <email>petia@ua.pt</email>
        </person>
        <person id="person-32650268">
            <firstname>Tom</firstname>
            <lastname>Heskes</lastname>
            <country>Netherlands</country>
            <organization-id>no-organization-present</organization-id>
            <email>t.heskes@science.ru.nl</email>
        </person>
        <person id="person-47184">
            <firstname>Stefanos</firstname>
            <lastname>Kollias</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>stefanos@cs.ntua.gr</email>
        </person>
        <person id="person-32651861">
            <firstname>Tonatiuh</firstname>
            <lastname>Pena Centeno</lastname>
            <country>Germany</country>
            <organization-id>universitt-greifswald</organization-id>
            <email>tonatiuh.pena.centeno@gmail.com</email>
            <email>tonatiuh.penacenteno@uni-greifswald.de</email>
        </person>
        <person id="person-32651376">
            <firstname>Charis</firstname>
            <lastname>Papadopoulos</lastname>
            <country>Greece</country>
            <organization-id>university-of-ioannina</organization-id>
            <email>charis@cs.uoi.gr</email>
        </person>
        <person id="person-47254">
            <firstname>Lubica</firstname>
            <lastname>Benuskova</lastname>
            <country>New Zealand</country>
            <organization-id>university-of-otago</organization-id>
            <email>lubica@cs.otago.ac.nz</email>
        </person>
        <person id="person-32598838">
            <firstname>Mauricio</firstname>
            <lastname>Alvarez</lastname>
            <country>Colombia</country>
            <organization-id>no-organization-present</organization-id>
            <email>malvarez@utp.edu.co</email>
        </person>
        <person id="person-45776">
            <firstname>Guenther</firstname>
            <lastname>Palm</lastname>
            <country>Germany</country>
            <organization-id>ulm-university</organization-id>
            <email>guenther.palm@uni-ulm.de</email>
        </person>
        <person id="person-32649738">
            <firstname>Giorgio</firstname>
            <lastname>Gnecco</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>giorgio.gnecco@dist.unige.it</email>
        </person>
        <person id="person-46122">
            <firstname>Claudio</firstname>
            <lastname>Mirasso</lastname>
            <country>Spain</country>
            <organization-id>institute-for-cross-disciplinary-physics-and-complex-systems</organization-id>
            <email>claudio@ifisc.uib-csic.es</email>
        </person>
        <person id="person-32235763">
            <firstname>Alessandro</firstname>
            <lastname>Di Nuovo</lastname>
            <country>United Kingdom</country>
            <organization-id>plymouth-university</organization-id>
            <email>Alessandro.dinuovo@plymouth.ac.uk</email>
        </person>
        <person id="person-32650411">
            <firstname>Vincenzo</firstname>
            <lastname>Piuri</lastname>
            <country>Italy</country>
            <organization-id>university-of-milan</organization-id>
            <email>vincenzo.piuri@unimi.it</email>
        </person>
        <person id="person-32649969">
            <firstname>Erol</firstname>
            <lastname>Gelenbe</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>e.gelenbe@imperial.ac.uk</email>
        </person>
        <person id="person-85050">
            <firstname>Roman</firstname>
            <lastname>Neruda</lastname>
            <country>Czech Republic</country>
            <organization-id>institute-of-computer-science-ascr</organization-id>
            <email>roman@cs.cas.cz</email>
        </person>
        <person id="person-49927">
            <firstname>Mario</firstname>
            <lastname>Koeppen</lastname>
            <country>Japan</country>
            <organization-id>kyushu-institute-of-technology</organization-id>
            <email>mkoeppen@ieee.org</email>
            <email>mario.koeppen@gmail.com</email>
        </person>
        <person id="person-32654058">
            <firstname>Shinji</firstname>
            <lastname>Watanabe</lastname>
            <country>Japan</country>
            <organization-id>merl</organization-id>
            <email>watanabe@merl.com</email>
        </person>
        <person id="person-24716">
            <firstname>Aristidis</firstname>
            <lastname>Likas</lastname>
            <organization-id>university-of-ioannina</organization-id>
            <email>arly@cs.uoi.gr</email>
        </person>
        <person id="person-32236453">
            <firstname>Giorgio</firstname>
            <lastname>Valentini</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>valentini@di.unimi.it</email>
        </person>
        <person id="person-32235592">
            <firstname>Francesco</firstname>
            <lastname>Camastra</lastname>
            <country>Italy</country>
            <organization-id>university-of-naples-parthenope</organization-id>
            <email>francesco.camastra@uniparthenope.it</email>
        </person>
        <person id="person-32652807">
            <firstname>Sohan</firstname>
            <lastname>Seth</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>Sohan.seth@hiit.fi</email>
        </person>
        <person id="person-32653499">
            <firstname>Dietrich</firstname>
            <lastname>Klakow</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>dietrich.klakow@lsv.uni-saarland.de</email>
        </person>
        <person id="person-47133">
            <firstname>Jose</firstname>
            <lastname>Nunez-Yanez</lastname>
            <country>United Kingdom</country>
            <organization-id>university-of-bristol</organization-id>
            <email>J.L.Nunez-Yanez@bristol.ac.uk</email>
        </person>
        <person id="person-32650240">
            <firstname>Amir</firstname>
            <lastname>Hussain</lastname>
            <country>United Kingdom</country>
            <organization-id>university-of-stirling</organization-id>
            <email>ahu@cs.stir.ac.uk</email>
        </person>
        <person id="person-40568">
            <firstname>Anastasios</firstname>
            <lastname>Tefas</lastname>
            <country>Greece</country>
            <organization-id>no-organization-present</organization-id>
            <email>tefas@aiia.csd.auth.gr</email>
        </person>
        <person id="person-32650367">
            <firstname>Benoit</firstname>
            <lastname>Scherrer</lastname>
            <country>United States</country>
            <organization-id>harvard-medical-school</organization-id>
            <email>benoit.scherrer@childrens.harvard.edu</email>
        </person>
        <person id="person-46116">
            <firstname>Ke</firstname>
            <lastname>Chen</lastname>
            <country>United Kingdom</country>
            <organization-id>university-of-manchester</organization-id>
            <email>Ke.Chen@manchester.ac.uk</email>
            <email>chen@cs.manchester.ac.uk</email>
        </person>
        <person id="person-32629057">
            <firstname>Hiroshi</firstname>
            <lastname>Shimodaira</lastname>
            <country>United Kingdom</country>
            <organization-id>university-of-edinburgh</organization-id>
            <email>h.shimodaira@ed.ac.uk</email>
        </person>
        <person id="person-48738">
            <firstname>Jaakko</firstname>
            <lastname>Peltonen</lastname>
            <country>Finland</country>
            <organization-id>aalto-university</organization-id>
            <email>Jaakko.Peltonen@aalto.fi</email>
        </person>
        <person id="person-32242673">
            <firstname>ramin</firstname>
            <lastname>pichevar</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>ramin.pichevar@usherbrooke.ca</email>
        </person>
        <person id="person-32681420">
            <firstname>Thomas</firstname>
            <lastname>Wennekers</lastname>
            <country>United Kingdom</country>
            <organization-id>plymouth-university</organization-id>
            <email>thomas.wennekers@plymouth.ac.uk</email>
        </person>
        <person id="person-32235753">
            <firstname>Marina</firstname>
            <lastname>Resta</lastname>
            <country>Italy</country>
            <organization-id>university-of-genova</organization-id>
            <email>mresta@unige.it</email>
        </person>
        <person id="person-32241085">
            <firstname>Maurizio</firstname>
            <lastname>Filippone</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>Maurizio.Filippone@glasgow.ac.uk</email>
        </person>
        <person id="person-32652054">
            <firstname>Jan</firstname>
            <lastname>Drugowitsch</lastname>
            <country>France</country>
            <organization-id>ecole-normale-superieure</organization-id>
            <email>jdrugo@gmail.com</email>
        </person>
        <person id="person-46023">
            <firstname>Michele</firstname>
            <lastname>Giugliano</lastname>
            <country>Belgium</country>
            <organization-id>university-of-antwerpen</organization-id>
            <email>Michele.Giugliano@ua.ac.be</email>
        </person>
        <person id="person-32693457">
            <firstname>Gregor</firstname>
            <lastname>Schöner</lastname>
            <country>Germany</country>
            <organization-id>ruhr-universitt-bochum</organization-id>
            <email>gregor.schoener@ini.ruhr-uni-bochum.de</email>
        </person>
        <person id="person-32652080">
            <firstname>Heiko</firstname>
            <lastname>Wersing</lastname>
            <country>Germany</country>
            <organization-id>honda-research-institute-europe</organization-id>
            <email>Heiko.wersing@honda-ri.de</email>
        </person>
        <person id="person-32651275">
            <firstname>Tobias</firstname>
            <lastname>Glasmachers</lastname>
            <country>Germany</country>
            <organization-id>ruhr-universitt-bochum</organization-id>
            <email>tobias.glasmachers@ini.rub.de</email>
        </person>
        <person id="person-32633436">
            <firstname>Bruno</firstname>
            <lastname>Apolloni</lastname>
            <country>Italy</country>
            <organization-id>university-of-milan</organization-id>
            <email>apolloni@di.unimi.it</email>
        </person>
        <person id="person-32278102">
            <firstname>Andre</firstname>
            <lastname>Gruning</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>a.gruning@surrey.ac.uk</email>
        </person>
        <person id="person-32651938">
            <firstname>Vassilios</firstname>
            <lastname>Verykios</lastname>
            <country>Greece</country>
            <organization-id>hellenic-open-university</organization-id>
            <email>verykios@inf.uth.gr</email>
        </person>
        <person id="person-32649897">
            <firstname>Igor</firstname>
            <lastname>Farkas</lastname>
            <country>Slovakia</country>
            <organization-id>comenius-university-in-bratislava</organization-id>
            <email>farkas@fmph.uniba.sk</email>
        </person>
        <person id="person-49394">
            <firstname>Péter</firstname>
            <lastname>Érdi</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>perdi@kzoo.edu</email>
        </person>
        <person id="person-32650599">
            <firstname>Kazushi</firstname>
            <lastname>Mimura</lastname>
            <country>Japan</country>
            <organization-id>hiroshima-city-university</organization-id>
            <email>mimura@hiroshima-cu.ac.jp</email>
        </person>
        <person id="person-32650571">
            <firstname>bjoern</firstname>
            <lastname>menze</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>menze@vision.ee.ethz.ch</email>
        </person>
        <person id="person-32651419">
            <firstname>Ivo</firstname>
            <lastname>Bukovsky</lastname>
            <country>Czech Republic</country>
            <organization-id>czech-technical-university-in-prague</organization-id>
            <email>Ivo.Bukovsky@fs.cvut.cz</email>
        </person>
        <person id="person-46964">
            <firstname>Teresa</firstname>
            <lastname>Ludermir</lastname>
            <country>Brazil</country>
            <organization-id>federal-university-of-pernambuco</organization-id>
            <email>tbl@cin.ufpe.br</email>
        </person>
        <person id="person-47138">
            <firstname>Vera</firstname>
            <lastname>Kurkova</lastname>
            <country>Czech Republic</country>
            <organization-id>institute-of-computer-science-academy-of-sciences-of-the-czech-republic</organization-id>
            <email>vera@cs.cas.cz</email>
        </person>
        <person id="person-32651088">
            <firstname>Zhiyuan</firstname>
            <lastname>Luo</lastname>
            <country>United Kingdom</country>
            <organization-id>royal-holloway-university-of-london</organization-id>
            <email>Zhiyuan.Luo@cs.rhul.ac.uk</email>
        </person>
        <person id="person-32650634">
            <firstname>Ali</firstname>
            <lastname>Minai</lastname>
            <country>United States</country>
            <organization-id>university-of-cincinnati</organization-id>
            <email>ali.minai@uc.edu</email>
        </person>
        <person id="person-32580152">
            <firstname>Zeng-Guang</firstname>
            <lastname>Hou</lastname>
            <country>China</country>
            <organization-id>no-organization-present</organization-id>
            <email>hou@compsys.ia.ac.cn</email>
        </person>
        <person id="person-49485">
            <firstname>Giacomo</firstname>
            <lastname>Indiveri</lastname>
            <country>Switzerland</country>
            <organization-id>university-of-zurich-and-eth-zurich</organization-id>
            <email>giacomo@ini.phys.ethz.ch</email>
        </person>
        <person id="person-46673">
            <firstname>Jordi</firstname>
            <lastname>Garcia-Ojalvo</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>jordi.g.ojalvo@upc.edu</email>
        </person>
        <person id="person-48693">
            <firstname>Francesco</firstname>
            <lastname>Masulli</lastname>
            <country>Italy</country>
            <organization-id>university-of-genova</organization-id>
            <email>francesco.masulli@unige.it</email>
        </person>
        <person id="person-46851">
            <firstname>Yoshiyuki</firstname>
            <lastname>Asai</lastname>
            <country>Japan</country>
            <organization-id>okinawa-institute-of-science-and-technology-graduate-university</organization-id>
            <email>yoshiyuki.asai@oist.jp</email>
        </person>
        <person id="person-59412">
            <firstname>Diego</firstname>
            <lastname>Liberati</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>liberati@elet.polimi.it</email>
        </person>
        <person id="person-32651976">
            <firstname>Nathalie</firstname>
            <lastname>Villa-Vialaneix</lastname>
            <country>France</country>
            <organization-id>universit-paris-</organization-id>
            <email>nathalie.villa@toulouse.inra.fr</email>
        </person>
        <person id="person-81561">
            <firstname>Zhirong</firstname>
            <lastname>Yang</lastname>
            <country>Finland</country>
            <organization-id>aalto-university</organization-id>
            <email>zhirong.yang@aalto.fi</email>
        </person>
        <person id="person-46134">
            <firstname>Roseli</firstname>
            <lastname>Wedemann</lastname>
            <country>Brazil</country>
            <organization-id>universidade-do-estado-do-rio-de-janeiro</organization-id>
            <email>rose.wedemann@gmail.com</email>
        </person>
        <person id="person-32306808">
            <firstname>Manuel</firstname>
            <lastname>Roveri</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>roveri@elet.polimi.it</email>
        </person>
        <person id="person-46093">
            <firstname>Alessandro</firstname>
            <lastname>Sperduti</lastname>
            <country>Italy</country>
            <organization-id>university-of-padova</organization-id>
            <email>sperduti@math.unipd.it</email>
        </person>
        <person id="person-45536">
            <firstname>Petia</firstname>
            <lastname>Koprinkova-Hristova</lastname>
            <country>Bulgaria</country>
            <organization-id>iict---bas</organization-id>
            <email>pkoprinkova@yahoo.com</email>
            <email>pkoprinkova@bas.bg</email>
        </person>
        <person id="person-45115">
            <firstname>Timo</firstname>
            <lastname>Honkela</lastname>
            <country>Finland</country>
            <organization-id>aalto-university</organization-id>
            <email>timo.honkela@tkk.fi</email>
            <email>timo.honkela@aalto.fi</email>
        </person>
        <person id="person-32235225">
            <firstname>Alessandro</firstname>
            <lastname>Rozza</lastname>
            <organization-id>universit-degli-studi-di-napoli</organization-id>
            <email>rozza@di.unimi.it</email>
        </person>
        <person id="person-32606978">
            <firstname>Luís</firstname>
            <lastname>Alexandre</lastname>
            <country>Portugal</country>
            <organization-id>ubi---univ-beira-interior</organization-id>
            <email>luis.Alexandre@ubi.pt</email>
        </person>
        <person id="person-32697866">
            <firstname>Heiko</firstname>
            <lastname>Neumann</lastname>
            <country>Germany</country>
            <organization-id>university-of-ulm</organization-id>
            <email>heiko.neumann@uni-ulm.de</email>
        </person>
        <person id="person-32658597">
            <firstname>Juha</firstname>
            <lastname>Karhunen</lastname>
            <country>Finland</country>
            <organization-id>aalto-university</organization-id>
            <email>juha.karhunen@aalto.fi</email>
        </person>
        <person id="person-46021">
            <firstname>Jorge</firstname>
            <lastname>Santos</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>jms@isep.ipp.pt</email>
        </person>
        <person id="person-32649636">
            <firstname>Pablo</firstname>
            <lastname>Estevez</lastname>
            <country>Chile</country>
            <organization-id>university-of-chile</organization-id>
            <email>pestevez@ing.uchile.cl</email>
        </person>
        <person id="person-32653512">
            <firstname>Shinichi</firstname>
            <lastname>Nakajima</lastname>
            <country>Japan</country>
            <organization-id>nikon-corporation</organization-id>
            <email>nakajima.s@nikon.co.jp</email>
        </person>
        <person id="person-47052">
            <firstname>Irena</firstname>
            <lastname>Koprinska</lastname>
            <country>Australia</country>
            <organization-id>university-of-sydney</organization-id>
            <email>irena@it.usyd.edu.au</email>
        </person>
        <person id="person-91060">
            <firstname>Mantas</firstname>
            <lastname>Lukoševičius</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>m.lukosevicius@jacobs-university.de</email>
            <email>mantas.lukosevicius@gmx.com</email>
        </person>
        <person id="person-32652226">
            <firstname>Mauro</firstname>
            <lastname>Gaggero</lastname>
            <country>Italy</country>
            <organization-id>national-research-council-of-italy</organization-id>
            <email>mauro.gaggero@gmail.com</email>
        </person>
        <person id="person-32598843">
            <firstname>Tanel</firstname>
            <lastname>Alumäe</lastname>
            <organization-id>tallinn-university-of-technology</organization-id>
            <email>tanel.alumae@phon.ioc.ee</email>
        </person>
        <person id="person-32651889">
            <firstname>Athanasios</firstname>
            <lastname>Tsadiras</lastname>
            <country>Greece</country>
            <organization-id>aristotle-university-of-thessaloniki</organization-id>
            <email>tsadiras@econ.auth.gr</email>
        </person>
        <person id="person-32268904">
            <firstname>Friedhelm</firstname>
            <lastname>Schwenker</lastname>
            <organization-id>university-of-ulm</organization-id>
            <email>friedhelm.schwenker@uni-ulm.de</email>
        </person>
        <person id="person-32681937">
            <firstname>George</firstname>
            <lastname>Mengov</lastname>
            <country>Bulgaria</country>
            <organization-id>sofia-university</organization-id>
            <email>g.mengov@feb.uni-sofia.bg</email>
        </person>
        <person id="person-32760">
            <firstname>Alessandro</firstname>
            <lastname>Villa</lastname>
            <country>Switzerland</country>
            <organization-id>university-of-lausanne</organization-id>
            <email>Alessandro.Villa@unil.ch</email>
            <email>avilla@neuroheuristic.org</email>
            <email>G.Bugmann@plymouth.ac.uk</email>
        </person>
        <person id="person-50804">
            <firstname>Angelo</firstname>
            <lastname>Cangelosi</lastname>
            <country>United Kingdom</country>
            <organization-id>plymouth-university</organization-id>
            <email>A.Cangelosi@plymouth.ac.uk</email>
        </person>
        <person id="person-32660075">
            <firstname>Achim</firstname>
            <lastname>Rettinger</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>rettinger@kit.edu</email>
        </person>
        <person id="person-47136">
            <firstname>Barbara</firstname>
            <lastname>Hammer</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>hammer@in.tu-clausthal.de</email>
        </person>
        <person id="person-32653710">
            <firstname>Fabrice</firstname>
            <lastname>Rossi</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>Fabrice.Rossi@apiacoa.org</email>
        </person>
        <person id="person-32650848">
            <firstname>Lan</firstname>
            <lastname>Du</lastname>
            <country>Australia</country>
            <organization-id>macquarie-university</organization-id>
            <email>dulan520@gmail.com</email>
        </person>
        <person id="person-32652581">
            <firstname>Shanfeng</firstname>
            <lastname>Zhu</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>zhusf@fudan.edu.cn</email>
        </person>
        <person id="person-32584453">
            <firstname>Botond Attila</firstname>
            <lastname>Bócsi</lastname>
            <country>Romania</country>
            <organization-id>babes-bolyai-university</organization-id>
            <email>bocsiboti@gmail.com</email>
        </person>
        <person id="person-32844371">
            <firstname>Lehel</firstname>
            <lastname>Csato</lastname>
            <country>Romania</country>
            <organization-id>babes-bolyai-university</organization-id>
            <email>lehel.csato@cs.ubbcluj.ro</email>
        </person>
        <person id="person-32608556">
            <firstname>Hani</firstname>
            <lastname>EL ASSAAD</lastname>
            <country>France</country>
            <organization-id>ifsttar</organization-id>
            <email>hani.el-assaad@ifsttar.fr</email>
        </person>
        <person id="person-32608589">
            <firstname>Allou</firstname>
            <lastname>Samé</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>allou.same@ifsttar.fr</email>
        </person>
        <person id="person-32608593">
            <firstname>Gérard</firstname>
            <lastname>Govaert</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>gerard.govaert@utc.fr</email>
        </person>
        <person id="person-32608591">
            <firstname>Patrice</firstname>
            <lastname>Aknin</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>patrice.aknin@ifsttar.fr</email>
        </person>
        <person id="person-32612536">
            <firstname>Yuya</firstname>
            <lastname>Okadome</lastname>
            <country>Japan</country>
            <organization-id>osaka-university</organization-id>
            <email>okadome.yuya@irl.sys.es.osaka-u.ac.jp</email>
        </person>
        <person id="person-32821827">
            <firstname>Yutaka</firstname>
            <lastname>Nakamura</lastname>
            <country>Japan</country>
            <organization-id>osaka-university</organization-id>
            <email>nakamura@irl.sys.es.osaka-u.ac.jp</email>
        </person>
        <person id="person-32821172">
            <firstname>Yumi</firstname>
            <lastname>Shikauchi</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>yumi-s@sys.i.kyoto-u.ac.jp</email>
        </person>
        <person id="person-91428">
            <firstname>Shin</firstname>
            <lastname>Ishii</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>ishii@i.kyoto-u.ac.jp</email>
        </person>
        <person id="person-32612543">
            <firstname>Hiroshi</firstname>
            <lastname>Ishiguro</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>ishiguro@sys.es.osaka-u.ac.jp</email>
        </person>
        <person id="person-32613328">
            <firstname>Johannes</firstname>
            <lastname>Schumacher</lastname>
            <country>Germany</country>
            <organization-id>insitute-of-cognitive-science-university-of-osnabrueck</organization-id>
            <email>joschuma@uos.de</email>
        </person>
        <person id="person-32816458">
            <firstname>Hazem</firstname>
            <lastname>Toutounji</lastname>
            <country>Germany</country>
            <organization-id>university-of-osnabrck</organization-id>
            <email>hazem.eq.toutounji@gmail.com</email>
            <email>htoutounji@uos.de</email>
        </person>
        <person id="person-50617">
            <firstname>Gordon</firstname>
            <lastname>Pipa</lastname>
            <organization-id>institute-of-cognitive-science</organization-id>
            <email>gpipa@uos.de</email>
        </person>
        <person id="person-27272">
            <firstname>Stefanos</firstname>
            <lastname>Ougiaroglou</lastname>
            <country>Greece</country>
            <organization-id>university-of-macedonia-greece</organization-id>
            <email>stoug@uom.gr</email>
        </person>
        <person id="person-32616005">
            <firstname>Leonidas</firstname>
            <lastname>Karamitopoulos</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>lkaramit@it.teithe.gr</email>
        </person>
        <person id="person-32841192">
            <firstname>Christos</firstname>
            <lastname>Tatoglou</lastname>
            <country>Greece</country>
            <organization-id>a-of-thessaloniki</organization-id>
            <email>xtatty@gmail.com</email>
        </person>
        <person id="person-32616001">
            <firstname>Georgios</firstname>
            <lastname>Evangelidis</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>gevan@uom.gr</email>
        </person>
        <person id="person-32771148">
            <firstname>Dimitris</firstname>
            <lastname>Dervos</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>dad@it.teithe.gr</email>
        </person>
        <person id="person-32263992">
            <firstname>Vladimir</firstname>
            <lastname>Kryzhanovskiy</lastname>
            <country>Russia</country>
            <organization-id>scientific-research-institute-for-system-analysis-of-russian-academy-of-sciences</organization-id>
            <email>vladimir.krizhanovsky@gmail.com</email>
        </person>
        <person id="person-90790">
            <firstname>Irina</firstname>
            <lastname>Zhelavskaya</lastname>
            <country>Russia</country>
            <organization-id>scientific-research-institute-for-system-analysis-of-russian-academy-of-sciences</organization-id>
            <email>winjei@ya.ru</email>
        </person>
        <person id="person-32617932">
            <firstname>Juan Antonio</firstname>
            <lastname>Clares Tomas</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>juanantonio.clares@murciaeduca.es</email>
        </person>
        <person id="person-32601365">
            <firstname>Hiroshi</firstname>
            <lastname>Okamoto</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>hiroshi.okamoto@fujixerox.co.jp</email>
        </person>
        <person id="person-47973">
            <firstname>Jérémie</firstname>
            <lastname>Cabessa</lastname>
            <country>Switzerland</country>
            <organization-id>unil</organization-id>
            <email>jcabessa@nhrg.org</email>
        </person>
        <person id="person-88926">
            <firstname>Carlos M.</firstname>
            <lastname>Alaíz</lastname>
            <country>Spain</country>
            <organization-id>universidad-autonoma-de-madrid</organization-id>
            <email>carlos.alaiz@uam.es</email>
        </person>
        <person id="person-32652175">
            <firstname>Álvaro</firstname>
            <lastname>Barbero</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>alvaro.barbero@uam.es</email>
        </person>
        <person id="person-32278526">
            <firstname>Jose</firstname>
            <lastname>Dorronsoro</lastname>
            <country>Spain</country>
            <organization-id>universidad-autonoma-de-madrid</organization-id>
            <email>jose.dorronsoro@uam.es</email>
        </person>
        <person id="person-93172">
            <firstname>Farouk</firstname>
            <lastname>Chérif</lastname>
            <country>Tunisia</country>
            <organization-id>issats-laboratory-of-math-physics-specials-functions-and-applications</organization-id>
            <email>faroukcheriff@yahoo.fr</email>
        </person>
        <person id="person-32896931">
            <firstname>Hajer</firstname>
            <lastname>Brahmi</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>brahmi.hajer@gmail.com</email>
        </person>
        <person id="person-32608416">
            <firstname>Boudour</firstname>
            <lastname>Ammar</lastname>
            <organization-id>national-school-of-engineers-of-sfax-university-of-sfax</organization-id>
            <email>boudour.ammar@ieee.org</email>
        </person>
        <person id="person-32475605">
            <firstname>Adel</firstname>
            <lastname>Alimi</lastname>
            <country>Tunisia</country>
            <organization-id>university-of-sfax</organization-id>
            <email>adel.alimi@ieee.org</email>
        </person>
        <person id="person-32664426">
            <firstname>Salvatore</firstname>
            <lastname>Frandina</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>frandina@dii.unisi.it</email>
        </person>
        <person id="person-32664275">
            <firstname>Marco</firstname>
            <lastname>Gori</lastname>
            <country>Italy</country>
            <organization-id>university-of-siena</organization-id>
            <email>marcoxgori@gmail.com</email>
        </person>
        <person id="person-32891932">
            <firstname>Marco</firstname>
            <lastname>Lippi</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>marcolippi83@gmail.com</email>
        </person>
        <person id="person-32664428">
            <firstname>Marco</firstname>
            <lastname>Maggini</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>maggini@dii.unisi.it</email>
        </person>
        <person id="person-32631364">
            <firstname>Stefano</firstname>
            <lastname>Melacci</lastname>
            <country>Italy</country>
            <organization-id>university-of-siena</organization-id>
            <email>mela@dii.unisi.it</email>
            <email>gmela.com@gmail.com</email>
            <email>mela@diism.unisi.it</email>
        </person>
        <person id="person-74294">
            <firstname>Rafal</firstname>
            <lastname>Zdunek</lastname>
            <country>Poland</country>
            <organization-id>wroclaw-university-of-technology</organization-id>
            <email>rafal.zdunek@pwr.wroc.pl</email>
        </person>
        <person id="person-32825936">
            <firstname>ANH-HUY</firstname>
            <lastname>PHAN</lastname>
            <country>Japan</country>
            <organization-id>brain-science-institute-riken</organization-id>
            <email>phan@brain.riken.jp</email>
        </person>
        <person id="person-32574613">
            <firstname>Andrzej</firstname>
            <lastname>Cichocki</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>cia@brain.riken.jp</email>
        </person>
        <person id="person-77936">
            <firstname>Nathan</firstname>
            <lastname>Burles</lastname>
            <country>United Kingdom</country>
            <organization-id>university-of-york</organization-id>
            <email>nburles@cs.york.ac.uk</email>
        </person>
        <person id="person-81421">
            <firstname>Simon</firstname>
            <lastname>O'Keefe</lastname>
            <organization-id>university-of-york</organization-id>
            <email>simon.okeefe@york.ac.uk</email>
            <email>sok@cs.york.ac.uk</email>
        </person>
        <person id="person-74124">
            <firstname>KyungHyun</firstname>
            <lastname>Cho</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>kyunghyun.cho@aalto.fi</email>
        </person>
        <person id="person-32276228">
            <firstname>Tapani</firstname>
            <lastname>Raiko</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>tapani.raiko@aalto.fi</email>
        </person>
        <person id="person-91386">
            <firstname>Alexander</firstname>
            <lastname>Ilin</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>alexander.ilin@aalto.fi</email>
        </person>
        <person id="person-32574655">
            <firstname>Jiri</firstname>
            <lastname>Sima</lastname>
            <country>Czech Republic</country>
            <organization-id>institute-of-computer-science-academy-of-sciences-of-the-czech-republic</organization-id>
            <email>sima@cs.cas.cz</email>
        </person>
        <person id="person-32608566">
            <firstname>Diego</firstname>
            <lastname>Peteiro-Barral</lastname>
            <country>Spain</country>
            <organization-id>university-of-a-corua</organization-id>
            <email>dpeteiro@udc.es</email>
        </person>
        <person id="person-32608631">
            <firstname>Bertha</firstname>
            <lastname>Guijarro-Berdiñas</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32603077">
            <firstname>Frank</firstname>
            <lastname>Sehnke</lastname>
            <country>Germany</country>
            <organization-id>center-for-solar-energy-and-hydrogen-research</organization-id>
            <email>frank.sehnke@zsw-bw.de</email>
        </person>
        <person id="person-32613494">
            <firstname>Artem</firstname>
            <lastname>Chernodub</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>a.chernodub@gmail.com</email>
        </person>
        <person id="person-32643624">
            <firstname>Giorgio</firstname>
            <lastname>Gnecco</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>giorgio.gnecco@unige.it</email>
        </person>
        <person id="person-103512">
            <firstname>Marco</firstname>
            <lastname>Gori</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>marco@dii.unisi.it</email>
        </person>
        <person id="person-32643631">
            <firstname>Stefano</firstname>
            <lastname>Melacci</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>mela@unisi.it</email>
        </person>
        <person id="person-32645663">
            <firstname>Igor</firstname>
            <lastname>Farkaš</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>farkas@ii.fmph.uniba.sk</email>
        </person>
        <person id="person-32645341">
            <firstname>Kristína</firstname>
            <lastname>Rebrová</lastname>
            <country>Slovakia</country>
            <organization-id>faculty-of-mathematics-physics-and-informatics-comenius-university-in-bratislava</organization-id>
            <email>kristina.rebrova@gmail.com</email>
        </person>
        <person id="person-32647319">
            <firstname>Daisuke</firstname>
            <lastname>Higuchi</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>126t250t@stu.kobe-u.ac.jp</email>
        </person>
        <person id="person-32647312">
            <firstname>Seiichi</firstname>
            <lastname>Ozawa</lastname>
            <country>Japan</country>
            <organization-id>kobe-university</organization-id>
            <email>ozawasei@kobe-u.ac.jp</email>
        </person>
        <person id="person-32664805">
            <firstname>Hunor Sandor</firstname>
            <lastname>Jakab</lastname>
            <country>Romania</country>
            <organization-id>babes-bolyai-university</organization-id>
            <email>jakabh@cs.ubbcluj.ro</email>
        </person>
        <person id="person-32608561">
            <firstname>Martin</firstname>
            <lastname>Meier</lastname>
            <country>Germany</country>
            <organization-id>bielefeld-university</organization-id>
            <email>mmeier@techfak.uni-bielefeld.de</email>
        </person>
        <person id="person-32622497">
            <firstname>Robert</firstname>
            <lastname>Haschke</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>rhaschke@techfak.uni-bielefeld.de</email>
        </person>
        <person id="person-32622495">
            <firstname>Helge J.</firstname>
            <lastname>Ritter</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>helge@techfak.uni-bielefeld.de</email>
        </person>
        <person id="person-32632447">
            <firstname>Salvatore</firstname>
            <lastname>Frandina</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>frandina@diism.unisi.it</email>
        </person>
        <person id="person-32632445">
            <firstname>Marco</firstname>
            <lastname>Lippi</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>lippi@diism.unisi.it</email>
        </person>
        <person id="person-32805321">
            <firstname>Marco</firstname>
            <lastname>Maggini</lastname>
            <country>Italy</country>
            <organization-id>university-of-siena</organization-id>
            <email>maggini@diism.unisi.it</email>
        </person>
        <person id="person-32690593">
            <firstname>Mikhail</firstname>
            <lastname>Suvorov</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>severe013@gmail.com</email>
        </person>
        <person id="person-32690587">
            <firstname>Sergey</firstname>
            <lastname>Ivliev</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32690589">
            <firstname>Markarian</firstname>
            <lastname>Garegin</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>g.markarian@lancaster.ac.uk</email>
        </person>
        <person id="person-32829656">
            <firstname>Denis</firstname>
            <lastname>Kolev</lastname>
            <country>Russia</country>
            <organization-id>lancaster-university</organization-id>
            <email>denis.g.kolev@gmail.com</email>
        </person>
        <person id="person-32690591">
            <firstname>Dmitry</firstname>
            <lastname>Zvikhachevskiy</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>zvikhacd@exchange.lancs.ac.uk</email>
        </person>
        <person id="person-32647922">
            <firstname>Plamen</firstname>
            <lastname>Angelov</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>p.angelov@lancaster.ac.uk</email>
        </person>
        <person id="person-32570818">
            <firstname>Ignas</firstname>
            <lastname>Martisius</lastname>
            <country>Lithuania</country>
            <organization-id>ktu</organization-id>
            <email>ignas.martisius@ktu.lt</email>
        </person>
        <person id="person-32910241">
            <firstname>Darius</firstname>
            <lastname>Birvinskas</lastname>
            <organization-id>kaunas-university-of-technology</organization-id>
            <email>darius.birvinskas@ktu.lt</email>
        </person>
        <person id="person-32608738">
            <firstname>Robertas</firstname>
            <lastname>Damasevicius</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>robertas.damasevicius@ktu.lt</email>
        </person>
        <person id="person-32608740">
            <firstname>Vacius</firstname>
            <lastname>Jusas</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>vacius.jusas@ktu.lt</email>
        </person>
        <person id="person-82751">
            <firstname>Cornelius</firstname>
            <lastname>Weber</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>weber@informatik.uni-hamburg.de</email>
        </person>
        <person id="person-50113">
            <firstname>Martin</firstname>
            <lastname>Spüler</lastname>
            <country>Germany</country>
            <organization-id>wilhelm-schikard-institute</organization-id>
            <email>spueler@informatik.uni-tuebingen.de</email>
        </person>
        <person id="person-52315">
            <firstname>Wolfgang</firstname>
            <lastname>Rosenstiel</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>rosen@informatik.uni-tuebingen.de</email>
        </person>
        <person id="person-52316">
            <firstname>Martin</firstname>
            <lastname>Bogdan</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>bogdan@informatik.uni-leipzig.de</email>
        </person>
        <person id="person-32629365">
            <firstname>Stephan</firstname>
            <lastname>Tschechne</lastname>
            <country>Germany</country>
            <organization-id>university-of-ulm</organization-id>
            <email>stephan.tschechne@uni-ulm.de</email>
        </person>
        <person id="person-79266">
            <firstname>Georg</firstname>
            <lastname>Layher</lastname>
            <country>Germany</country>
            <organization-id>university-of-ulm</organization-id>
            <email>georg.layher@uni-ulm.de</email>
        </person>
        <person id="person-32682302">
            <firstname>Cristian</firstname>
            <lastname>Axenie</lastname>
            <country>Germany</country>
            <organization-id>technische-universitt-mnchen</organization-id>
            <email>cristian.axenie@tum.de</email>
        </person>
        <person id="person-32270841">
            <firstname>Yulia</firstname>
            <lastname>Sandamirskaya</lastname>
            <country>Germany</country>
            <organization-id>ruhr-universitt-bochum</organization-id>
            <email>sandayci@rub.de</email>
            <email>yulia.sandamirskaya@ini.rub.de</email>
        </person>
        <person id="person-32603478">
            <firstname>Brian</firstname>
            <lastname>Gardner</lastname>
            <country>United Kingdom</country>
            <organization-id>university-of-surrey</organization-id>
            <email>b.gardner@surrey.ac.uk</email>
        </person>
        <person id="person-32572263">
            <firstname>Marta</firstname>
            <lastname>Castellano</lastname>
            <country>Germany</country>
            <organization-id>institute-of-cognitive-sciences</organization-id>
            <email>m@martacastellano.eu</email>
        </person>
        <person id="person-32600205">
            <firstname>Tobias</firstname>
            <lastname>Brosch</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>tobias.brosch@uni-ulm.de</email>
        </person>
        <person id="person-32616608">
            <firstname>Francis</firstname>
            <lastname>Jeanson</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>francis_jeanson@carleton.ca</email>
        </person>
        <person id="person-32616606">
            <firstname>Anthony</firstname>
            <lastname>White</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>arpwhite@scs.carleton.ca</email>
        </person>
        <person id="person-32628925">
            <firstname>robert</firstname>
            <lastname>fujii</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>fujii@u-aizu.ac.jp</email>
        </person>
        <person id="person-32643967">
            <firstname>Youwei</firstname>
            <lastname>Zheng</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>youwei.zheng@northwestern.edu</email>
            <email>youwei.zheng@uni-rostock.de</email>
        </person>
        <person id="person-32643979">
            <firstname>Lars</firstname>
            <lastname>Schwabe</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>lars.schwabe@uni-rostock.de</email>
        </person>
        <person id="person-32676676">
            <firstname>Klaus</firstname>
            <lastname>Förger</lastname>
            <country>Finland</country>
            <organization-id>aalto-university</organization-id>
            <email>klaus.forger@aalto.fi</email>
        </person>
        <person id="person-32663823">
            <firstname>Parimala</firstname>
            <lastname>Alva</lastname>
            <country>United Kingdom</country>
            <organization-id>university-of-hertfordshire</organization-id>
            <email>p.alva2@herts.ac.uk</email>
        </person>
        <person id="person-32663829">
            <firstname>Giseli</firstname>
            <lastname>De Sousa</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32663830">
            <firstname>Ben</firstname>
            <lastname>Torben-Nielsen</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32821943">
            <firstname>Reinoud</firstname>
            <lastname>Maex</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-94722">
            <firstname>Rod</firstname>
            <lastname>Adams</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>r.g.adams@herts.ac.uk</email>
        </person>
        <person id="person-94721">
            <firstname>Neil</firstname>
            <lastname>Davey</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>n.davey@herts.ac.uk</email>
        </person>
        <person id="person-32664612">
            <firstname>Volker</firstname>
            <lastname>Steuber</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>v.steuber@herts.ac.uk</email>
        </person>
        <person id="person-32640481">
            <firstname>Yasuhiro</firstname>
            <lastname>Hatori</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>hatori@cvs.cs.tsukuba.ac.jp</email>
        </person>
        <person id="person-32663979">
            <firstname>Tatsuroh</firstname>
            <lastname>Mashita</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32663980">
            <firstname>Ko</firstname>
            <lastname>Sakai</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32623111">
            <firstname>Juan Manuel</firstname>
            <lastname>Alonso-Weber</lastname>
            <country>Spain</country>
            <organization-id>polytechnic-school-universidad-carlos-iii-de-madrid</organization-id>
            <email>jmaw@ia.uc3m.es</email>
        </person>
        <person id="person-32623108">
            <firstname>M. Paz</firstname>
            <lastname>Sesmero</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>msesmero@inf.uc3m.es</email>
        </person>
        <person id="person-32643614">
            <firstname>German</firstname>
            <lastname>Gutierrez</lastname>
            <country>Spain</country>
            <organization-id>university-carlos-iii-of-madrid</organization-id>
            <email>ggutierr@inf.uc3m.es</email>
        </person>
        <person id="person-32643660">
            <firstname>Agapito</firstname>
            <lastname>Ledezma</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>ledezma@inf.uc3m.es</email>
        </person>
        <person id="person-32643658">
            <firstname>Araceli</firstname>
            <lastname>Sanchis</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>masm@inf.uc3m.es</email>
        </person>
        <person id="person-32863918">
            <firstname>Kiril</firstname>
            <lastname>Alexiev</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>alexiev@bas.bg</email>
        </person>
        <person id="person-32900067">
            <firstname>Marjan</firstname>
            <lastname>Trutschl</lastname>
            <country>United States</country>
            <organization-id>lsus</organization-id>
            <email>mtrutsch@lsus.edu</email>
        </person>
        <person id="person-32616599">
            <firstname>Phillip</firstname>
            <lastname>Kilgore</lastname>
            <country>United States</country>
            <organization-id>lsu-shreveport</organization-id>
            <email>pkilgore@lsus.edu</email>
        </person>
        <person id="person-32900073">
            <firstname>Urska</firstname>
            <lastname>Cvek</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>ucvek@lsus.edu</email>
        </person>
        <person id="person-32626990">
            <firstname>Hui</firstname>
            <lastname>Wei</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>weihui@fudan.edu.cn</email>
        </person>
        <person id="person-32627027">
            <firstname>Qing-Song</firstname>
            <lastname>Zuo</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32627028">
            <firstname>Bo</firstname>
            <lastname>Lang</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-88722">
            <firstname>Christian</firstname>
            <lastname>Vollmer</lastname>
            <country>Germany</country>
            <organization-id>ilmenau-university-of-technology</organization-id>
            <email>christian.vollmer@tu-ilmenau.de</email>
        </person>
        <person id="person-89458">
            <firstname>Horst-Michael</firstname>
            <lastname>Gross</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>horst-michael.gross@tu-ilmenau.de</email>
        </person>
        <person id="person-89459">
            <firstname>Julian</firstname>
            <lastname>Eggert</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>julian.eggert@honda-ri.de</email>
        </person>
        <person id="person-32644589">
            <firstname>Christo</firstname>
            <lastname>Panchev</lastname>
            <country>United Kingdom</country>
            <organization-id>university-of-sunderland</organization-id>
            <email>christo.panchev@sunderland.ac.uk</email>
        </person>
        <person id="person-32675185">
            <firstname>Dr Muhammad Naveed</firstname>
            <lastname>Anwar</lastname>
            <country>United Kingdom</country>
            <organization-id>the-open-university</organization-id>
            <email>mna2606@yahoo.com</email>
            <email>naveed.anwar@open.ac.uk</email>
        </person>
        <person id="person-32644596">
            <firstname>Michael</firstname>
            <lastname>Oakes</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>michael.oakes@sunderland.ac.uk</email>
        </person>
        <person id="person-32651503">
            <firstname>Grégoire</firstname>
            <lastname>Lefebvre</lastname>
            <country>France</country>
            <organization-id>orange-labs</organization-id>
            <email>gregoire.lefebvre@orange.com</email>
        </person>
        <person id="person-33073274">
            <firstname>Samuel</firstname>
            <lastname>Berlemont</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>samuel.berlemont@orange.com</email>
        </person>
        <person id="person-90154">
            <firstname>Franck</firstname>
            <lastname>Mamalet</lastname>
            <country>France</country>
            <organization-id>orange-labs</organization-id>
            <email>franck.mamalet@orange.com</email>
        </person>
        <person id="person-85059">
            <firstname>Garcia</firstname>
            <lastname>Christophe</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>christophe.garcia@liris.cnrs.fr</email>
        </person>
        <person id="person-32805438">
            <firstname>Mashud</firstname>
            <lastname>Rana</lastname>
            <country>Australia</country>
            <organization-id>university-of-sydney</organization-id>
            <email>mashud@it.usyd.edu.au</email>
        </person>
        <person id="person-32663134">
            <firstname>Abbas</firstname>
            <lastname>Khosravi</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>abbas.khosravi@deakin.edu.au</email>
        </person>
        <person id="person-32664303">
            <firstname>Julien</firstname>
            <lastname>Martel</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>julien.martel@insa-lyon.fr</email>
        </person>
        <person id="person-32664307">
            <firstname>Toru</firstname>
            <lastname>Nakashika</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>nakashika@me.cs.scitec.kobe-u.ac.jp</email>
        </person>
        <person id="person-32663510">
            <firstname>Christophe</firstname>
            <lastname>Garcia</lastname>
            <country>France</country>
            <organization-id>insa-de-lyon</organization-id>
            <email>christophe.garcia@insa-lyon.fr</email>
        </person>
        <person id="person-32664305">
            <firstname>Khalid</firstname>
            <lastname>Idrissi</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>khalid.Idrissi@insa-lyon.fr</email>
        </person>
        <person id="person-32664621">
            <firstname>Krista</firstname>
            <lastname>Lagus</lastname>
            <country>Finland</country>
            <organization-id>aalto-university</organization-id>
            <email>krista.lagus@aalto.fi</email>
        </person>
        <person id="person-32664731">
            <firstname>Juho</firstname>
            <lastname>Saari</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>juho.saari@uef.fi</email>
        </person>
        <person id="person-32664729">
            <firstname>Ilari</firstname>
            <lastname>Nieminen</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>ilari.nieminen@aalto.fi</email>
        </person>
        <person id="person-32664569">
            <firstname>Pablo</firstname>
            <lastname>Barros</lastname>
            <country>Brazil</country>
            <organization-id>university-of-pernambuco</organization-id>
            <email>pablovin@gmail.com</email>
        </person>
        <person id="person-32664995">
            <firstname>Nestor</firstname>
            <lastname>Júnior</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>ntmj@ecomp.poli.br</email>
        </person>
        <person id="person-32664991">
            <firstname>Juvenal</firstname>
            <lastname>Bisneto</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>jmmb@ecomp.poli.br</email>
        </person>
        <person id="person-32875016">
            <firstname>Bruno</firstname>
            <lastname>Fernandes</lastname>
            <country>Brazil</country>
            <organization-id>universidade-de-pernambuco</organization-id>
            <email>bjtf@ecomp.poli.br</email>
        </person>
        <person id="person-32275002">
            <firstname>Byron</firstname>
            <lastname>Bezerra</lastname>
            <country>Brazil</country>
            <organization-id>university-of-pernambuco</organization-id>
            <email>byronleite@ecomp.poli.br</email>
        </person>
        <person id="person-32664993">
            <firstname>Sérgio</firstname>
            <lastname>Fernandes</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>smmfast@gmail.com</email>
        </person>
        <person id="person-32587518">
            <firstname>Jens</firstname>
            <lastname>Hocke</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>hocke@inb.uni-luebeck.de</email>
        </person>
        <person id="person-75983">
            <firstname>Davide</firstname>
            <lastname>Anguita</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>Davide.Anguita@unige.it</email>
        </person>
        <person id="person-75910">
            <firstname>Alessandro</firstname>
            <lastname>Ghio</lastname>
            <country>Italy</country>
            <organization-id>university-of-genoa</organization-id>
            <email>alessandro.ghio@unige.it</email>
        </person>
        <person id="person-32817687">
            <firstname>Luca</firstname>
            <lastname>Oneto</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>luca.oneto@unige.it</email>
        </person>
        <person id="person-32624361">
            <firstname>Xavier</firstname>
            <lastname>Parra</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>xavier.parra@upc.edu</email>
        </person>
        <person id="person-32841763">
            <firstname>Jorge Luis</firstname>
            <lastname>Reyes Ortiz</lastname>
            <organization-id>universidad-politecnica-de-catalunya</organization-id>
            <email>jorge.luis.reyes@estudiant.upc.edu</email>
        </person>
        <person id="person-75984">
            <firstname>Sandro</firstname>
            <lastname>Ridella</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>sandro.ridella@unige.it</email>
        </person>
        <person id="person-32642975">
            <firstname>Enkelejda</firstname>
            <lastname>Tafaj</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>tafaj@informatik.uni-tuebingen.de</email>
        </person>
        <person id="person-32815671">
            <firstname>Thomas</firstname>
            <lastname>Kübler</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>thomas.kuebler@uni-tuebingen.de</email>
        </person>
        <person id="person-32643067">
            <firstname>Gjergji</firstname>
            <lastname>Kasneci</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>gjergji.kasneci@hpi.uni-potsdam.de</email>
        </person>
        <person id="person-32643069">
            <firstname>Wolfgang</firstname>
            <lastname>Rosenstiel</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>rosenstiel@informatik.uni-tuebingen.de</email>
        </person>
        <person id="person-32652795">
            <firstname>Pablo</firstname>
            <lastname>Romeu</lastname>
            <country>Spain</country>
            <organization-id>university-ceu-cardenal-herrera</organization-id>
            <email>pablo.romeu@uch.ceu.es</email>
        </person>
        <person id="person-32642063">
            <firstname>Francisco</firstname>
            <lastname>Zamora-Martinez</lastname>
            <country>Spain</country>
            <organization-id>universidad-ceu-cardenal-herrera</organization-id>
            <email>francisco.zamora@uch.ceu.es</email>
        </person>
        <person id="person-32642138">
            <firstname>Paloma</firstname>
            <lastname>Botella-Rocamora</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>paloma.botella@uch.ceu.es</email>
        </person>
        <person id="person-32642136">
            <firstname>Juan</firstname>
            <lastname>Pardo</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>juan.pardo@uch.ceu.es</email>
        </person>
        <person id="person-32555774">
            <firstname>Yancho</firstname>
            <lastname>Todorov</lastname>
            <country>Bulgaria</country>
            <organization-id>institute-of-information-and-communication-technologies-bulgarian-academy-of-sciences</organization-id>
            <email>yancho.todorov@ieee.org</email>
        </person>
        <person id="person-32891779">
            <firstname>Margarita</firstname>
            <lastname>Terziyska</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>terzyiska@gmail.com</email>
        </person>
        <person id="person-32889721">
            <firstname>Michail</firstname>
            <lastname>Petrov</lastname>
            <country>Bulgaria</country>
            <organization-id>technical-university-sofia-branch-plovdiv</organization-id>
            <email>mpetrov@tu-plovdiv.bg</email>
        </person>
        <person id="person-32879054">
            <firstname>Christian</firstname>
            <lastname>Denk</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>christian.denk@tum.de</email>
        </person>
        <person id="person-32818512">
            <firstname>Francisco</firstname>
            <lastname>Llobet Blandino</lastname>
            <country>Germany</country>
            <organization-id>no-organization-present</organization-id>
            <email>llobetblandino@mytum.de</email>
        </person>
        <person id="person-32817638">
            <firstname>Francesco</firstname>
            <lastname>Galluppi</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>francesco.galluppi@cs.man.ac.uk</email>
        </person>
        <person id="person-32664576">
            <firstname>Luis</firstname>
            <lastname>Plana</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>plana@cs.man.ac.uk</email>
        </person>
        <person id="person-32817650">
            <firstname>Steve</firstname>
            <lastname>Furber</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>sfurber@cs.man.ac.uk</email>
            <email>steve.furber@manchester.ac.uk</email>
        </person>
        <person id="person-32637568">
            <firstname>Oliver</firstname>
            <lastname>Lomp</lastname>
            <country>Germany</country>
            <organization-id>ruhr-universitt-bochum</organization-id>
            <email>oliver.lomp@ini.ruhr-uni-bochum.de</email>
        </person>
        <person id="person-32664496">
            <firstname>Stephan Klaus Ulrich</firstname>
            <lastname>Zibner</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>stephan.zibner@ini.ruhr-uni-bochum.de</email>
        </person>
        <person id="person-32664498">
            <firstname>Mathis</firstname>
            <lastname>Richter</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>mathis.richter@ini.ruhr-uni-bochum.de</email>
        </person>
        <person id="person-32876440">
            <firstname>Inaki</firstname>
            <lastname>Rano</lastname>
            <country>United Kingdom</country>
            <organization-id>university-of-ulster</organization-id>
            <email>i.rano@ulster.ac.uk</email>
        </person>
        <person id="person-32574901">
            <firstname>Tibor</firstname>
            <lastname>Kmet</lastname>
            <country>Slovakia</country>
            <organization-id>cpu-in-nitra</organization-id>
            <email>tkmet@ukf.sk</email>
        </person>
        <person id="person-32605374">
            <firstname>Maria</firstname>
            <lastname>Kmetova</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>mkmetova@ukf.sk</email>
        </person>
        <person id="person-32615670">
            <firstname>Tsubasa</firstname>
            <lastname>Takamatsu</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>osana-yachiyo@osn.cs.teu.ac.jp</email>
        </person>
        <person id="person-90928">
            <firstname>Yuko</firstname>
            <lastname>Osana</lastname>
            <country>Japan</country>
            <organization-id>tokyo-university-of-technology</organization-id>
            <email>osana@cs.teu.ac.jp</email>
        </person>
        <person id="person-32644860">
            <firstname>Mohammed</firstname>
            <lastname>Boukens</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32644854">
            <firstname>Abdelkrim</firstname>
            <lastname>Boukabou</lastname>
            <country>Algeria</country>
            <organization-id>univ-jijel</organization-id>
            <email>aboukabou@univ-jijel.dz</email>
        </person>
        <person id="person-32772947">
            <firstname>Naima</firstname>
            <lastname>Chouikhi</lastname>
            <organization-id>enis</organization-id>
            <email>naima.chouikhi@gmail.com</email>
        </person>
        <person id="person-32664847">
            <firstname>Nasser</firstname>
            <lastname>Rezzoug</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32664848">
            <firstname>Philippe</firstname>
            <lastname>Gorce</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32608984">
            <firstname>Paul</firstname>
            <lastname>Olivier</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>paul.olivier@upc.edu</email>
        </person>
        <person id="person-32613222">
            <firstname>Juan Manuel</firstname>
            <lastname>Moreno Arostegui</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32676612">
            <firstname>Robert</firstname>
            <lastname>Hercus</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>Hercus@neuramatix.com</email>
        </person>
        <person id="person-32878974">
            <firstname>Kit Yee</firstname>
            <lastname>Wong</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>KitYee@neuramatix.com</email>
        </person>
        <person id="person-32647230">
            <firstname>kim fong</firstname>
            <lastname>ho</lastname>
            <country>Malaysia</country>
            <organization-id>neuramatix-sdn-bhd</organization-id>
            <email>kfho@neuramatix.com</email>
        </person>
        <person id="person-32664077">
            <firstname>Fumiaki</firstname>
            <lastname>Saitoh</lastname>
            <country>Japan</country>
            <organization-id>aoyama-gakuin-univ</organization-id>
            <email>f.saitoh.tot@gmail.com</email>
        </person>
        <person id="person-32664664">
            <firstname>Akihide</firstname>
            <lastname>Utani</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32588081">
            <firstname>Tinghua</firstname>
            <lastname>Wang</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>wthpku@163.com</email>
        </person>
        <person id="person-32593288">
            <firstname>Junyang</firstname>
            <lastname>Rao</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32593289">
            <firstname>Dongyan</firstname>
            <lastname>Zhao</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32396748">
            <firstname>Tomasz</firstname>
            <lastname>Zabkowski</lastname>
            <country>Poland</country>
            <organization-id>warsaw-university-of-life-sciences</organization-id>
            <email>tomasz_zabkowski@sggw.pl</email>
        </person>
        <person id="person-32396756">
            <firstname>Ryszard</firstname>
            <lastname>Szupiluk</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>rszupi@sgh.waw.pl</email>
        </person>
        <person id="person-32599619">
            <firstname>Piotr</firstname>
            <lastname>Wojewnik</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>piotr.wojewnik@gmail.com</email>
        </person>
        <person id="person-32802568">
            <firstname>Achim</firstname>
            <lastname>Strunk</lastname>
            <country>Germany</country>
            <organization-id>no-organization-present</organization-id>
            <email>achim.strunk@weather-consult.com</email>
        </person>
        <person id="person-32613522">
            <firstname>Martin</firstname>
            <lastname>Felder</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>martin.felder@zsw-bw.de</email>
        </person>
        <person id="person-32613524">
            <firstname>Joris</firstname>
            <lastname>Brombach</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>joris.brombach@weather-consult.com</email>
        </person>
        <person id="person-32613528">
            <firstname>Anton</firstname>
            <lastname>Kaifel</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>anton.kaifel@zsw-bw.de</email>
        </person>
        <person id="person-32613526">
            <firstname>Jon</firstname>
            <lastname>Meis</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>jon.meis@weather-consult.com</email>
        </person>
        <person id="person-32896316">
            <firstname>michael</firstname>
            <lastname>knapek</lastname>
            <country>Finland</country>
            <organization-id>aalto-university</organization-id>
            <email>contactmiska@knapek.org</email>
        </person>
        <person id="person-32642633">
            <firstname>George</firstname>
            <lastname>Tsekouras</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>tsekouras_george_j@yahoo.gr</email>
        </person>
        <person id="person-32642629">
            <firstname>Fotis</firstname>
            <lastname>Kanellos</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>kanellos@mail.ntua.gr</email>
        </person>
        <person id="person-32642631">
            <firstname>Nikos</firstname>
            <lastname>Mastorakis</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>mastor@wseas.org</email>
        </person>
        <person id="person-32640650">
            <firstname>Yukinori</firstname>
            <lastname>Homma</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>homma@soft.ics.keio.ac.jp</email>
        </person>
        <person id="person-32643338">
            <firstname>Masafumi</firstname>
            <lastname>Hagiwara</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>hagiwara@soft.ics.keio.ac.jp</email>
        </person>
        <person id="person-32598791">
            <firstname>Marvin</firstname>
            <lastname>Struwe</lastname>
            <country>Germany</country>
            <organization-id>no-organization-present</organization-id>
            <email>mstruwe@fb2.fh-frankfurt.de</email>
        </person>
        <person id="person-32622189">
            <firstname>Stephan</firstname>
            <lastname>Hasler</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>stephan.hasler@honda-ri.de</email>
        </person>
        <person id="person-32871076">
            <firstname>Ute</firstname>
            <lastname>Bauer-Wersing</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>ubauer@fb2.fh-frankfurt.de</email>
        </person>
        <person id="person-32613422">
            <firstname>Nikolay</firstname>
            <lastname>Neshov</lastname>
            <organization-id>no-organization-present</organization-id>
            <email>nneshov@tu-sofia.bg</email>
        </person>
        <person id="person-32682932">
            <firstname>Dmitry</firstname>
            <lastname>Kangin</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
        <person id="person-32682933">
            <firstname>George</firstname>
            <lastname>Kolev</lastname>
            <organization-id>no-organization-present</organization-id>
        </person>
    </persons>
    <papers>
        <paper id="paper-32599932">
            <title>Hessian Corrected Input Noise Models</title>
            <abstract>When the inputs of a regression problem are corrupted with noise, integrating out the noise process leads to biased estimates. We present a method that corrects the bias caused by the integration. The correction is proportional to the Hessian of the learned model and to the variance of the input noise. The method works for arbitrary regression models, the only requirement is two times differentiability of the respective model. The conducted experiments suggest that significant improvement can be gained using the proposed method. Nevertheless, experiments on high dimensional data highlight the limitations of the algorithm.&#xD;
</abstract>
            <keywords>
                <keyword>input noise models</keyword>
                <keyword>regression</keyword>
                <keyword>hessian</keyword>
            </keywords>
            <authors>
                <author-id>person-32584453</author-id>
                <author-id>person-32844371</author-id>
            </authors>
        </paper>
        <paper id="paper-32608586">
            <title>Model-based clustering of temporal data</title>
            <abstract>This paper addresses the problem of temporal data clustering using a dynamic Gaussian mixture model whose means are considered as latent variables distributed according to random walks. Its final objective is to track the dynamic evolution of some critical railway components using data acquired through embedded sensors. The parameters of the proposed algorithm are estimated by maximum likelihood via the Expectation-Maximization algorithm. In contrast to other approaches as the maximum a posteriori estimation in which the covariance matrices of the random walks have to be fixed by the user, the results of the simulations show the ability of the proposed algorithm to correctly estimate these covariances while keeping a low clustering error rate.</abstract>
            <keywords>
                <keyword>Clustering</keyword>
                <keyword>dynamic latent variable model</keyword>
                <keyword>mixture model</keyword>
                <keyword>EM algorithm</keyword>
                <keyword>Kalman filter</keyword>
                <keyword>time series clustering</keyword>
                <keyword>maximum likelihood</keyword>
                <keyword>maximum a posteriori</keyword>
            </keywords>
            <authors>
                <author-id>person-32608556</author-id>
                <author-id>person-32608589</author-id>
                <author-id>person-32608593</author-id>
                <author-id>person-32608591</author-id>
            </authors>
        </paper>
        <paper id="paper-32612540">
            <title>Fast approximation method for Gaussian process regression using hash function for non-uniformly distributed data</title>
            <abstract>Gaussian process regression (GPR) has the ability to deal with non-linear regression readily, although the calculation cost increases with the sample size.&#xD;
In this paper, we propose a fast approximation method for GPR using both locality-sensitive hashing and product of experts models.&#xD;
To investigate the performance of our method, we apply it to regression problems, i.e., artificial data and actual hand motion data.&#xD;
Results indicate that our method can perform accurate calculation and fast approximation of GPR even if the dataset is non-uniformly distributed.</abstract>
            <keywords>
                <keyword>Gaussian process regression</keyword>
                <keyword>locality-sensitive hashing</keyword>
                <keyword>product of experts model</keyword>
            </keywords>
            <authors>
                <author-id>person-32612536</author-id>
                <author-id>person-32821827</author-id>
                <author-id>person-32821172</author-id>
                <author-id>person-91428</author-id>
                <author-id>person-32612543</author-id>
            </authors>
        </paper>
        <paper id="paper-32613336">
            <title>An Analytical Approach to Delay-Coupled Reservoir Computing</title>
            <abstract>Reservoir computing has been successfully applied in difficult time series prediction tasks by injecting an input signal into a spatially extended reservoir of nonlinear subunits to perform history-dependent nonlinear computation.  Recently, the network was replaced by a single nonlinear node, delay-coupled to itself. Instead of a spatial topology, subunits are arrayed in time along one delay span of the system. As a result, the reservoir exists only implicitly in a single delay differential equation, numerical solving of which is costly. We derive here approximate analytical equations for the reservoir by solving the underlying system explicitly. The analytical approximation represents the system accurately and yields comparable performance in reservoir benchmark tasks, while reducing computational costs by several orders of magnitude. This has important implications with respect to electronic realizations of the reservoir and opens up new possibilities for optimization and theoretical investigation.&#xD;
</abstract>
            <keywords>
                <keyword>reservoir computing</keyword>
                <keyword>single node delay-coupled reservoir</keyword>
                <keyword>delay-coupled systems</keyword>
                <keyword>time series prediction</keyword>
                <keyword>recurrent neural networks</keyword>
                <keyword>delay differential equations</keyword>
            </keywords>
            <authors>
                <author-id>person-32613328</author-id>
                <author-id>person-32816458</author-id>
                <author-id>person-50617</author-id>
            </authors>
        </paper>
        <paper id="paper-32615998">
            <title>Applying general-purpose Data Reduction Techniques for fast time series classification</title>
            <abstract>The one-nearest neighbour classifier is a widely-used time series classification method. However, its efficiency depends on the size of the training set as well as on data dimensionality. Although many speed-up methods for fast time series classification have been proposed, state-of-the-art, non-parametric data reduction techniques have not been exploited on time series data. This paper presents an experimental study where known prototype selection and abstraction data reduction techniques are evaluated both on original data and a dimensionally reduced representation form of the same data from seven time series datasets. The results show that data reduction, even when applied on dimensionally reduced data, can in some cases improve the accuracy and at the same time reduce the computational cost of classification.</abstract>
            <keywords>
                <keyword>time series classification,nearest neighbor,data reduction</keyword>
            </keywords>
            <authors>
                <author-id>person-27272</author-id>
                <author-id>person-32616005</author-id>
                <author-id>person-32841192</author-id>
                <author-id>person-32616001</author-id>
                <author-id>person-32771148</author-id>
            </authors>
        </paper>
        <paper id="paper-32617929">
            <title>Two-layer vector perceptron</title>
            <abstract>A new model – two-layer vector perceptron – is offered. Though, comparing with a single-layer perceptron, its operation needs slightly more (by 5%) calculations and more effective computer memory, it excels in a much lower error rate (four orders of magnitude as lower).</abstract>
            <keywords>
                <keyword>vector neural networks</keyword>
                <keyword>Potts model</keyword>
            </keywords>
            <authors>
                <author-id>person-32263992</author-id>
                <author-id>person-90790</author-id>
                <author-id>person-32617932</author-id>
            </authors>
        </paper>
        <paper id="paper-32619276">
            <title>Local Detection of Communities by Neural-Network Dynamics</title>
            <abstract>Community structure is a hallmark of a variety of real-world networks. Here we propose a local method for detecting communities in networks. The method is described as ‘local’ because it is intended to find the community to which a given source node belongs without knowing all the communities in the network. We have devised this method inspired by possible mechanisms for stable propagation of neuronal activities in neural networks. To demonstrate the effectiveness of our method, local detection of communities in synthetic benchmark networks and real social networks is examined. The community structure detected by our method is perfectly consistent with the correct community structure of these networks. </abstract>
            <keywords>
                <keyword>Complex Network</keyword>
                <keyword>Community Detection</keyword>
                <keyword>Markov Chain</keyword>
                <keyword>Spreading Activation</keyword>
                <keyword>Neural Network</keyword>
            </keywords>
            <authors>
                <author-id>person-32601365</author-id>
            </authors>
        </paper>
        <paper id="paper-32638614">
            <title>The Super-Turing Computational Power of Interactive Evolving Recurrent Neural Networks</title>
            <abstract>Understanding the dynamical and computational capabilities of neural models represents an issue of central importance. Here, we consider a model of first-order recurrent neural networks provided with the possibility to evolve over time and involved in a basic interactive and memory active computational paradigm. In this context, we prove that the so-called {\it interactive evolving recurrent neural networks} are computationally equivalent to interactive Turing machines with advice, hence capable of super-Turing potentialities. We further provide a precise characterisation of the $\omega$-translations realised by these networks. Therefore, the consideration of evolving capabilities in a first-order neural model provides the potentiality to break the Turing barrier.</abstract>
            <keywords>
                <keyword>recurrent neural networks</keyword>
                <keyword>neural computation</keyword>
                <keyword>interactive computation</keyword>
                <keyword>analog computation</keyword>
                <keyword>Turing machines with advice</keyword>
                <keyword>super-Turing</keyword>
            </keywords>
            <authors>
                <author-id>person-47973</author-id>
                <author-id>person-32760</author-id>
            </authors>
        </paper>
        <paper id="paper-32652172">
            <title>Group Fused Lasso</title>
            <abstract>We introduce the Group Total Variation (GTV) regularizer, a modification of Total Variation that uses the l21 norm instead of the l1 one to deal with multidimensional features.&#xD;
When used as the only regularizer, GTV can be applied jointly with iterative convex optimization algorithms such as FISTA. This requires to compute its proximal operator which we derive using a dual formulation. GTV can also be combined with a Group Lasso (GL) regularizer, leading to what we call Group Fused Lasso (GFL) whose proximal operator can now be computed combining the GTV and GL proximals through Dykstra algorithm.&#xD;
We will illustrate how to apply GFL in strongly structured but ill-posed regression problems as well as the use of GTV to denoise colour images.</abstract>
            <keywords>
                <keyword>Group Fused Lasso</keyword>
                <keyword>Group Total Variation</keyword>
                <keyword>Group Lasso</keyword>
                <keyword>Fused Lasso</keyword>
                <keyword>Total Variation</keyword>
            </keywords>
            <authors>
                <author-id>person-88926</author-id>
                <author-id>person-32652175</author-id>
                <author-id>person-32278526</author-id>
            </authors>
        </paper>
        <paper id="paper-32664755">
            <title>Exponential synchronization of a class of RNNs with discrete and distributed delays</title>
            <abstract>This paper studies the exponential synchronization of RNNs.&#xD;
The investigations are carried out by means of Lyapunov stability method and the Halanay inequality lemma. Finally, a numerical example with graphical illustrations is given to illuminate the presented synchronization scheme.</abstract>
            <keywords>
                <keyword>recurrent neural networks</keyword>
                <keyword></keyword>
                <keyword>exponential synchronization</keyword>
                <keyword>Stability</keyword>
            </keywords>
            <authors>
                <author-id>person-93172</author-id>
                <author-id>person-32896931</author-id>
                <author-id>person-32608416</author-id>
                <author-id>person-32475605</author-id>
            </authors>
        </paper>
        <paper id="paper-32665205">
            <title>Variational Foundations  of  Online Backpropagation</title>
            <abstract>On-line Backpropagation has become very popular and it has been the subject of in-depth theoretical analyses and massive experimentation. Yet, after almost three decades from its publication, it is still surprisingly the source of tough theoretical questions and of experimental results that are somewhat shrouded in mystery. Although seriously plagued by  local minima, the batch-mode version of the algorithm is clearly posed as an optimization problem while, in spite of its effectiveness in many real-world problems, the on-line mode version has not been given a clean formulation, yet. Using variational arguments, in this paper, the on-line formulation is proposed as the minimization of a classic functional that is inspired by the principle of minimal action in analytic mechanics.  The proposed approach clashes sharply with common interpretations of on-line learning as an approximation of batch-mode, and it suggests that processing data all at once might be just an artificial formulation of learning  that is hopeless in difficult real-world problems.</abstract>
            <keywords>
                <keyword>on-line Backpropagation</keyword>
                <keyword>principle of least action</keyword>
                <keyword>regularization</keyword>
                <keyword>local minima</keyword>
                <keyword>dissipative systems.</keyword>
            </keywords>
            <authors>
                <author-id>person-32664426</author-id>
                <author-id>person-32664275</author-id>
                <author-id>person-32891932</author-id>
                <author-id>person-32664428</author-id>
                <author-id>person-32631364</author-id>
            </authors>
        </paper>
        <paper id="paper-32676289">
            <title>GNMF with Newton-based Methods</title>
            <abstract>Several variants of Nonnegative Matrix Factorization (NMF) have been proposed for supervised classification of various objects. Graph regularized NMF (GNMF) incorporates the information on the data geometric structure to the training process, which considerably improves the classification results. However, the multiplicative algorithms used for updating the underlying factors may result in a slow convergence of the training process. To tackle this problem, we propose to use the Spectral Projected Gradient (SPG) method that is based on quasi-Newton methods. The results are presented for image classification problems.</abstract>
            <keywords>
                <keyword>Nonnegative Matrix Factorization</keyword>
                <keyword>Graph-regularized NMF</keyword>
                <keyword>Spectral Projected Gradient</keyword>
                <keyword>Quasi-Newton Methods</keyword>
                <keyword>Image Classification</keyword>
            </keywords>
            <authors>
                <author-id>person-74294</author-id>
                <author-id>person-32825936</author-id>
                <author-id>person-32574613</author-id>
            </authors>
        </paper>
        <paper id="paper-32612692">
            <title>Improving the Associative Rule Chaining Architecture</title>
            <abstract>This paper describes improvements to the rule chaining architecture presented in [1]. The architecture uses distributed associative memories to allow the system to utilise memory efficiently, and superimposed distributed representations in order to reduce the time complexity of a tree search to O(d), where d is the depth of the tree. This new work reduces the memory required by the architecture, and can also further reduce the time complexity.&#xD;
&#xD;
[1] Austin, J., Hobson, S., Burles, N., O'Keefe, S.: A Rule Chaining Architecture Using a Correlation Matrix Memory. Artificial Neural Networks and Machine Learning - ICANN 2012, 49-56 (2012)</abstract>
            <keywords>
                <keyword>rule chaining,correlation matrix memory,associative memory,distributed representation,parallel distributed computation</keyword>
            </keywords>
            <authors>
                <author-id>person-77936</author-id>
                <author-id>person-81421</author-id>
                <author-id>person-32268372</author-id>
            </authors>
        </paper>
        <paper id="paper-32573592">
            <title>A Two-Stage Pretraining Algorithm for Deep Boltzmann Machines</title>
            <abstract>A deep Boltzmann machine (DBM) is a recently introduced Markov random field model that has multiple layers of hidden units. It has been shown empirically that it is difficult to train a DBM with approximate maximum-likelihood learning using the stochastic gradient unlike its simpler special case, restricted Boltzmann machine (RBM).  In this paper, we propose a novel pretraining algorithm that consists of two stages; obtaining approximate posterior distributions over hidden units from a simpler model and maximizing the variational lower-bound given the fixed hidden posterior distributions. We show empirically that the proposed method overcomes the difficulty in training DBMs from randomly initialized parameters and results in a better, or comparable, generative model when compared to the conventional pretraining algorithm.  </abstract>
            <keywords>
                <keyword>Deep Boltzmann Machine</keyword>
                <keyword>Deep Learning</keyword>
                <keyword>Pretraining</keyword>
            </keywords>
            <authors>
                <author-id>person-74124</author-id>
                <author-id>person-32276228</author-id>
                <author-id>person-91386</author-id>
                <author-id>person-32658597</author-id>
            </authors>
        </paper>
        <paper id="paper-32603569">
            <title>A Low-Energy Implementation of Finite Automata by Optimal-Size Neural Nets</title>
            <abstract>Recently, a new so-called energy complexity measure has been introduced and studied for feedforward perceptron networks. This measure is inspired by the fact that biological neurons require more energy to transmit a spike than not to fire and the activity of neurons in the brain is quite sparse, with only about 1% of neurons firing. We investigate the energy complexity for recurrent networks which bounds the number of active neurons at any time instant of a computation. We prove that any deterministic finite automaton with $m$ states can be simulated by a neural network of optimal size $s=\Theta(\sqrt{m})$ with time overhead $O(s/e)$ per one input bit, using the energy $O(e)$, for any $e=\Omega(\log s)$ and $e=O(s)$, which shows the time-energy tradeoff in recurrent networks.</abstract>
            <keywords>
                <keyword>neural networks</keyword>
                <keyword>finite automata</keyword>
                <keyword>energy complexity</keyword>
                <keyword>optimal size</keyword>
            </keywords>
            <authors>
                <author-id>person-32574655</author-id>
            </authors>
        </paper>
        <paper id="paper-32608612">
            <title>A Distributed Learning Algorithm Based on Frontier Vector Quantization and Information Theory</title>
            <abstract>In this paper, we propose a novel distributed learning algorithm built upon the Frontier Vector Quantization based on Information Theory (FVQIT) method. The FVQIT is very effective in classification problems but it shows poor training time performance. Thus, distributed learning is appropriate here to speed up training. One of the most promising lines of research towards learning from distributed data sets is separated learning and model integration. Separated learning avoids moving raw data around the distributed nodes. The integration of local models is implemented in this research using a genetic algorithm. The results obtained from twelve classification data sets demonstrate the efficacy of the proposed method. In average, the distributed FVQIT performs 13.56 times faster than the FVQIT and improves classification accuracy by 5.25%.</abstract>
            <keywords>
                <keyword>Machine learning</keyword>
                <keyword>distributed learning</keyword>
                <keyword>FVQIT</keyword>
                <keyword>neural networks</keyword>
                <keyword>genetic algorithms</keyword>
            </keywords>
            <authors>
                <author-id>person-32608566</author-id>
                <author-id>person-32608631</author-id>
            </authors>
        </paper>
        <paper id="paper-32613374">
            <title>Efficient Baseline-free Sampling in Parameter Exploring Policy Gradients: Super Symmetric PGPE</title>
            <abstract>Policy Gradient methods that explore directly in parameter space are among the most effective and robust direct policy search methods and have drawn a lot of attention lately. The basic method from this field, Policy Gradients with Parameter-based Exploration, uses two samples that are symmetric around the current hypothesis to circumvent misleading reward in asymmetrical reward distributed problems gathered with the usual baseline approach. The exploration parameters are still updated by a baseline approach - leaving the exploration prone to asymmetric reward distributions. In this paper we will show how the exploration parameters can be sampled quasi symmetric despite having limited instead of free parameters for exploration. We give a transformation approximation to get quasi symmetric samples with respect to the exploration without changing the overall sampling distribution. Finally we will demonstrate that sampling symmetrically also for the exploration parameters is superior in needs of samples and robustness than the original sampling approach.</abstract>
            <keywords>
                <keyword>Parameter Exploration</keyword>
                <keyword>Policy Gradients</keyword>
                <keyword>Baseline-free Sampling</keyword>
                <keyword>Reinforcement Learning</keyword>
            </keywords>
            <authors>
                <author-id>person-32603077</author-id>
            </authors>
        </paper>
        <paper id="paper-32613491">
            <title>Direct Method for Training Feed-forward Neural Networks using Batch Extended Kalman Filter for Multi-Step-Ahead Predictions</title>
            <abstract>This paper is dedicated to the long-term, or multi-step-ahead, time series prediction problem. We propose a novel method for training feed-forward neural networks, such as multilayer perceptrons, with tapped delay lines. Special batch calculation of derivatives called Forecasted Propagation Through Time and batch modification of the Extended Kalman Filter are introduced. Experiments were carried out on well-known timeseries benchmarks, the Mackey-Glass chaotic process and the Santa Fe Laser Data Series. Recurrent and feed-forward neural networks were evaluated.</abstract>
            <keywords>
                <keyword>multi-step-ahead prediction</keyword>
                <keyword>Batch Extended Kalman Filter</keyword>
                <keyword>Forecasted Propagation Through Time</keyword>
            </keywords>
            <authors>
                <author-id>person-32613494</author-id>
            </authors>
        </paper>
        <paper id="paper-32643628">
            <title>Learning with hard constraints</title>
            <abstract>A learning paradigm is proposed, in which one has both classical supervised examples and constraints that cannot be violated, called here “hard constraints”, such as those enforcing the probabilistic normalization of a density function or imposing coherent decisions of the classifiers acting on different views of the same pattern. In contrast, supervised examples can be violated at the cost of some penalization (quantified by the choice of a suitable loss function) and so play the roles of “soft constraints”. Constrained variational calculus is exploited to derive a representation theorem, which provides a description of the “optimal body of the agent”, i.e., the functional structure of the solution to the proposed learning problem. It is shown that the solution can be represented in terms of a set of “support constraints”, thus extending the well-known notion of “support vectors”.</abstract>
            <keywords>
                <keyword>Learning from constraints</keyword>
                <keyword>learning with prior knowledge</keyword>
                <keyword>multi-task learning</keyword>
                <keyword>support constraints</keyword>
                <keyword>constrained variational calculus</keyword>
            </keywords>
            <authors>
                <author-id>person-32643624</author-id>
                <author-id>person-103512</author-id>
                <author-id>person-32643631</author-id>
                <author-id>person-32551372</author-id>
            </authors>
        </paper>
        <paper id="paper-32645660">
            <title>Bidirectional Activation-based Neural Network Learning Algorithm</title>
            <abstract>We present a model of a bidirectional three-layer neural network with sigmoidal units, which can be trained to learn arbitrary mappings. We introduce a bidirectional activation-based learning algorithm (BAL), inspired by O’Reilly’s supervised Generalized Recirculation (GeneRec) algorithm that has been designed as a biologically plausible alternative to standard error backpropagation. BAL shares several features with GeneRec, but differs from it by being completely bidirectional regarding the activation propagation and the weight updates. In pilot experiments, we test the learning properties of BAL using three artificial data sets with binary patterns of increasing complexity.</abstract>
            <keywords>
                <keyword>bidirectional network</keyword>
                <keyword>error-driven learning</keyword>
                <keyword>activation states</keyword>
                <keyword>binary codes association</keyword>
                <keyword>biological plausibility</keyword>
            </keywords>
            <authors>
                <author-id>person-32645663</author-id>
                <author-id>person-32645341</author-id>
            </authors>
        </paper>
        <paper id="paper-32647316">
            <title>A Neural Network Model for Online Multi-task Multi-Label Pattern Recognition</title>
            <abstract>This paper presents a new sequential multi-task learning model with the following functions: one-pass incremental learning, task allocation, knowledge transfer, task consolidation, learning of multi-label data, and active learning. This model learns multi-label data with incomplete task information incrementally. When no task information is given, class labels are allocated to appropriate tasks based on prediction errors; thus, the task allocation sometimes fails especially at the early stage. To recover from the misallocation, the proposed model has a backup mechanism called task consolidation, which can modify the task allocation not only based on prediction errors but also based on task labels in training data (if given) and a heuristics on multi-label data. The experimental results demonstrate that the proposed model has good performance in both classification and task categorization.</abstract>
            <keywords>
                <keyword>multi-task learning</keyword>
                <keyword>incremental learning</keyword>
                <keyword>neural networks</keyword>
                <keyword>multi-label recognition</keyword>
            </keywords>
            <authors>
                <author-id>person-32647319</author-id>
                <author-id>person-32647312</author-id>
            </authors>
        </paper>
        <paper id="paper-32676583">
            <title>Novel feature selection and kernel-based value approximation method for reinforcement learning</title>
            <abstract>We present a novel sparsification and value function approximation method for on-line reinforcement learning in continuous state and action spaces. Our approach is based on the kernel least squares temporal difference learning&#xD;
algorithm. We derive a recursive version and enhance the algorithm with a new sparsification mechanism based on the topology maps represented by proximity graphs. The sparsification mechanism – speeding up computations – favors datapoints minimizing the divergence of the target-function gradient, thereby also considering the shape of the target function. The performance of our sparsification and approximation method is tested on a standard benchmark RL problem. </abstract>
            <keywords>
                <keyword>reinforcement learning</keyword>
                <keyword>kernel methods</keyword>
                <keyword>function approximation</keyword>
            </keywords>
            <authors>
                <author-id>person-32664805</author-id>
                <author-id>person-32844371</author-id>
            </authors>
        </paper>
        <paper id="paper-32622492">
            <title>Learning of Lateral Interactions for Perceptual Grouping employing Information Gain</title>
            <abstract>Perceptual Grouping is an important aspect in the understanding of sensory input. One of the major problems&#xD;
there is, how features can form meaningful groups while segregating from non relevant informations.&#xD;
One solution can be to couple features by attracting and repelling interactions and let neural dynamics&#xD;
decide the assignment of features to groups. In this paper, we present a modification of a learning approach&#xD;
to find these couplings, which explicitly incorporates the information gain of feature pairs, increasing the overall&#xD;
grouping quality of the original technique. The new approach is evaluated with an oscillator network and&#xD;
compared to the original work.</abstract>
            <keywords>
                <keyword>Perceptual Grouping</keyword>
                <keyword>Dynamical Systems</keyword>
                <keyword>Pattern recognition</keyword>
            </keywords>
            <authors>
                <author-id>person-32608561</author-id>
                <author-id>person-32622497</author-id>
                <author-id>person-32622495</author-id>
            </authors>
        </paper>
        <paper id="paper-32632440">
            <title>On-line Laplacian One-Class Support Vector Machines</title>
            <abstract>We propose a manifold regularization algorithm designed to work in an on-line scenario where data arrive continuously over time and it is not feasible to completely store the data stream for training the classifier in batch mode. The On-line Laplacian One-Class SVM (OLapOCSVM) algorithm exploits both positively labeled and totally unlabeled examples, updating the classifier hypothesis as new data becomes available. The learning procedure is based on conjugate gradient descent in the primal formulation of the SVM. The on-line algorithm uses an efficient buffering technique to deal with the continuous incoming data. In particular, we define a buffering policy that is based on the current estimate of the support of the input data distribution.  The experimental results on real-world data show that OLapOCSVM compares favorably  with the corresponding batch algorithms, while making it possible to be applied in generic on-line scenarios with limited memory requirements.</abstract>
            <keywords>
                <keyword>On-line learning</keyword>
                <keyword>One-Class SVM</keyword>
                <keyword>RKHS</keyword>
                <keyword>Manifold Regularization</keyword>
                <keyword>Semi-supervised learning.</keyword>
            </keywords>
            <authors>
                <author-id>person-32632447</author-id>
                <author-id>person-32632445</author-id>
                <author-id>person-32805321</author-id>
                <author-id>person-32631364</author-id>
            </authors>
        </paper>
        <paper id="paper-32690585">
            <title>OSA: One-class Recursive SVM Algorithm with Negative Samples for Fault Detection</title>
            <abstract>In this paper a novel one-class classification approach (called OSA) is proposed. The algorithm is particularly suitable for fault detection in complex technological systems, such as aircraft. This study is based on the capability of one-class support vector machine (SVM) method to classify correctly the observation and measurement data, obtained during the exploitation of the system such as airborne  aircraft into a single class of ‘normal’ behavior and, respectively, leave data that is not assigned to this class as suspected anomalies. In order to ensure real time (in flight) application a recursive learning procedure of the method is proposed. The proposed method takes into account both “positive”/”normal” and “negative”/”abnormal” examples of the base class, keeping the overall model structure as an outlier-detection approach. This approach is generic for any fault detection problem (for example in areas such as process control, computer networks, analysis of data from interrogations, etc.). The advantages  of the new algorithm based on OSA are  verified by comparison  with several classifiers, including the traditional one-class SVM. The proposed approach is tested for fault detection problem using real flight data from a large number of aircraft of different make (USA, Western European as well as Russian).</abstract>
            <keywords>
                <keyword>Flight Data Analysis</keyword>
                <keyword>Fault Detection and Identification</keyword>
                <keyword>one class SVM</keyword>
            </keywords>
            <authors>
                <author-id>person-32690593</author-id>
                <author-id>person-32690587</author-id>
                <author-id>person-32690589</author-id>
                <author-id>person-32829656</author-id>
                <author-id>person-32690591</author-id>
                <author-id>person-32647922</author-id>
            </authors>
        </paper>
        <paper id="paper-32608733">
            <title>EEG Dataset Reduction and Classification Using Wave Atom Transform</title>
            <abstract>Brain Computer Interface (BCI) systems perform intensive&#xD;
processing of the electroencephalogram (EEG) data in order to form control signals for external electronic devices or virtual objects. The main task of a BCI system is to correctly detect and classify mental states in the EEG data. The efficiency (accuracy and speed) of a BCI system depends upon the feature dimensionality of the EEG signal and the number of mental states required for control. Feature reduction can help improve system learning speed and, in some cases, classification accuracy. Here we consider Wave Atom Transform (WAT) of the EEG data as a feature reduction method. WAT takes input data and concentrates its energy&#xD;
in a few transform coefficients. WAT is used as a data preprocessing step for feature extraction. We use artificial neural networks (ANNs) for classification and perform research with varying number of neurons in a hidden layer and different network training functions (Levenberg-Marquardt, Conjugate Gradient Backpropagation, Bayesian Regulariza-&#xD;
tion). The novelty of the paper is the application of WAT in the EEG data processing. We conclude that the method can be successfully used for feature extraction and dataset feature reduction in the BCI domain.</abstract>
            <keywords>
                <keyword>EEG</keyword>
                <keyword>Brain Computer Interface</keyword>
                <keyword>Wave Atom Transform</keyword>
                <keyword>dimensionality reduction</keyword>
                <keyword>classification</keyword>
            </keywords>
            <authors>
                <author-id>person-32570818</author-id>
                <author-id>person-32910241</author-id>
                <author-id>person-32608738</author-id>
                <author-id>person-32608740</author-id>
            </authors>
        </paper>
        <paper id="paper-32616184">
            <title>Embodied Language Understanding with a Multiple Timescale Recurrent Neural Network</title>
            <abstract>How the human brain understands natural language and what we can learn for intelligent systems is open research. Recently, researchers claimed that language is embodied in most -- if not all -- sensory and sensorimotor modalities and that the brain's architecture favours the emergence of language. In this paper we investigate the characteristics of such an architecture and propose a model based on the Multiple Timescale Recurrent Neural Network, extended by embodied visual perception. We show that such an architecture can learn the meaning of utterances with respect to visual perception and that it can produce verbal utterances that correctly describe previously unknown scenes.</abstract>
            <keywords>
                <keyword>Embodied Language</keyword>
                <keyword>MTRNN</keyword>
                <keyword>Language Acquisition</keyword>
            </keywords>
            <authors>
                <author-id>person-89382</author-id>
                <author-id>person-82751</author-id>
                <author-id>person-47310</author-id>
            </authors>
        </paper>
        <paper id="paper-32628772">
            <title>Unsupervised online calibration of a c-VEP Brain-Computer Interface (BCI)</title>
            <abstract>Brain-Computer Interfaces (BCIs) can be used to give paralyzed patients a means for communication. But so far, only supervised methods have been used for calibration of an online BCI. In this paper we present a method that allows to calibrate a BCI online and unsupervised. Based on offline data we show that the unsupervised calibration method works and validate the results in an online experiment with 8 subjects, who were able to control the BCI with an average accuracy of 85 %. We thereby have shown for the first time that an online unsupervised calibration of a BCI is possible and allows for successful BCI control.</abstract>
            <keywords>
                <keyword>Brain-Computer interface</keyword>
                <keyword>BCI</keyword>
                <keyword> unsupervised learning</keyword>
            </keywords>
            <authors>
                <author-id>person-50113</author-id>
                <author-id>person-52315</author-id>
                <author-id>person-52316</author-id>
            </authors>
        </paper>
        <paper id="paper-32629374">
            <title>A Biologically Inspired Model for the Detection of External and Internal Head Motions</title>
            <abstract>Non-verbal communication signals are to a large part conveyed by visual motion information of the user's facial components (intrinsic motion) and head (extrinsic motion).  An observer perceives the visual flow as a superposition of both motions. However, when visual signals are used for training of classifiers for non-articulated communication signals, a decomposition is advantageous. We propose a biologically inspired model that builds upon the known functional organization of cortical motion processing at low and intermediate stages to decompose the composite motion signal. The approach extends previous models to incorporate mechanisms that represent motion gradients and direction sensitivity. The neural models operate on larger spatial scales to capture properties in flow patterns elicited by turning head movements. Center-surround mechanisms build contrast-sensitive cells and detect local facial motion. The model is probed with video samples and outputs occurrences and magnitudes of extrinsic and intrinsic motion patterns.</abstract>
            <keywords>
                <keyword>Social Interaction</keyword>
                <keyword>HCI</keyword>
                <keyword>Motion Patterns</keyword>
                <keyword>Cortical Processing</keyword>
            </keywords>
            <authors>
                <author-id>person-32629365</author-id>
                <author-id>person-79266</author-id>
                <author-id>person-32697866</author-id>
            </authors>
        </paper>
        <paper id="paper-32664830">
            <title>Cortically Inspired Sensor Fusion Network for Mobile Robot Heading Estimation</title>
            <abstract>All physical systems must reliably extract information from their noisily and partially observable environment, such as distances to objects. Biology has developed reliable mechanisms to combine multi-modal sensory information into a coherent belief about the underlying environment that caused the percept; a process called sensor fusion. Autonomous technical systems (such as mobile robots) employ compute-intense algorithms for sensor fusion, which hardly work in real-time; yet their results in complex unprepared environments are typically inferior to human performance. Despite the little we know about cortical computing principles for sensor fusion, an obvious difference between biological and technical information processing lies in the way information flows: computer algorithms are typically designed as feed-forward filter-banks, whereas in Cortex we see vastly recurrent connected networks with intertwined information processing, storage, and exchange. In this paper we model such information processing as distributed graphical network, in which independent neural computing nodes obtain and represent sensory information, while processing and exchanging exclusively local data. Given various external sensory stimuli, the network relaxes into the best possible explanation of the underlying cause, subject to the inferred reliability of sensor signals. We implement a simple test-case scenario with a 4 dimensional sensor fusion task on an autonomous mobile robot and demonstrate its performance. We expect to be able to expand this sensor fusion principle to vastly more complex tasks.</abstract>
            <keywords>
                <keyword>Cortical inspired sensor fusion</keyword>
                <keyword>graphical network</keyword>
                <keyword>local processing</keyword>
                <keyword>mobile robotics</keyword>
            </keywords>
            <authors>
                <author-id>person-32682302</author-id>
                <author-id>person-90477</author-id>
            </authors>
        </paper>
        <paper id="paper-32664922">
            <title>Learning Sensorimotor Transformations with Dynamic Neural Fields</title>
            <abstract>The sensorimotor maps link the perceived states to  actions, required to achieve the goals of a behaving agent. These mappings depend on the physics of the body of the agent, as well as the dynamics and geometry of the environment, in which the behavior unfolds. Autonomous acquisition and updating of the mappings is crucial for robust behavior in a changing real-world environment. Autonomy of many architectures, which implement the learning and adaptation of sensorimotor maps, is limited. Here, we present a neural-dynamic architecture that enables autonomous learning of the sensorimotor transformation, involved in looking behavior. The architecture is built using Dynamic Neural Fields and is implemented on a robotic agent that consists of an eDVS sensor on a pan-tilt unit. </abstract>
            <keywords>
                <keyword>Dynamic Neural Fields</keyword>
                <keyword>autonomous learning</keyword>
                <keyword>sensorimotor transformations</keyword>
            </keywords>
            <authors>
                <author-id>person-32270841</author-id>
                <author-id>person-90477</author-id>
            </authors>
        </paper>
        <paper id="paper-32618075">
            <title>Learning Temporally Precise Spiking Patterns through Reward Modulated Spike-Timing-Dependent Plasticity</title>
            <abstract>Precise neuronal spike timing plays an important role in many aspects of cognitive processing. Here, we explore how a spiking neural network can learn to generate temporally precise spikes in response to a spatio-temporal pattern, through spike-timing-dependent plasticity modulated by a delayed reward signal. An escape noise neuron is implemented as the readout to incorporate the effect of background noise on spike timing. We compare the performance of two different escape rate functions that drive spiking in the readout neuron: the Arrhenius &amp; Current (A&amp;C) and Exponential (EXP) model. Our results show that the network can learn to reproduce target spike patterns containing between 1 and 10 spikes with 10 ms temporal accuracy. We also demonstrate the superior performance of the A&amp;C model over the EXP model for the parameters we consider, especially when reproducing a large number of target spikes.</abstract>
            <keywords>
                <keyword>Neuronal Plasticity</keyword>
                <keyword>Stochastic Neuron</keyword>
                <keyword>Synapses</keyword>
            </keywords>
            <authors>
                <author-id>person-32603478</author-id>
                <author-id>person-32278102</author-id>
            </authors>
        </paper>
        <paper id="paper-32575007">
            <title>Memory trace in spiking neural networks</title>
            <abstract>Spiking neural networks have a limited memory capacity, such that a stimulus arriving at time t would vanish over a timescale of 200-300 milliseconds [1]. Therefore, only neural computations that require history dependencies within this short range can be accomplished. In this paper, the limited memory capacity of a spiking neural network is extended by coupling it to an delayed-dynamical system. This presents the possibility of information exchange between spiking neurons and continuous .delayed systems</abstract>
            <keywords>
                <keyword>spiking neural networks</keyword>
                <keyword>memory trace</keyword>
                <keyword>delayed-dynamical systems</keyword>
                <keyword>reservoir computing</keyword>
            </keywords>
            <authors>
                <author-id>person-32572263</author-id>
                <author-id>person-50617</author-id>
            </authors>
        </paper>
        <paper id="paper-32600209">
            <title>Attention-Gated Reinforcement Learning in Neural Networks-A Unified View</title>
            <abstract>Learning in the brain is associated with changes of connection strengths between neurons. Here, we consider neural networks with output units for each possible action. Training is performed by giving rewards for correct actions. A major problem in effective learning is to assign credit to units playing a decisive role in the stimulus-response mapping. Previous work suggested an attentional feedback signal in combination with a global reinforcement signal to determine&#xD;
plasticity at units in earlier processing levels. However, it could not learn from delayed rewards (e.g., a robot could escape from fire but not walk through it to rescue a person). Based on the AGREL framework, we developed a new attention-gated learning scheme that makes use of delayed rewards. Finally, we show a close relation to standard error backpropagation.</abstract>
            <keywords>
                <keyword>Reinforcement Learning</keyword>
                <keyword>Backpropagation</keyword>
                <keyword>AGREL</keyword>
                <keyword>Delayed Rewards</keyword>
                <keyword>Attention</keyword>
                <keyword>Hebbian Learning</keyword>
            </keywords>
            <authors>
                <author-id>person-32600205</author-id>
                <author-id>person-32268904</author-id>
                <author-id>person-32697866</author-id>
            </authors>
        </paper>
        <paper id="paper-32616603">
            <title>Dynamic Memory for Robot Control using Delay-based Coincidence Detection Neurones</title>
            <abstract>This paper demonstrates the feasibility of dynamic memory in transmission delay coincidence detection networks. We present a low complexity, procedural algorithm for determining delay connectivity for the control of a simulated e-puck robot to solve the t-maze memory task. This work shows that dynamic memory modules need not undergo structural change during learning but that peripheral structures could be alternate candidates for this. Overall, this supports the view that delay coincidence detection networks can be effectively coupled to produce embodied adaptive behaviours.</abstract>
            <keywords>
                <keyword>Dynamic Memory</keyword>
                <keyword>Transmission Delays</keyword>
                <keyword>Coincidence Detection</keyword>
                <keyword>Spiking Neural Networks</keyword>
                <keyword>Embodied Cognition</keyword>
            </keywords>
            <authors>
                <author-id>person-32616608</author-id>
                <author-id>person-32616606</author-id>
            </authors>
        </paper>
        <paper id="paper-32627217">
            <title>Robust Principal Component Analysis for Brain Imaging</title>
            <abstract>Discrimination of cognitive states from functional Magnetic&#xD;
Resonance Images (fMRI) is a challenging task, particularly when across&#xD;
subjects common representation of brain states is to be detected. Among&#xD;
several difficulties, the huge number of features (voxels) is a major ob-&#xD;
stacle for reliable discrimination of common patterns across brains. Prin-&#xD;
cipal Component Analysis (PCA) is widely applied for learning of low&#xD;
dimensional linear data models in image processing.The main drawback&#xD;
of the traditional PCA is that it is a least-square technique that fails&#xD;
to account for outliers. Previous attempts to make PCA robust have&#xD;
treated the entire image as an outlier. However, the fMRIs may contain&#xD;
undesirable artifacts due to errors related with the brain scanning pro-&#xD;
cess, alignment errors or pixels that are corrupted by noise. In this paper&#xD;
we propose a new dimensionality reduction approach based on Robust&#xD;
Principal Component Analysis (RPCA) that uses an intra-sample outlier&#xD;
process to account for pixel outliers. The RPCA improves classification&#xD;
accuracy of two cognitive brain states across various subjects compared&#xD;
to using conventional PCA or not performing dimensionality reduction.</abstract>
            <keywords>
                <keyword>brain imaging</keyword>
                <keyword>robust principal component analysis</keyword>
                <keyword>functional Magnetic Resonance Imaging</keyword>
            </keywords>
            <authors>
                <author-id>person-32574873</author-id>
            </authors>
        </paper>
        <paper id="paper-32631163">
            <title>Phase Control of Coupled Neuron Oscillators</title>
            <abstract>The phase response of an Izhikevich neuron integrator/resonator model based oscillator to a weak short-duration external input pulse is used to determine the Izhikevich model dynamic parameter values needed to attain a specified phase difference between coupled neuron oscillators working at the same natural oscillation frequency. The design of a new type of neuron oscillator-chain based artificial central pattern generator for the coordinated four-legged animal walking movement is proposed as an application.</abstract>
            <keywords>
                <keyword>Izhikevich neuron model</keyword>
                <keyword>saddle-node bifurcation</keyword>
                <keyword>Andronov-Hopf bifurcation</keyword>
                <keyword>integrator</keyword>
                <keyword>resonator</keyword>
                <keyword>stable limit cycle</keyword>
                <keyword>phase difference</keyword>
                <keyword>phase response curve</keyword>
                <keyword>weakly-coupled oscillators</keyword>
            </keywords>
            <authors>
                <author-id>person-32628925</author-id>
            </authors>
        </paper>
        <paper id="paper-32643976">
            <title>Dendritic computations in a Rall model with strong distal stimulation</title>
            <abstract>Rall's work is the basis for investigating dendritic computations,&#xD;
but only recently the technology became available to study their&#xD;
properties experimentally. Empirical evidence supports idea that synaptic&#xD;
inputs at distal dendritic locations set the context for recognizing&#xD;
synaptic activation patterns of synapses proximal to the soma. Such a&#xD;
context-dependence is fundamental for action selection and decision making.&#xD;
It is usually assumed that active channels in dendrites are necessary.&#xD;
Here, we investigate under which conditions of synaptic drive a passive&#xD;
dendrite model can realize such a context-dependence. Using a simple&#xD;
optimization procedure we find that stronger distal than proximal activation,&#xD;
paired with delayed inhibition, is sufficient to produce so-called up&#xD;
states. Testing the model on a diffeerent protocol (selectivity to synaptic&#xD;
activation sequences: distal to proximal vs. proximal to distal) shows that&#xD;
it is more similar to recent experimental findings than Rall's original parameterization,and similar to a model with active dendrites. Our results&#xD;
show that, given stronger distal activation, context-dependent pattern&#xD;
recognition can be implemented in passive dendrites. Future experimental&#xD;
studies need to determine on a case-by-case basis the contribution of&#xD;
active channels in dendrites (a single neuron property) vs. synaptic drive&#xD;
(a network property) in context-dependent pattern recognition.</abstract>
            <keywords>
                <keyword>Computational neuroscience</keyword>
                <keyword>dendrites</keyword>
                <keyword>pattern recognition</keyword>
                <keyword>classi</keyword>
            </keywords>
            <authors>
                <author-id>person-32643967</author-id>
                <author-id>person-32643979</author-id>
            </authors>
        </paper>
        <paper id="paper-32660269">
            <title>Modeling Action Verb Semantics Using Motion Tracking</title>
            <abstract>In this article, we consider how semantics of action verbs can be grounded on motion tracking data. We present the basic principles and requirements for grounding of verbs through case studies related to human movement. The data includes high-dimensional movement patterns and linguistic expressions that people have used to name these movements. We discuss open issues and possibilities related to symbol grounding. As a conclusion, we find the grounding to be useful when reasoning about the meaning of words and relationships between them within one language and potentially also between languages.</abstract>
            <keywords>
                <keyword>cognitive systems</keyword>
                <keyword>symbol grounding</keyword>
                <keyword>multimodality</keyword>
                <keyword>language processing</keyword>
            </keywords>
            <authors>
                <author-id>person-45115</author-id>
                <author-id>person-32676676</author-id>
            </authors>
        </paper>
        <paper id="paper-32663827">
            <title>Evolution of Dendritic Morphologies using Deterministic and Nondeterministic Genotype to Phenotype Mapping</title>
            <abstract>In this study, two morphological representations in the genotype, a deterministic and a nondeterministic  representation, are compared when evolving a neuronal morphology for a pattern recognition task. The deterministic approach represents the dendritic morphology explicitly as a set of partitions in the genotype which can give rise to a&#xD;
single phenotype. The nondeterministic method used in this study encodes only the branching probability in the genotype which can produce multiple phenotypes. The main result is that the nondeterministic method instigates &#xD;
the selection of more symmetric dendritic morphologies which was not observed in the deterministic method.</abstract>
            <keywords>
                <keyword>Dendritic Morphology</keyword>
                <keyword>Pattern Recognition</keyword>
            </keywords>
            <authors>
                <author-id>person-32663823</author-id>
                <author-id>person-32663829</author-id>
                <author-id>person-32663830</author-id>
                <author-id>person-32821943</author-id>
                <author-id>person-94722</author-id>
                <author-id>person-94721</author-id>
                <author-id>person-32664612</author-id>
            </authors>
        </paper>
        <paper id="paper-32663947">
            <title>Sparseness Controls the Receptive Field Characteristics of V4 Neurons: Generation of Curvature Selectivity in V4</title>
            <abstract>Physiological studies have reported that the intermediate-level visual area represents primitive shape by the selectivity to curvature and its direction. However, it has not been revealed that what coding scheme underlies the construction of the selectivity with complex characteristics. We propose that sparse representation is crucial for the construction so that a sole control of sparseness is capable of generating physiological characteristics. To test the proposal, we applied component analysis with sparseness constraint to activities of model neurons, and investigated whether the computed bases reproduce the characteristics of the selectivity. To evaluate the learned bases quantitatively, we computed the tuning properties of single bases and the population, as similar to the physiological reports. The basis functions reproduced the physiological characteristics when sparseness was medium (0.6-0.8). These results indicate that sparse representation is crucial for the curvature selectivity, and that a sole control of sparseness is capable of constructing the representation.</abstract>
            <keywords>
                <keyword>shape representation</keyword>
                <keyword>curvature</keyword>
                <keyword>sparse coding</keyword>
                <keyword>computational model</keyword>
            </keywords>
            <authors>
                <author-id>person-32640481</author-id>
                <author-id>person-32663979</author-id>
                <author-id>person-32663980</author-id>
            </authors>
        </paper>
        <paper id="paper-32643655">
            <title>Handwritten Digit Recognition with Pattern Transformations and Neural Network Averaging</title>
            <abstract>Recently there has been a considerable improvement in applications related with isolated handwritten digit and letter recognition supported on the use of deep and convolutional neural networks and other combinations which make use of ensemble averaging. The proposal of the present work is based on a relatively modest sized Neural Network trained with standard Back Propagation and combined with a set of input pattern transformations. Applying ensemble averaging on the trained Neural Networks gives an encouraging error rate of 0.34% measured on the MNIST dataset.&#xD;
</abstract>
            <keywords>
                <keyword>Artificial Neural Networks - Back Propagation - Ensembles - MNIST – Handwritten Digit Recognition</keyword>
            </keywords>
            <authors>
                <author-id>person-32623111</author-id>
                <author-id>person-32623108</author-id>
                <author-id>person-32643614</author-id>
                <author-id>person-32643660</author-id>
                <author-id>person-32643658</author-id>
            </authors>
        </paper>
        <paper id="paper-32664903">
            <title>Echo State Networks in Dynamic Data Clustering</title>
            <abstract>The present paper follows the initial work on multidimensional static data clustering using a novel neural network structure, namely Echo state network (ESN). Here we exploit dynamic nature of these networks for solving of clustering task of a multidimensional dynamic data set. The data used in this in-vestigation are taken from an experimental set-up applied for tasting of visual discrimination of complex dot motions. The proposed here model, although far from complicated brain theories, can serve as a good basis for investigation of humans perception.</abstract>
            <keywords>
                <keyword>Echo state networks</keyword>
                <keyword>dynamic data clustering</keyword>
                <keyword>visual discrimination of complex motions</keyword>
            </keywords>
            <authors>
                <author-id>person-45536</author-id>
                <author-id>person-32863918</author-id>
            </authors>
        </paper>
        <paper id="paper-32616629">
            <title>Self-Organization in Parallel Coordinates</title>
            <abstract>Parallel coordinates has shown itself to be a powerful method of exploring and visualizing multidimensional data. However, applying this method to large data sets often introduces clutter, resulting in reduced insight of the data under investigation. We present a new technique that combines the classical parallel  coordinates plot with a synthesized dimension that uses topological proximity as an indicator of similarity. We resolve the issue of overplotting and increase the utility of the widely-used parallel coordinates visualization.</abstract>
            <keywords>
                <keyword>Parallel Coordinates</keyword>
                <keyword>Self-Organizing Map</keyword>
                <keyword>Visualization</keyword>
                <keyword>Multidimensional Data.</keyword>
            </keywords>
            <authors>
                <author-id>person-32900067</author-id>
                <author-id>person-32616599</author-id>
                <author-id>person-32900073</author-id>
            </authors>
        </paper>
        <paper id="paper-32627025">
            <title>A General Image Representation Scheme and its Improvement for Image Analysis</title>
            <abstract>In this paper, a bio-inspired neural network is developed to represent images and analysis features of images effectively. This model adopts schemes of retinal ganglion cells (GC) working and GCs’ non-classical receptive fields (nCRF) that can dynamically adjust their sizes/scales according to the visual information. Extensive experiments are provided to value the effect of image representing, and experimental results show that this neural network model can represent images at a low cost and with a favor in improving both segmentation and integration processing. Most importantly, the GC-array model provides a basic infrastructure for image semantic extraction.</abstract>
            <keywords>
                <keyword>nCRF</keyword>
                <keyword>Image representation</keyword>
                <keyword>Multi-scale</keyword>
                <keyword>Contour detection</keyword>
            </keywords>
            <authors>
                <author-id>person-32626990</author-id>
                <author-id>person-32627027</author-id>
                <author-id>person-32627028</author-id>
            </authors>
        </paper>
        <paper id="paper-32637493">
            <title>Learning Features for Activity Recognition with Shift-invariant Sparse Coding</title>
            <abstract>In activity recognition, traditionally, features are chosen heuristically, based on explicit domain knowledge. Typical features are statistical measures, like mean, standard deviation, etc., which are tailored to the application at hand and might not fit in other cases. However, Feature Learning techniques have recently gained attention for building approaches that generalize over different application domains. More conventional approaches, like Principal Component Analysis, and newer ones, like Deep Belief Networks, have been studied so far and yielded significantly better results than traditional techniques. In this paper we study the potential of Shift-invariant Sparse Coding (SISC) as an additional Feature Learning technique for activity recognition. &#xD;
We evaluate the performance on several publicly available activity recognition data sets and show that classification based on features learned by SISC outperforms other previously presented Feature Learning techniques.</abstract>
            <keywords>
                <keyword>feature learning</keyword>
                <keyword>activity recognition</keyword>
                <keyword>sparse coding</keyword>
            </keywords>
            <authors>
                <author-id>person-88722</author-id>
                <author-id>person-89458</author-id>
                <author-id>person-89459</author-id>
            </authors>
        </paper>
        <paper id="paper-32644593">
            <title>Hearing aid classification based on audiology data</title>
            <abstract>Presented is a comparative study of two machine learning models (MLP Neural Network and Bayesian Network) as part of a decision support system for prescribing ITE (in the ear) and BTE (behind the ear) aids for people with hearing difficulties. The models are developed/trained and evaluated on a large set of patient records from major NHS audiology centre in England. The two main questions which the models aim to address are: 1) What type of hearing aid (ITE/BTE) should be prescribed to the patient? and 2) Which factors influence the choice of ITE as opposed to BTE hearing aids? The models developed here were evaluated against actual prescriptions given by the doctors and showed relatively high classification rates with the MLP network achieving slightly better results.</abstract>
            <keywords>
                <keyword>Audiology Data Mining</keyword>
                <keyword>Decision Support System</keyword>
                <keyword>Multi-layer Perceptron</keyword>
                <keyword>Bayesian Network</keyword>
            </keywords>
            <authors>
                <author-id>person-32644589</author-id>
                <author-id>person-32675185</author-id>
                <author-id>person-32644596</author-id>
            </authors>
        </paper>
        <paper id="paper-32651510">
            <title>BLSTM-RNN based 3D Gesture Classification</title>
            <abstract>This paper presents a new robust method for inertial MEM (MicroElectroMechanical systems) 3D gesture recognition. The linear acceleration and the angular velocity, respectively provided by the accelerometer and the gyrometer, are sampled in time resulting in 6D values at each time step which are used as inputs for the gesture recognition system. We propose to build a system based on Bidirectional Long Short-Term Memory Recurrent Neural Networks (BLSTM-RNN) for gesture classification from raw MEM data. We also compare this system to a geometric approach using DTW (Dynamic Time Warping) and a statistical method based on HMM (Hidden Markov Model) from filtered and denoised MEM data. Experimental results on 22 individuals producing 14 gestures in the air show that the proposed approach outperforms classical classification methods with a classification mean rate of 95.57% and a standard deviation of 0.50 for 616 test gestures. Furthermore, these experiments underline that combining accelerometer and gyrometer information gives better results that using a single inertial description.</abstract>
            <keywords>
                <keyword>LSTM-RNN; DTW; HMM; MEM;  Hand gesture recognition</keyword>
            </keywords>
            <authors>
                <author-id>person-32651503</author-id>
                <author-id>person-33073274</author-id>
                <author-id>person-90154</author-id>
                <author-id>person-85059</author-id>
            </authors>
        </paper>
        <paper id="paper-32663131">
            <title>Feature Selection for Neural Network-Based Interval Forecasting of Electricity Demand Data</title>
            <abstract>We consider feature selection for interval forecasting of time series data. In particular, we study feature selection for LUBEX, a neural-network based approach for computing prediction intervals and its application for predicting future electricity demands from a time series of previous demands. Our results show that the mutual information and correlation-based feature selection methods are able to select a small set of lag variables that when used with LUBEX construct valid and stable prediction intervals (coverage probability of 97.44% and 96.68%, respectively, for confidence level of 90%). In contrast, the popular partial autocorrelation feature selection method fails to do this (coverage probability of 69.69%). Our evaluation was conducted using one year of half-hourly Australian electricity demand data. </abstract>
            <keywords>
                <keyword>electricity demand forecasting</keyword>
                <keyword>prediction intervals</keyword>
                <keyword>neural networks</keyword>
                <keyword>feature selection</keyword>
            </keywords>
            <authors>
                <author-id>person-32805438</author-id>
                <author-id>person-47052</author-id>
                <author-id>person-32663134</author-id>
            </authors>
        </paper>
        <paper id="paper-32664300">
            <title>A Combination of Hand-crafted and Hierarchical High-level Learnt Feature Extraction for Music Genre Classiﬁcation</title>
            <abstract>In this paper, we propose a new approach for automatic music genre classification which relies on learning a feature hierarchy with a deep learning architecture over hand-crafted feature extracted from an audio signal. Unlike the state-of-the-art approaches, our scheme uses an unsupervised learning algorithm based on Deep Belief Networks (DBN) learnt on block-wise MFCC (that we treat as 2D images), followed by a supervised learning algorithm for fine-tuning the extracted features. Experiments performed on the GTZAN dataset show that the proposed scheme clearly outperforms the state-of-the-art approaches.&#xD;
</abstract>
            <keywords>
                <keyword>music genre classification</keyword>
                <keyword>high-level hierarchy feature extraction</keyword>
                <keyword>deep learning</keyword>
                <keyword>deep belief networks</keyword>
            </keywords>
            <authors>
                <author-id>person-32664303</author-id>
                <author-id>person-32664307</author-id>
                <author-id>person-32663510</author-id>
                <author-id>person-32664305</author-id>
            </authors>
        </paper>
        <paper id="paper-32664726">
            <title>Exploration of loneliness questionnaires using the self-organising map</title>
            <abstract>Statistical machine learning methods can provide help when developing&#xD;
preventative services and tools that support the empowerment of&#xD;
individuals. We explore how the self-organizing map could be utilized&#xD;
as a tool for analyzing, visualizing and browsing heterogeneous survey&#xD;
data on wellbeing that contains both quantitative (numeric) and&#xD;
qualitative (text) data. &#xD;
There is systematic evidence implying that social isolation has&#xD;
drastic consequences for subjective well-being and health. It is&#xD;
important to obtain a deeper understanding of the phenomenon.&#xD;
Analysis of loneliness questionnaire data&#xD;
(N=521) succeeds in identifying profiles of loneliness as well as&#xD;
identifies crowd-sourced ideas for improving social wellbeing among&#xD;
the different subgroups.&#xD;
</abstract>
            <keywords>
                <keyword>self-organising maps</keyword>
                <keyword>social isolation</keyword>
                <keyword>health and wellbeing</keyword>
                <keyword>crowdsourcing</keyword>
            </keywords>
            <authors>
                <author-id>person-32664621</author-id>
                <author-id>person-32664731</author-id>
                <author-id>person-32664729</author-id>
                <author-id>person-45115</author-id>
            </authors>
        </paper>
        <paper id="paper-32664988">
            <title>An Effective Dynamic Gesture Recognition System based on the Feature Vector Reduction for SURF and LCS</title>
            <abstract>Speed Up Robust Feature (SURF) and Local Contour Sequence(LCS) are methods used for feature extraction techniques  for dynamic gesture recognition. A problem presented by these techniques is the large amount of data in the output vector which difficult the classification task. This paper presents a novel method for dimensionality reduction of the features extracted by SURF and LCS, called Convexity Approach. The proposed method is evaluated in a gesture recognition task and improves the recognition rate of LCS while SURF while decreases the amount of data in the output vector.</abstract>
            <keywords>
                <keyword>Gesture Recognition</keyword>
                <keyword>Pattern Recognition</keyword>
                <keyword>Neural Network</keyword>
                <keyword>Hidden Markov Model</keyword>
                <keyword>Dynamic Time Wrapper</keyword>
                <keyword>Feature Extraction</keyword>
            </keywords>
            <authors>
                <author-id>person-32664569</author-id>
                <author-id>person-32664995</author-id>
                <author-id>person-32664991</author-id>
                <author-id>person-32875016</author-id>
                <author-id>person-32275002</author-id>
                <author-id>person-32664993</author-id>
            </authors>
        </paper>
        <paper id="paper-32588975">
            <title>Feature Weighting by Maximum Distance Minimization</title>
            <abstract>The k-NN algorithm is still very popular due to its simplicity and the easy interpretability of the results. However, the often used Euclidean distance is an arbitrary choice for many datasets. It is arbitrary because often the data is described by measurements from different domains. Therefore, the Euclidean distance often leads to a bad classification rate of k-NN. By feature weighting the scaling of dimensions can be adapted and the classification performance can be significantly improved. We here present a simple linear programming based method for feature weighting, which in contrast to other feature weighting methods is robust to the initial scaling of the data dimensions. An evaluation is performed on real-world datasets from the UCI repository with comparison to other feature weighting algorithms and to Large Margin Nearest Neighbor Classification (LMNN) as a metric learning algorithm. </abstract>
            <keywords>
                <keyword>feature selection</keyword>
                <keyword>feature weighting</keyword>
                <keyword>metric learning</keyword>
                <keyword>k-Nearest-Neighbor</keyword>
                <keyword>Relief</keyword>
                <keyword>LMNN</keyword>
            </keywords>
            <authors>
                <author-id>person-32587518</author-id>
                <author-id>person-32277579</author-id>
            </authors>
        </paper>
        <paper id="paper-32624356">
            <title>Training Computationally Efficient Smartphone-Based Human Activity Recognition Models</title>
            <abstract>The exploitation of smartphones for Human Activity Recognition (HAR) has been an active research area in which the development of fast and efficient Machine Learning approaches is crucial for preserving battery life and reducing computational requirements. In this work, we present a HAR system which incorporates smartphone-embedded inertial sensors and uses Support Vector Machines (SVM) for the classification of Activities of Daily Living (ADL). By exploiting a publicly available benchmark HAR dataset, we show the benefits of adding smartphones gyroscope signals into the recognition system against the traditional accelerometer-based approach, and explore two feature selection mechanisms for allowing a radically faster recognition: the utilization of exclusively time domain features and the adaptation of the L1 SVM model which performs comparably to non-linear approaches while neglecting a large number of non-informative features.</abstract>
            <keywords>
                <keyword>Smartphones</keyword>
                <keyword>Human Activity Recognition</keyword>
                <keyword>SVM</keyword>
                <keyword>L1 SVM</keyword>
                <keyword>Feature Selection</keyword>
            </keywords>
            <authors>
                <author-id>person-75983</author-id>
                <author-id>person-75910</author-id>
                <author-id>person-32817687</author-id>
                <author-id>person-32624361</author-id>
                <author-id>person-32841763</author-id>
            </authors>
        </paper>
        <paper id="paper-32624407">
            <title>A Novel Procedure for Training L1-L2 Support Vector Machine Classifiers</title>
            <abstract>In this work we propose a novel algorithm for training L1-L2 Support Vector Machine (SVM) classifiers. L1-L2 SVMs allow to combine the effectiveness of L2 models and the feature selection characteristics of L1 solutions. The proposed training approach allows the exploitation of all the well-known effective and reliable tools already developed for conventional L2 SVMs, thus minimal effort is required by the user to implement L1-L2 model training. Moreover, the proposed method is flexible, as it allows to train L1, L1-L2 and L2 SVMs, as well as to fine tune the trade-off between dimensionality reduction and classification accuracy. The effectiveness of our approach is tested on a Human Activity Recognition real-world dataset.</abstract>
            <keywords>
                <keyword>Support Vector Machine</keyword>
                <keyword>Sequential Minimal Optimization algorithm</keyword>
                <keyword>L1-L2 Regularization</keyword>
                <keyword>Human Activity Recognition</keyword>
            </keywords>
            <authors>
                <author-id>person-75983</author-id>
                <author-id>person-75910</author-id>
                <author-id>person-32817687</author-id>
                <author-id>person-32841763</author-id>
                <author-id>person-75984</author-id>
            </authors>
        </paper>
        <paper id="paper-32643062">
            <title>Online Classiﬁcation of Eye Tracking Data for Automated Analysis of Traffic Hazard Perception</title>
            <abstract>Complex and hazardous driving situations often arise with the delayed perception of traﬃc objects. To automatically detect whether such objects have been perceived by the driver, there is a need for techniques that can reliably recognize whether the driver’s eyes have ﬁxated or are pursuing the hazardous object (i.e., detecting ﬁxations, saccades, and smooth pursuits from raw eye tracking data). This paper presents a system for analyzing the driver’s visual behavior based on an adaptive online algorithm for detecting and distinguishing between ﬁxation clusters, saccades, and smooth pursuits.&#xD;
</abstract>
            <keywords>
                <keyword>classiﬁcation</keyword>
                <keyword>eye data</keyword>
                <keyword>traffic hazard</keyword>
                <keyword>perception</keyword>
            </keywords>
            <authors>
                <author-id>person-32642975</author-id>
                <author-id>person-32815671</author-id>
                <author-id>person-32643067</author-id>
                <author-id>person-32643069</author-id>
                <author-id>person-52316</author-id>
            </authors>
        </paper>
        <paper id="paper-32642131">
            <title>Time-series forecasting of indoor temperature using pre-trained Deep Neural Networks</title>
            <abstract>Artificial neural networks have proved to be good at time-series forecasting problems, being widely studied at literature. Traditionally, shallow architectures were used due to convergence problems when dealing with deep models.  Recent research findings enable deep architectures training, opening a new interesting research area called deep learning. This paper presents a study of deep learning techniques applied to time-series forecasting in a real indoor temperature forecasting task, studying performance due to different hyper-parameter configurations. When using deep models, better generalization performance at test set and an overfitting reduction has been observed.</abstract>
            <keywords>
                <keyword>Artificial neural networks</keyword>
                <keyword>deep learning</keyword>
                <keyword>time series</keyword>
                <keyword>auto-encoders</keyword>
                <keyword>temperature forecasting</keyword>
                <keyword>energy efficiency</keyword>
            </keywords>
            <authors>
                <author-id>person-32652795</author-id>
                <author-id>person-32642063</author-id>
                <author-id>person-32642138</author-id>
                <author-id>person-32642136</author-id>
            </authors>
        </paper>
        <paper id="paper-32651597">
            <title> Recurrent Fuzzy-Neural Network with fast  learning algorithm for Predictive Control</title>
            <abstract>This paper presents a Takagi-Sugeno type recurrent fuzzy-neural network with a global feedback. To improve the predictions and to minimize the possible model oscillations, a hybrid learning procedure based on Gradient descent and the fast converging Gauss-Newton algorithms, is designed. The model performance is evaluated in prediction of two chaotic time series – Mackey-Glass and Rossler. The proposed recurrent fuzzy-neural network is coupled with analytical optimization approach in a Model Predictive Control scheme. The potentials of the obtained predictive controller are demonstrated by simulation experiments to control a nonlinear Continuous Stirred Tank Reactor.</abstract>
            <keywords>
                <keyword>recurrent fuzzy-neural networks</keyword>
                <keyword>Takagi-Sugeno</keyword>
                <keyword>predictive control</keyword>
                <keyword>optimization</keyword>
                <keyword>Gradient descent</keyword>
                <keyword>Gauss-Newton method</keyword>
                <keyword>momentum learning</keyword>
            </keywords>
            <authors>
                <author-id>person-32555774</author-id>
                <author-id>person-32891779</author-id>
                <author-id>person-32889721</author-id>
            </authors>
        </paper>
        <paper id="paper-32664573">
            <title>Real-Time Interface Board for Closed-Loop Robotic Tasks on the SpiNNaker Neural Computing System</title>
            <abstract>Various custom hardware solutions for simulation of neural circuitry have recently been developed, each focusing on particular aspects such as low power operation, high computation speed, or biologically detailed simulations. The spiNNaker computing system has been developed to simulate large spiking neural circuits in real-time in a network of parallel operating microcontrollers, interconnected by a high-speed asynchronous interface. A potential application area is autonomous mobile robotics, which would tremendously benefit from on-board simulations of networks of tens of thousands of spiking neurons in real time. Currently, the spiNNaker hardware only provides a single Ethernet interface for booting, debug, and input and output of data, which results in a severe bottleneck for sensory perception and motor control signals. This paper describes a small and flexible real-time I/O-hardware interface to connect external devices such as robotic sensors and actuators directly to the fast asynchronous internal communication infrastructure of the spiNNaker neural computing system. We evaluate performance in terms of package throughput and present a simple application demonstration of a closed loop mobile robot interpreting visual data to approach the most salient stimulus.</abstract>
            <keywords>
                <keyword>massive parallel simulation of spiking neurons</keyword>
                <keyword>spiNNaker</keyword>
                <keyword>hardware interface board</keyword>
                <keyword>mobile robotics</keyword>
            </keywords>
            <authors>
                <author-id>person-32879054</author-id>
                <author-id>person-32818512</author-id>
                <author-id>person-32817638</author-id>
                <author-id>person-32664576</author-id>
                <author-id>person-32817650</author-id>
                <author-id>person-90477</author-id>
            </authors>
        </paper>
        <paper id="paper-32664491">
            <title>A Software Framework for Cognition, Embodiment, Dynamics, and Autonomy in Robotics: cedar</title>
            <abstract>We present cedar, a software framework for the implementation and simulation of embodied cognitive models based on Dynamic Field Theory (DFT). DFT is a neurally inspired theoretical framework that integrates perception, action, and cognition. cedar captures the power of DFT in software by facilitating the process of software development for embodied cognitive systems, both artificial and as models of human cognition. In cedar, models can be designed through a graphical interface and interactively tuned. We demonstrate this by implementing an exemplary robotic architecture.</abstract>
            <keywords>
                <keyword>software framework</keyword>
                <keyword>embodied cognition</keyword>
                <keyword>neural dynamics</keyword>
                <keyword>Dynamic Field Theory</keyword>
                <keyword>cognitive robotic models</keyword>
            </keywords>
            <authors>
                <author-id>person-32637568</author-id>
                <author-id>person-32664496</author-id>
                <author-id>person-32664498</author-id>
                <author-id>person-32876440</author-id>
                <author-id>person-32693457</author-id>
            </authors>
        </paper>
        <paper id="paper-32574917">
            <title>Adaptive Critic Neural Network Solution of Optimal Control Problems with Delays in State and Control Variables</title>
            <abstract>A neural network based optimal control synthesis is presented for solving optimal control problems with delays in state and control variables subject to  control and state constraints. The optimal control problem is transcribed into nonlinear programming problem which is implemented with adaptive critic neural network.&#xD;
The proposed simulation methods is illustrated by an analytical example and the optimal control problem of nitrogen transformation cycle model with discrete time delay of nutrient uptake.&#xD;
Results show that adaptive critic based systematic approach are promising in obtaining the optimal control with delays in state and control variables subject to control and state constraints. </abstract>
            <keywords>
                <keyword>optimal control problem with delays</keyword>
                <keyword>state and control constraints</keyword>
                <keyword>recurrent neural network</keyword>
                <keyword>adaptive critic synthesis</keyword>
                <keyword>numerical examples</keyword>
                <keyword>nitrogen transformation cycle</keyword>
            </keywords>
            <authors>
                <author-id>person-32574901</author-id>
                <author-id>person-32605374</author-id>
            </authors>
        </paper>
        <paper id="paper-32615667">
            <title>Emotion Generation System considering Complex Emotion based on MaC Model with Neural Networks</title>
            <abstract>In this paper, we propose an emotion generation system considering complex emotion based on MaC model using neural networks. In the proposed system, the chaotic neural network and the Kohonen Feature Map (KFM) associative memory are used in the Emotion Generator of the MaC model. The proposed system makes use of the probabilistic association ability of the KFM associative memory in order to generate different emotions for same external input. And, the proposed system makes use of the dynamic association ability of the chaotic neural network in order to generate emotions based on its history. Moreover, the proposed model can deal with not only basic emotions but also complex emotions.&#xD;
</abstract>
            <keywords>
                <keyword>Emotion Generation System</keyword>
                <keyword>Complex Emotion</keyword>
                <keyword>MaC Model</keyword>
                <keyword>Chaotic Neural Network</keyword>
                <keyword>Kohonen Feature Map Associative Memory</keyword>
            </keywords>
            <authors>
                <author-id>person-32615670</author-id>
                <author-id>person-90928</author-id>
            </authors>
        </paper>
        <paper id="paper-32644858">
            <title>Neuro-Optimal Controller for Robot Manipulators</title>
            <abstract>This paper presents an algorithm for continuous-time quadratic optimization with neural compensation of motion control. A simpler reformulation explicit solution to the Hamilton-Jacobi-Bellman equation for optimal control of rigid robot motion is found by solving an algebraic Riccati matrix equation. The system stability is investigated according to Lyapunov function theory and it is shown that global asymptotic stability holds in the case of known system model. It is also shown how optimal control and neural control may act in concert in the case of unknown system model. The neural algorithm is derived from Lyapunov stability analysis, so that both system-tracking stability and error convergence can be guaranteed in the closed-loop system. Experimental and simulation results from a two-link robot manipulator show the satisfactory performance of the proposed control schemes.</abstract>
            <keywords>
                <keyword>Optimal control</keyword>
                <keyword>neural networks</keyword>
                <keyword>robotic control</keyword>
            </keywords>
            <authors>
                <author-id>person-32644860</author-id>
                <author-id>person-32644854</author-id>
            </authors>
        </paper>
        <paper id="paper-32664845">
            <title>Learning to walk using a Recurrent neural network with time delay</title>
            <abstract>Abstract. Walking based on gaits is one of the most approved methodologies for walking robot. In this paper, we develop learning strategy for walking biped robot or human based on a self made database using biomechanical capture. This system is provided by a Recurrent Neural Network (RNN) with an internal discrete time delay. &#xD;
The role of the proposed network is the training of human walking data by giving an estimation of the biped's next position at each time and achieve a human-like natural walking. Different architectures of RNN are proposed and tested.&#xD;
In Particular, a comparative study is given and the results of the RNN mixed with extended Kalman filter are illustrated.</abstract>
            <keywords>
                <keyword>Human walking</keyword>
                <keyword>3D human simulator</keyword>
                <keyword>Recurrent Neural Network</keyword>
                <keyword>Biomechanics</keyword>
                <keyword>e-kalman filter</keyword>
            </keywords>
            <authors>
                <author-id>person-32608416</author-id>
                <author-id>person-32772947</author-id>
                <author-id>person-93172</author-id>
                <author-id>person-32475605</author-id>
                <author-id>person-32664847</author-id>
                <author-id>person-32664848</author-id>
            </authors>
        </paper>
        <paper id="paper-32613220">
            <title>The Imbalance Network and Incremental Evolution for Mobile Robot Nervous System Design</title>
            <abstract>Automatic design of neurocontrollers (as in Evoluationary Robotics) utilizes incremental evolution to solve for more complex behaviors. Also manual design techniques such as task decomposition are employed. Manual design itself can benefit from focusing on using incremental evolution to add more automatic design. The imbalance network is a neural network that integrates incremental evolution with an incremental design process without the need for task decomposition. Instead, the imbalance network uses the mechanism of the equilibrium-action cycle to structure the network while emphasizing behavior emergence. An example 11-step design (including a 5-step evolutionary process) is briefly mentioned to help ground the imbalance network concepts.</abstract>
            <keywords>
                <keyword>imbalance network</keyword>
                <keyword>equilibrium-action cycle</keyword>
                <keyword>incremental evolution</keyword>
                <keyword>emergence</keyword>
                <keyword>task decomposition</keyword>
            </keywords>
            <authors>
                <author-id>person-32608984</author-id>
                <author-id>person-32613222</author-id>
            </authors>
        </paper>
        <paper id="paper-32676609">
            <title>Balancing of a Simulated Inverted Pendulum Using the NeuraBASE Network Model</title>
            <abstract>This paper presents an alternative approach for the control and balancing operations of a simulated inverted pendulum. The proposed method uses a neuronal network called NeuraBase to learn the sensor events obtained via a simulated rotary encoder and a simulated stepper motor, which rotates the swinging arm. A neuron layer called the controller network will link the sensor neuron events to the motor neurons. The proposed NeuraBase network model (NNM) has demonstrated its ability to successfully control the balancing operation of the pendulum, in the absence of a dynamic model and theoretical control methods.</abstract>
            <keywords>
                <keyword>Neural Network</keyword>
                <keyword>Inverted Pendulum</keyword>
            </keywords>
            <authors>
                <author-id>person-32676612</author-id>
                <author-id>person-32878974</author-id>
                <author-id>person-32647230</author-id>
            </authors>
        </paper>
        <paper id="paper-32664662">
            <title>Coordinated Rule Acquisition of Decision Making on Supply Chain by  Exploitation-oriented Reinforcement Learning -Beer Game as an Example-</title>
            <abstract>Decision-making of product order is an important problem in inventory control on a supply chain. Beer game is a typical task in&#xD;
such a problem. Recently, various approaches which apply agent model to a beer game are proposed widely. In beer game task, it has been reported&#xD;
that the result in which the Q-learning is better than Genetic Algorithms (GA) is obtained. However, the flexible adaptation to the&#xD;
dynamics of dynamic environment is difficult for these approaches, because these learning algorithms assume static environment. On the other&#xD;
hand, exploitation-oriented reinforcement learning algorithm is robust in dynamic environment. In this study, we solve these problems, by using&#xD;
profit sharing which is typical exploitation-oriented agent learning algorithm. Furthermore, we verify validity by comparing such performances.&#xD;
abstract environment.</abstract>
            <keywords>
                <keyword>Reinforcement Learning</keyword>
                <keyword>Agent Based Modeling</keyword>
                <keyword>Suppy ChainManegiment(SCM)</keyword>
                <keyword>Beer Game</keyword>
                <keyword>Exploitation-oriented Learning</keyword>
            </keywords>
            <authors>
                <author-id>person-32664077</author-id>
                <author-id>person-32664664</author-id>
            </authors>
        </paper>
        <paper id="paper-32593286">
            <title>Using Exponential Kernel for Word Sense Disambiguation</title>
            <abstract>The success of machine learning approaches to word sense disambiguation (WSD) is largely dependent on the representation of the context in which an ambiguous word occurs. Typically, the contexts are represented as the vector space using ”Bag of Words (BoW)” technique. Despite its ease of use, BoW representation suffers from well-known limitations, mostly due to its inability to exploit semantic similarity between terms. In this paper, we apply the exponential kernel, which models semantic similarity by means of a diffusion process on a graph defined by lexicon and co-occurrence information, to smooth the BoW representation for WSD. Exponential kernel virtually exploits higher order co-occurrences to infer semantic similarities in an elegant way. The superiority of the proposed method is demonstrated experimentally with several SensEval disambiguation tasks. </abstract>
            <keywords>
                <keyword>Word sense disambiguation (WSD)</keyword>
                <keyword>Exponential kernel</keyword>
                <keyword>Support vector machine (SVM)</keyword>
                <keyword>Kernel method</keyword>
                <keyword>Natural language processing</keyword>
            </keywords>
            <authors>
                <author-id>person-32588081</author-id>
                <author-id>person-32593288</author-id>
                <author-id>person-32593289</author-id>
            </authors>
        </paper>
        <paper id="paper-32599616">
            <title>Independent Component Analysis filtration for Value at Risk modelling</title>
            <abstract>In this article we present independent component analysis (ICA) applied to the concept of value at risk (VaR) modelling. The use of ICA decomposition enables to extract components with particular statistical properties that can be interpreted in economic terms. However, the characteristic of financial time series, in particular the nonstationarity in terms of higher order statistics, makes it difficult to apply ICA to VaR right away. This requires using adequate ICA algorithms or their modification taking into account the statistical characteristics of financial data.</abstract>
            <keywords>
                <keyword>Value at Risk</keyword>
                <keyword>Independent Component Analysis</keyword>
                <keyword>financial time series analysis</keyword>
            </keywords>
            <authors>
                <author-id>person-32396748</author-id>
                <author-id>person-32396756</author-id>
                <author-id>person-32599619</author-id>
            </authors>
        </paper>
        <paper id="paper-32613517">
            <title>Wind Power Resource Estimation with Deep Neural Networks</title>
            <abstract>The measure-correlate-predict technique is state-of-the-art for assessing the quality of a wind power resource based on long term numerical weather prediction systems. On-site wind speed measurements are correlated to meteorological reanalysis data, which represent the best historical estimate available for the atmospheric state. The different variants of MCP more or less correct the statistical main attributes by making the meteorological reanalyses bias and scaling free using the on-site measurements. However, by neglecting the higher order correlations none of the variants utilize the full potential of the measurements. We show that deep neural networks make use of these higher order correlations. Our implementation is tailored to the requirements of MCP in the context of wind resource assessment. We show the application of this method to a set of different locations and compare the results to a simple linear fit to the wind speed frequency distribution as well as to a standard linear regression MCP, that represents the state-of-the-art in industrial aerodynamics. The neural network based MCP outperforms both other methods with respect to correlation, root-mean-square error and the distance in the wind speed frequency distribution. Site assessment can be considered one of the most important steps developing a wind energy project. To this end, the approach described can be regarded as a novel, high-quality tool for reducing uncertainties in the long-term reference problem of on-site measurements.</abstract>
            <keywords>
                <keyword>Deep Neural Networks</keyword>
                <keyword>Renewable Energy</keyword>
                <keyword>Neural Network Applications</keyword>
            </keywords>
            <authors>
                <author-id>person-32603077</author-id>
                <author-id>person-32802568</author-id>
                <author-id>person-32613522</author-id>
                <author-id>person-32613524</author-id>
                <author-id>person-32613528</author-id>
                <author-id>person-32613526</author-id>
            </authors>
        </paper>
        <paper id="paper-32623267">
            <title>Wavelet Neural Networks for Electricity Load Forecasting – Dealing with Border Distortion and Shift Invariance</title>
            <abstract>We consider a wavelet neural network approach for electricity load prediction. The wavelet transform is used to decompose the load into different frequency components that are predicted separately using neural networks. We firstly propose a new approach for signal extension which minimizes the border distortion when decomposing the data, outperforming three standard methods. We also compare the performance of the standard wavelet transform, which is shift variant, with a non-decimated transform, which is shift invariant. Our results show that the use of shift invariant transform considerably improves the prediction accuracy. In addition to wavelet neural network, we also present the results of wavelet linear regression, wavelet model trees and a number of baselines. Our evaluation uses two years of Australian electricity data. </abstract>
            <keywords>
                <keyword>electricity load forecasting</keyword>
                <keyword>wavelet-based neural networks</keyword>
            </keywords>
            <authors>
                <author-id>person-32805438</author-id>
                <author-id>person-47052</author-id>
            </authors>
        </paper>
        <paper id="paper-32636421">
            <title>Interactive Two-Level WEBSOM for Organizational Exploration</title>
            <abstract>This article introduces a novel development in WEBSOM research for interactive visualization of document collections. The Interactive Two-Level WEBSOM, I2WEBSOM, includes two main components, a map of terms, and a dynamic map of documents. The map of terms is used to enable interactive feature selection and weighting. The map of documents is calculated using terminology-based feature vectors where their weights can be changed using the first-level map. In the experimental part, we focus on the application of creating maps of people based on their interest or competence profiles.</abstract>
            <keywords>
                <keyword>text mining</keyword>
                <keyword>self-organizing map</keyword>
                <keyword>visualization</keyword>
                <keyword>competence management</keyword>
            </keywords>
            <authors>
                <author-id>person-45115</author-id>
                <author-id>person-32896316</author-id>
            </authors>
        </paper>
        <paper id="paper-32642626">
            <title>Optimal Operation of Electric Power Production System without Transmission Losses using Artificial Neural Networks based on Augmented Lagrange Multiplier Method</title>
            <abstract>The optimal economic operation of a thermal electric power production system without considering transmission losses is a critical problem for ships, aircrafts, island power systems and it is usually solved with Lagrange method. In this paper, an alternative solution method is proposed using artificial neural networks (ANN) based on augmented Lagrange multiplier method with equality and inequality constraints. The respective theoretical analysis is presented, while a specific case study is studied. The advantages and disadvantages of the method are discussed and compared with the classical Lagrange method and ANN method based on external penalty functions.</abstract>
            <keywords>
                <keyword>ANN</keyword>
                <keyword>economic dispatch</keyword>
                <keyword>thermal power system</keyword>
            </keywords>
            <authors>
                <author-id>person-32642633</author-id>
                <author-id>person-32642629</author-id>
                <author-id>person-32642631</author-id>
                <author-id>person-32555480</author-id>
            </authors>
        </paper>
        <paper id="paper-32643335">
            <title>An Echo State Network with Working Memories for Probabilistic Language Modeling</title>
            <abstract>In this paper, we propose an ESN having multiple timescale layer and working memories as a probabilistic language model.&#xD;
The reservoir of the proposed model is composed of three neuron groups each with an associated time constant,&#xD;
which enables the model to learn the hierarchical structure of language.&#xD;
We add working memories to enhance the effect of multiple timescale layers.&#xD;
As shown by the experiments, the proposed model can be trained efficiently and accurately to predict the next word from given words.&#xD;
In addition, we found that use of working memories is especially effective in learning grammatical structure.</abstract>
            <keywords>
                <keyword>Probabilistic language model</keyword>
                <keyword>ESNs</keyword>
                <keyword>working memory</keyword>
            </keywords>
            <authors>
                <author-id>person-32640650</author-id>
                <author-id>person-32643338</author-id>
            </authors>
        </paper>
        <paper id="paper-32622184">
            <title>Using the Analytic Feature Framework for the Detection of Occluded Objects</title>
            <abstract>In this paper we apply the analytic feature framework, which was originally proposed for the large scale identification of segmented objects, for object detection in complex traffic scenes. We describe the necessary adaptations and show the competitiveness of the framework on different real-world data&#xD;
sets. Similar to the current state-of-the-art, the evaluation reveals a strong degradation of performance with increasing occlusion of the objects. We shortly discuss possible steps to tackle this problem and numerically analyze typical occlusion cases for a car detection task. Motivated by the fact that most cars are occluded by other cars, we present first promising results for a framework that uses separate classifiers for unoccluded and occluded cars and takes their&#xD;
mutual response characteristic into account. This training procedure can be applied to many other trainable detection approaches.</abstract>
            <keywords>
                <keyword>Object detection</keyword>
                <keyword>Supervised learning</keyword>
                <keyword>Occlusion handling</keyword>
            </keywords>
            <authors>
                <author-id>person-32598791</author-id>
                <author-id>person-32622189</author-id>
                <author-id>person-32871076</author-id>
            </authors>
        </paper>
        <paper id="paper-32633793">
            <title>Boltzmann Machines for Image Denoising</title>
            <abstract>Image denoising based on a probabilistic model of local&#xD;
image patches has been employed by various researchers,&#xD;
and recently a deep denoising autoencoder has been&#xD;
proposed by Burger et al. (2012) and Xie et al. (2012) as a&#xD;
good model for this.  In this paper, we propose that&#xD;
another popular family of models in the field of&#xD;
deep learning, called Boltzmann machines, can&#xD;
perform image denoising as well as, or in certain cases&#xD;
of high level of noise, better than denoising&#xD;
autoencoders. We empirically evaluate these two models&#xD;
on three different sets of images with different types&#xD;
and levels of noise.  The experiments confirmed our&#xD;
claim and revealed that the denoising performance can be&#xD;
improved by adding more hidden layers, especially when&#xD;
the level of noise is high.&#xD;
</abstract>
            <keywords>
                <keyword>Image Denoising</keyword>
                <keyword>Deep Learning</keyword>
                <keyword>Restricted Boltzmann Machine</keyword>
                <keyword>Deep Boltzmann Machine</keyword>
            </keywords>
            <authors>
                <author-id>person-74124</author-id>
            </authors>
        </paper>
        <paper id="paper-32613554">
            <title>Comparison on Late Fusion Methods of Low Level Features for Content Based Image Retrieval</title>
            <abstract>Finding the right feature for image representation is an important key to attaining successful Content Based Image Retrieval (CBIR) system. This choice depends on the content of images to be searched. Today’s real world image databases are heterogeneous and consist of images that can be described&#xD;
appropriately using different feature types. One approach to deal with this is to utilize late fusion methods. That is, the CBIR system must be able to fuse multiple results produced by each feature. In this paper by experimental comparison of output results achieved from eleven low-level features over three image databases an appropriate several sets of features are selected and five late fusion methods are applied over each set. By analysis of the results for all methods it has been shown which ones reach the best performances and stable&#xD;
retrieval accuracy among the investigated image databases and sets of features.</abstract>
            <keywords>
                <keyword>Content Based Image Retrieval</keyword>
                <keyword>Late Fusion</keyword>
                <keyword>LIRe</keyword>
            </keywords>
            <authors>
                <author-id>person-32613422</author-id>
            </authors>
        </paper>
        <paper id="paper-32682930">
            <title>Vehicle plate recognition using improved neocognitron neural network</title>
            <abstract>This paper describes a novel vehicle plate recognition algorithm based on text detection and improved neocognitron neural network, similar to [1] and based on Fukushima's neocognitron. The proposed recognition algorithm allows us to improve the recognition speed and accuracy comparing to both traditional neocognitron and some state-of-art algorithms (multilayer perceptron, topological methods). It can be used as a solution for image classification and analysis tasks. As an example, the neocognitron can be utilized for symbols recognition [2]. We propose several modifications comparing to the Fukushima's modification of the neocognitron: namely, layer dimensions adjustment, threshold function and connection Gaussian kernel parameters estimation. The patterns' width and height are taken into account independently in order to improve the recognition of patterns of slightly different dimensions. The learning and recognition calculations are performed as FFT convolutions in order to overcome the complexity of the neocognitron output calculations. The algorithm was tested on low-resolution (360_288) video sequences and gave more accurate results comparing to the state-of-the-art methods for low-resolution test set.</abstract>
            <keywords>
                <keyword>vehicle plates recognition</keyword>
                <keyword>image segmentation</keyword>
                <keyword>Chan-Vese algorithm</keyword>
                <keyword>neocognitron neural network</keyword>
            </keywords>
            <authors>
                <author-id>person-32682932</author-id>
                <author-id>person-32682933</author-id>
                <author-id>person-32647922</author-id>
            </authors>
        </paper>
    </papers>
    <organizations>
        <organization id="suny-stony-brook">
            <name>SUNY Stony Brook</name>
            <country>United States</country>
        </organization>
        <organization id="no-organization-present">
            <name>no-organization-present</name>
        </organization>
        <organization id="universita-di-pisa">
            <name>Universita` di Pisa</name>
            <country>Italy</country>
        </organization>
        <organization id="university-of-hamburg">
            <name>University of Hamburg</name>
        </organization>
        <organization id="universitt-hamburg">
            <name>Universität Hamburg</name>
            <country>Germany</country>
        </organization>
        <organization id="university-of-genova">
            <name>University of Genova</name>
            <country>Italy</country>
        </organization>
        <organization id="democritus-university-of-thrace">
            <name>Democritus University of Thrace</name>
            <country>Greece</country>
        </organization>
        <organization id="tu-mnchen">
            <name>TU München</name>
            <country>Germany</country>
        </organization>
        <organization id="berlin-institute-of-technology">
            <name>Berlin Institute of Technology</name>
            <country>Germany</country>
        </organization>
        <organization id="university-of-milano">
            <name>University of Milano</name>
            <country>Italy</country>
        </organization>
        <organization id="university-of-york">
            <name>University of York</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="idiap-research-institute">
            <name>Idiap Research Institute</name>
            <country>Switzerland</country>
        </organization>
        <organization id="ibm">
            <name>IBM</name>
            <country>Japan</country>
        </organization>
        <organization id="university-of-sheffield">
            <name>University of Sheffield</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="ku-leuven">
            <name>KU Leuven</name>
            <country>Belgium</country>
        </organization>
        <organization id="technical-university-sofia">
            <name>Technical University Sofia</name>
            <country>Bulgaria</country>
        </organization>
        <organization id="university-of-aveiro">
            <name>University of Aveiro</name>
            <country>Portugal</country>
        </organization>
        <organization id="universitt-greifswald">
            <name>Universität Greifswald</name>
            <country>Germany</country>
        </organization>
        <organization id="university-of-ioannina">
            <name>University of Ioannina</name>
            <country>Greece</country>
        </organization>
        <organization id="university-of-otago">
            <name>University of Otago</name>
            <country>New Zealand</country>
        </organization>
        <organization id="ulm-university">
            <name>Ulm University</name>
            <country>Germany</country>
        </organization>
        <organization id="institute-for-cross-disciplinary-physics-and-complex-systems">
            <name>Institute for Cross-Disciplinary Physics and Complex Systems</name>
            <country>Spain</country>
        </organization>
        <organization id="plymouth-university">
            <name>Plymouth University</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="university-of-milan">
            <name>University of Milan</name>
            <country>Italy</country>
        </organization>
        <organization id="institute-of-computer-science-ascr">
            <name>Institute of Computer Science, ASCR</name>
            <country>Czech Republic</country>
        </organization>
        <organization id="kyushu-institute-of-technology">
            <name>Kyushu Institute of Technology</name>
            <country>Japan</country>
        </organization>
        <organization id="merl">
            <name>MERL</name>
            <country>Japan</country>
        </organization>
        <organization id="university-of-naples-parthenope">
            <name>University of Naples Parthenope</name>
            <country>Italy</country>
        </organization>
        <organization id="university-of-bristol">
            <name>University of Bristol</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="university-of-stirling">
            <name>University of Stirling</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="harvard-medical-school">
            <name>Harvard Medical School</name>
            <country>United States</country>
        </organization>
        <organization id="university-of-manchester">
            <name>University of Manchester</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="university-of-edinburgh">
            <name>University of Edinburgh</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="aalto-university">
            <name>Aalto University</name>
            <country>Finland</country>
        </organization>
        <organization id="ecole-normale-superieure">
            <name>Ecole Normale Superieure</name>
            <country>France</country>
        </organization>
        <organization id="university-of-antwerpen">
            <name>University of Antwerpen</name>
            <country>Belgium</country>
        </organization>
        <organization id="ruhr-universitt-bochum">
            <name>Ruhr-Universität Bochum</name>
            <country>Germany</country>
        </organization>
        <organization id="honda-research-institute-europe">
            <name>Honda Research Institute Europe</name>
            <country>Germany</country>
        </organization>
        <organization id="hellenic-open-university">
            <name>Hellenic Open University</name>
            <country>Greece</country>
        </organization>
        <organization id="comenius-university-in-bratislava">
            <name>Comenius University in Bratislava</name>
            <country>Slovakia</country>
        </organization>
        <organization id="hiroshima-city-university">
            <name>Hiroshima City University</name>
            <country>Japan</country>
        </organization>
        <organization id="czech-technical-university-in-prague">
            <name>Czech Technical University in Prague</name>
            <country>Czech Republic</country>
        </organization>
        <organization id="federal-university-of-pernambuco">
            <name>Federal University of Pernambuco</name>
            <country>Brazil</country>
        </organization>
        <organization id="institute-of-computer-science-academy-of-sciences-of-the-czech-republic">
            <name>Institute of Computer Science, Academy of Sciences of the Czech Republic</name>
            <country>Czech Republic</country>
        </organization>
        <organization id="royal-holloway-university-of-london">
            <name>Royal Holloway, University of London</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="university-of-cincinnati">
            <name>University of Cincinnati</name>
            <country>United States</country>
        </organization>
        <organization id="university-of-zurich-and-eth-zurich">
            <name>University of Zurich and ETH Zurich</name>
            <country>Switzerland</country>
        </organization>
        <organization id="okinawa-institute-of-science-and-technology-graduate-university">
            <name>Okinawa Institute of Science and Technology Graduate University</name>
            <country>Japan</country>
        </organization>
        <organization id="universit-paris-">
            <name>Université Paris 1</name>
            <country>France</country>
        </organization>
        <organization id="universidade-do-estado-do-rio-de-janeiro">
            <name>Universidade do Estado do Rio de Janeiro</name>
            <country>Brazil</country>
        </organization>
        <organization id="university-of-padova">
            <name>University of Padova</name>
            <country>Italy</country>
        </organization>
        <organization id="iict---bas">
            <name>IICT - BAS</name>
            <country>Bulgaria</country>
        </organization>
        <organization id="universit-degli-studi-di-napoli">
            <name>Università degli Studi di Napoli</name>
        </organization>
        <organization id="ubi---univ-beira-interior">
            <name>UBI - Univ. Beira Interior</name>
            <country>Portugal</country>
        </organization>
        <organization id="university-of-ulm">
            <name>University of Ulm</name>
            <country>Germany</country>
        </organization>
        <organization id="university-of-chile">
            <name>University of Chile</name>
            <country>Chile</country>
        </organization>
        <organization id="nikon-corporation">
            <name>Nikon Corporation</name>
            <country>Japan</country>
        </organization>
        <organization id="university-of-sydney">
            <name>University of Sydney</name>
            <country>Australia</country>
        </organization>
        <organization id="national-research-council-of-italy">
            <name>National Research Council of Italy</name>
            <country>Italy</country>
        </organization>
        <organization id="tallinn-university-of-technology">
            <name>Tallinn University of Technology</name>
        </organization>
        <organization id="aristotle-university-of-thessaloniki">
            <name>Aristotle University of Thessaloniki</name>
            <country>Greece</country>
        </organization>
        <organization id="sofia-university">
            <name>Sofia University</name>
            <country>Bulgaria</country>
        </organization>
        <organization id="university-of-lausanne">
            <name>University of Lausanne</name>
            <country>Switzerland</country>
        </organization>
        <organization id="macquarie-university">
            <name>Macquarie University</name>
            <country>Australia</country>
        </organization>
        <organization id="babes-bolyai-university">
            <name>Babes Bolyai University</name>
            <country>Romania</country>
        </organization>
        <organization id="ifsttar">
            <name>IFSTTAR</name>
            <country>France</country>
        </organization>
        <organization id="osaka-university">
            <name>Osaka University</name>
            <country>Japan</country>
        </organization>
        <organization id="insitute-of-cognitive-science-university-of-osnabrueck">
            <name>Insitute of Cognitive Science, University of Osnabrueck</name>
            <country>Germany</country>
        </organization>
        <organization id="university-of-osnabrck">
            <name>University of Osnabrück</name>
            <country>Germany</country>
        </organization>
        <organization id="institute-of-cognitive-science">
            <name>Institute of Cognitive Science</name>
        </organization>
        <organization id="university-of-macedonia-greece">
            <name>University of Macedonia, Greece</name>
            <country>Greece</country>
        </organization>
        <organization id="a-of-thessaloniki">
            <name>A.Τ.Ε.Ι. of Thessaloniki</name>
            <country>Greece</country>
        </organization>
        <organization id="scientific-research-institute-for-system-analysis-of-russian-academy-of-sciences">
            <name>Scientific-Research Institute for System Analysis of Russian Academy of Sciences</name>
            <country>Russia</country>
        </organization>
        <organization id="unil">
            <name>UNIL</name>
            <country>Switzerland</country>
        </organization>
        <organization id="universidad-autonoma-de-madrid">
            <name>Universidad Autonoma de Madrid</name>
            <country>Spain</country>
        </organization>
        <organization id="issats-laboratory-of-math-physics-specials-functions-and-applications">
            <name>ISSATS, Laboratory of Math Physics; Specials Functions and Applications</name>
            <country>Tunisia</country>
        </organization>
        <organization id="national-school-of-engineers-of-sfax-university-of-sfax">
            <name>National School of Engineers of Sfax, University of Sfax</name>
        </organization>
        <organization id="university-of-sfax">
            <name>University of Sfax</name>
            <country>Tunisia</country>
        </organization>
        <organization id="university-of-siena">
            <name>University of Siena</name>
            <country>Italy</country>
        </organization>
        <organization id="wroclaw-university-of-technology">
            <name>Wroclaw University of Technology</name>
            <country>Poland</country>
        </organization>
        <organization id="brain-science-institute-riken">
            <name>Brain Science Institute, RIKEN</name>
            <country>Japan</country>
        </organization>
        <organization id="university-of-a-corua">
            <name>University of A Coruña</name>
            <country>Spain</country>
        </organization>
        <organization id="center-for-solar-energy-and-hydrogen-research">
            <name>Center for Solar Energy and Hydrogen Research</name>
            <country>Germany</country>
        </organization>
        <organization id="faculty-of-mathematics-physics-and-informatics-comenius-university-in-bratislava">
            <name>Faculty of Mathematics, Physics and Informatics, Comenius University in Bratislava</name>
            <country>Slovakia</country>
        </organization>
        <organization id="kobe-university">
            <name>Kobe University</name>
            <country>Japan</country>
        </organization>
        <organization id="bielefeld-university">
            <name>Bielefeld University</name>
            <country>Germany</country>
        </organization>
        <organization id="lancaster-university">
            <name>Lancaster University</name>
            <country>Russia</country>
        </organization>
        <organization id="ktu">
            <name>KTU</name>
            <country>Lithuania</country>
        </organization>
        <organization id="kaunas-university-of-technology">
            <name>Kaunas University of Technology</name>
        </organization>
        <organization id="wilhelm-schikard-institute">
            <name>Wilhelm-Schikard Institute</name>
            <country>Germany</country>
        </organization>
        <organization id="technische-universitt-mnchen">
            <name>Technische Universität München</name>
            <country>Germany</country>
        </organization>
        <organization id="university-of-surrey">
            <name>University of Surrey</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="institute-of-cognitive-sciences">
            <name>Institute of Cognitive Sciences</name>
            <country>Germany</country>
        </organization>
        <organization id="university-of-hertfordshire">
            <name>University of Hertfordshire</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="polytechnic-school-universidad-carlos-iii-de-madrid">
            <name>Polytechnic School Universidad Carlos III de Madrid</name>
            <country>Spain</country>
        </organization>
        <organization id="university-carlos-iii-of-madrid">
            <name>University Carlos III of Madrid</name>
            <country>Spain</country>
        </organization>
        <organization id="lsus">
            <name>LSUS</name>
            <country>United States</country>
        </organization>
        <organization id="lsu-shreveport">
            <name>LSU Shreveport</name>
            <country>United States</country>
        </organization>
        <organization id="ilmenau-university-of-technology">
            <name>Ilmenau University of Technology</name>
            <country>Germany</country>
        </organization>
        <organization id="university-of-sunderland">
            <name>University of Sunderland</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="the-open-university">
            <name>The Open University</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="orange-labs">
            <name>Orange Labs</name>
            <country>France</country>
        </organization>
        <organization id="insa-de-lyon">
            <name>INSA de Lyon</name>
            <country>France</country>
        </organization>
        <organization id="university-of-pernambuco">
            <name>University of Pernambuco</name>
            <country>Brazil</country>
        </organization>
        <organization id="universidade-de-pernambuco">
            <name>Universidade de Pernambuco</name>
            <country>Brazil</country>
        </organization>
        <organization id="university-of-genoa">
            <name>University of Genoa</name>
            <country>Italy</country>
        </organization>
        <organization id="universidad-politecnica-de-catalunya">
            <name>Universidad Politecnica de Catalunya</name>
        </organization>
        <organization id="university-ceu-cardenal-herrera">
            <name>University CEU Cardenal Herrera</name>
            <country>Spain</country>
        </organization>
        <organization id="universidad-ceu-cardenal-herrera">
            <name>Universidad CEU-Cardenal Herrera</name>
            <country>Spain</country>
        </organization>
        <organization id="institute-of-information-and-communication-technologies-bulgarian-academy-of-sciences">
            <name>Institute of Information and Communication Technologies, Bulgarian Academy of Sciences</name>
            <country>Bulgaria</country>
        </organization>
        <organization id="technical-university-sofia-branch-plovdiv">
            <name>Technical University Sofia, branch Plovdiv</name>
            <country>Bulgaria</country>
        </organization>
        <organization id="university-of-ulster">
            <name>University of Ulster</name>
            <country>United Kingdom</country>
        </organization>
        <organization id="cpu-in-nitra">
            <name>CPU in Nitra</name>
            <country>Slovakia</country>
        </organization>
        <organization id="tokyo-university-of-technology">
            <name>Tokyo University of Technology</name>
            <country>Japan</country>
        </organization>
        <organization id="univ-jijel">
            <name>Univ Jijel</name>
            <country>Algeria</country>
        </organization>
        <organization id="enis">
            <name>ENIS</name>
        </organization>
        <organization id="neuramatix-sdn-bhd">
            <name>neuramatix sdn bhd</name>
            <country>Malaysia</country>
        </organization>
        <organization id="aoyama-gakuin-univ">
            <name>Aoyama gakuin Univ.</name>
            <country>Japan</country>
        </organization>
        <organization id="warsaw-university-of-life-sciences">
            <name>Warsaw University of Life Sciences</name>
            <country>Poland</country>
        </organization>
    </organizations>
</conference>
